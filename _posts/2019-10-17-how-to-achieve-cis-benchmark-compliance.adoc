---
title: How to achieve compliance with the CIS AWS Foundations Benchmark
categories: Compliance
image: /assets/img/guides/cis-compliance/cis-logo.png
excerpt: Learn how to achieve and maintain compliance with each of the CIS AWS Foundations Benchmark recommendations.
tags: ["aws", "security", "compliance"]
cloud: ["aws"]
redirect_from: /static/guides/compliance/how-to-achieve-cis-benchmark-compliance/
---
:page-type: guide
:page-layout: post

:toc:
:toc-placement!:

// GitHub specific settings. See https://gist.github.com/dcode/0cfbf2699a1fe9b46ff04c41721dda74 for details.
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
toc::[]
endif::[]

== Intro
This is a complete guide to help you achieve compliance with the
link:https://www.cisecurity.org/benchmark/amazon_web_services/[CIS AWS Foundations Benchmark]. By following this guide,
you can launch infrastructure that is compliant with the Benchmark recommendations, and you'll be set to retain a
compliant state over time because all of the infrastructure is defined as code. This guide targets version 1.3.0 of the Benchmark.

NOTE: Previously, we supported version 1.2.0 of the Benchmark. If you are looking to upgrade from v1.2.0 to v1.3.0,
please follow link:/guides/upgrades/how-to-update-to-cis-13/[the upgrade guide] instead.

image:/assets/img/guides/cis-compliance/cis-account-architecture.png[CIS Benchmark Architecture]

=== What is the CIS AWS Foundations Benchmark?
The link:https://www.cisecurity.org/resources/?type=benchmark[CIS Benchmarks] are objective, consensus-driven
configuration guidelines developed by security experts to help organizations improve their security posture.
The AWS Foundations Benchmark is a set of configuration best practices for hardening AWS accounts to establish
a secure foundation for running workloads on AWS. It also provides ongoing monitoring to ensure that the
account remains secure.

=== What you'll learn in this guide

This guide consists of five main sections:

<<core_concepts>>::
  An overview of the AWS Foundations Benchmark, including its control sections and structure.

<<production_grade_design>>::
  How to use infrastructure as code to achieve compliance with minimal redundancy and maximum flexibility.

<<deployment_walkthrough>>::
  A step-by-step guide to achieving compliance using the Gruntwork Infrastructure as Code Library and the
  Gruntwork CIS AWS Foundations Benchmark wrapper modules.

<<next_steps>>::
  How to measure and maintain compliance.

<<traceability_matrix>>::
  A reference table that maps each Benchmark recommendation to the corresponding section in the deployment
walkthrough.


Feel free to read the guide from start to finish or skip around to whatever part interests you!

[[core_concepts]]
== Core concepts

The CIS AWS Foundations Benchmark is organized into the following sections:
 +
 +

. Identity and Access Management
. Storage
. Logging
. Monitoring
. Networking

There are multiple recommendations within each section. Note the use of the term _recommendation_ as opposed
to _control_ or _requirement_. This reinforces the point that CIS is a self-imposed, best-practices standard,
as opposed to compulsory or regulated and centralized standards such as the
link:https://www.pcisecuritystandards.org/[PCI DSS] for the payment card industry or
link:https://www.hhs.gov/hipaa/for-professionals/security/laws-regulations/index.html[HIPAA] for covered
health care entities.

=== Assessment Status
Each recommendation is classified as either _Automated_ or _Manual_. _Automated_ recommendations indicate that
the check for the recommendation may be accessed programmatically (e.g., an API exists to validate or enable
the recommendation). _Manual_ recommendations must be checked and remediated manually.

=== Profiles
The Benchmark defines two profile levels. Level one recommendations are easier to implement, incur less
overhead, but still substantially improve security. Level two recommendations are meant for highly sensitive
environments with a lower risk appetite. They may be more difficult to implement and/or cause more overhead in
day-to-day usage.

=== CIS Controls

Each recommendation is also linked to a corresponding link:https://www.cisecurity.org/controls/[CIS Control]. The
controls are distinct from the Benchmark. They're described by CIS as "a prioritized set of actions that collectively
form a defense-in-depth set of best practices that mitigate the most common attacks against systems and networks."
Organizations seeking to implement a comprehensive security program or framework can use the controls to measure their
progress and prioritize security efforts. The Foundations Benchmark is just one of several guidelines that can help
reach the bar set by the CIS Controls. Refer to the Benchmark document directly to view how the recommendations map to
controls.

=== Recommendation sections

==== Identity and Access Management
_Number of recommendations: 22_

The recommendations in this section involve the use of identity, accounts, authentication, and authorization.
On AWS, most identity and access control related concerns are managed using the
link:https://aws.amazon.com/iam/[eponymous IAM service]. Hence, most (but not all) of the recommendations in
this section discuss particular IAM configurations, such as the configuration of the password policy, the use
of various groups and roles, and the configuration of multi-factor authentication (MFA) devices.

==== Storage
_Number of recommendations: 3_

This section was added in the version 1.3.0 and involves the use of storage capabilities of AWS. The relevant
services for this section are link:https://aws.amazon.com/s3/[S3] and link:https://aws.amazon.com/ec2/[EC2]. The
recommendations in this section pertain to in-transit and at-rest encryption.

==== Logging
_Number of recommendations: 11_

AWS has a variety of logging, monitoring, and auditing features, and the Benchmark has recommendations for
several of them:

* link:https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-user-guide.html[AWS CloudTrail] tracks user activity and API usage
* link:https://docs.aws.amazon.com/config/latest/developerguide/WhatIsConfig.html[AWS Config] records and evaluates resource configurations
* link:https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html[VPC Flow Logs] capture network traffic information
  in VPCs

AWS has several other logging related features that are not covered directly by the Benchmark. For example,
the primary log ingestion and query service, link:https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html[Amazon CloudWatch
Logs], is integrated with many other AWS services. The Benchmark does not contain any recommendations
specifically for CloudWatch Logs, though many recommendations do make mention of it.

==== Monitoring
_Number of recommendations: 15_

Monitoring is an overloaded term in the industry. In the context of the AWS Foundations Benchmark, the
monitoring section is exclusively about monitoring for specific API calls using the CloudTrail service paired
with link:https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/MonitoringLogData.html[CloudWatch Logs
filter metrics]. Each recommendation in this section spells out a specific filter and an associated alarm.

==== Networking
_Number of recommendations: 4_

The Benchmark is uncomfortably light on networking, considering its central role in the security of any
distributed system. The recommendations merely limit traffic from the zero network (`0.0.0.0/0`) and
suggest limiting routing for VPC peering connections based on link:https://en.wikipedia.org/wiki/Principle_of_least_privilege[the principle of least-privilege].

[[production_grade_design]]
== Production-grade design
In <<core_concepts>> we discussed the basics of the AWS Foundations Benchmark. Although it's possible to achieve
compliance with the Benchmark by manually configuring each setting in the web console or entering the CLI commands, we
strongly discourage this approach. It precludes
link:https://gruntwork.io/guides/foundations/how-to-use-gruntwork-infrastructure-as-code-library/#infrastructure-as-code[the
myriad benefits of using code to manage infrastructure].
 +
 +

Instead, we advise using link:https://www.terraform.io[Terraform] (or similar tools, such as
link:https://aws.amazon.com/cloudformation/[CloudFormation] or link:https://www.pulumi.com/[Pulumi]) to configure cloud
resources programmatically. This section will cover the Terraform resources you can use to implement each of the
recommendations. We assume that you're familiar with the basics of Terraform. If you aren't, read our
link:https://blog.gruntwork.io/an-introduction-to-terraform-f17df9c6d180[Introduction to Terraform blog post], or pick
up the link:https://blog.gruntwork.io/terraform-up-running-2nd-edition-early-release-is-now-available-b104fc29783f[2nd
edition of Terraform Up & Running].

=== Identity and Access Management
The first section of the Benchmark centers on Identity and Access Management, including the following:

* Avoiding usage of the "root" account
* Requiring MFA for IAM users
* Setting a specific password policy
* Disabling administrative permissions
* Limiting the use of API access keys
* Using IAM roles
* Removing expired SSL/TLS certificates
* Enabling IAM Access Analyzer

In the subsequent sections, we'll review the recommendations and discuss how to implement them using Terraform resources and data sources.

[[configure_authentication]]
==== Configure authentication
One of main areas of concern in the IAM section relates to authentication. The Benchmark has recommendations for IAM
users and the root user account, password policy, and multi-factor authentication. There is more than one way to
authenticate to AWS, and the method you choose determines how to implement these recommendations in your code.

===== Federated authentication using SAML
Perhaps the most robust and secure method for authenticating to AWS is to use
link:https://aws.amazon.com/identity/saml/[federated SAML authentication] with an identity provider (IdP) like Okta,
Google, or Active Directory. In this configuration, users authenticate to the IdP and assume IAM roles to obtain
permissions in AWS. All user management is handled in the IdP, where you can assign roles to users according to their
needs. If you use this approach, several of the Benchmark recommendations, including recommendations 1.10,
1.15, and 1.11, are not applicable (assuming you have no IAM users at all).

Configuring SAML is a multi-step process that is outside the scope of this guide. Familiarize yourself with the
process by reviewing the link:https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_create_saml.html[AWS
documentation on the matter]. You can use the
link:https://www.terraform.io/docs/providers/aws/r/iam_saml_provider.html[`aws_iam_saml_provider`] and
link:https://www.terraform.io/docs/providers/aws/d/iam_policy_document.html[`aws_iam_policy_document`] Terraform
resources to manage your SAML provider via code.

===== IAM user authentication
Another option is to authenticate using IAM users. The accounts are created and managed directly in AWS as opposed to a
third-party provider. IAM users log in to AWS with a password and an optional MFA device. IAM users are easier to get
started with than SAML, and they're also free to use. However, to avoid unauthorized access, it's crucial to configure
the IAM user settings securely. IAM users may be more suitable for smaller environments with only a few users.

A few tips on creating IAM users with Terraform:

* To create IAM users, use the link:https://www.terraform.io/docs/providers/aws/r/iam_user.html[`aws_iam_user`] and
link:https://www.terraform.io/docs/providers/aws/r/iam_user_login_profile.html[`aws_iam_user_login_profile`] resources.

* As instructed by recommendation 1.11, do not create API access keys for new users automatically. The intent is that
users should create them on their own if and when needed.

* To stay compliant with recommendation 1.15, be sure to never attach IAM policies directly to IAM users. Instead, create IAM groups, attach policies to those groups, and add the user to groups using the link:https://www.terraform.io/docs/providers/aws/r/iam_user_group_membership.html[`aws_iam_user_group_membership`]. This helps to avoid scenarios where auditing the exact permissions of IAM users becomes difficult and unmaintainable.

Consider the following example which creates a user with access to AWS Support:

[source,hcl]
----
resource "aws_iam_user" "support_user" {
  name = "support"
}

resource "aws_iam_group" "example_group" {
  name = "support-group"
}

resource "aws_iam_group_policy_attachment" "support_group_attach" {
  group      = aws_iam_group.example_group.name
  policy_arn = "arn:aws:iam::aws:policy/AWSSupportAccess"
}

resource "aws_iam_user_group_membership" "example" {
  user = aws_iam_user.example_user.name
  groups = [aws_iam_group.example_group.name]
}

----

This code creates an IAM user called `support`, adds them to a new group called `support-group`, and attaches the
`AWSSupportAccess` managed policy to the group. It demonstrates how to meet a few of the Benchmark recommendations:

1. The user is created without an API access key (recommendation 1.11). Access keys should only be created by the user later.
2. The policy is attached to an IAM group, not directly to the IAM user (recommendation 1.15).
3. Recommendation 1.17 specifically requires that the Support policy be used. You should attach it to a group, as
shown here.

==== Do not use full administrator privileges
Recommendation 1.16 states that no IAM policies with full administrator privileges be assigned. However, some
administrator access is needed to maintain the account on an ongoing basis, and use of the root account is also
prohibited. What to do?

One approach is to create an IAM policy with full permissions to IAM and nothing else. Attach the policy to a group,
and give access only to trusted users. This allows _effective_ administrator access without an _explicit_
administrator policy. For example, you could use the following Terraform code to create such a policy:

[source,hcl]
----
data "aws_iam_policy_document" "iam_admin" {
  statement {
    sid = "iamAdmin"
    actions = [
      "iam:*",
    ]
    resources = ["*"]
    effect = "Allow"
  }
}
----

You can then attach that policy to a group:

[source,hcl]
----
resource "aws_iam_policy" "iam_admin" {
  name   = "iam_admin"
  path   = "/"
  policy = data.aws_iam_policy_document.iam_admin.json
}

resource "aws_iam_group" "iam_admin" {
  name = "iam-admins"
}

resource "aws_iam_group_policy_attachment" "iam_admin_group_attach" {
  group      = aws_iam_group.iam_admin.name
  policy_arn = aws_iam_policy.iam_admin.arn
}
----

In this example, any IAM user that is a member of the `iam-admins` group will have has permissions to access all
functionality in the IAM service, make them an effective administrator of the account.

==== Enabling multi-factor authentication for IAM users
Recommendation 1.10, which requires all IAM users to have MFA enabled, seems straightforward on the surface, but in AWS,
there's no way to explicitly require MFA for log in. Instead, you can make sure that all groups and roles have a
conditional IAM policy attached that explicitly denies all actions unless MFA is enabled. This way, whenever a user logs
in without MFA, all services will show a permission denied error if the user didn't use MFA.

The
link:https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_aws_my-sec-creds-self-manage-mfa-only.html[AWS
documentation has an example of this policy]. Create the policy with Terraform, and attach it to every group
you create - including the `iam-admins` and `support` groups we created above. Here's an example:

[source,hcl]
----
data "aws_iam_policy_document" "require_mfa_policy" {
  statement {
    sid = "AllowViewAccountInfo"
    effect = "Allow"
    actions = ["iam:ListVirtualMFADevices"]
    resources = ["*"]
  }

  statement {
    sid = "AllowManageOwnVirtualMFADevice"
    effect = "Allow"
    actions = [
      "iam:CreateVirtualMFADevice",
      "iam:DeleteVirtualMFADevice"
    ]
    resources = [
      "arn:aws:iam::${var.aws_account_id}:mfa/$${aws:username}",
    ]
  }

  statement {
    sid = "AllowManageOwnUserMFA"
    effect = "Allow"
    actions = [
      "iam:DeactivateMFADevice",
      "iam:EnableMFADevice",
      "iam:GetUser",
      "iam:ListMFADevices",
      "iam:ResyncMFADevice"
    ]
    resources = [
      "arn:aws:iam::${var.aws_account_id}:user/$${aws:username}",
      "arn:aws:iam::${var.aws_account_id}:mfa/$${aws:username}"
    ]
  }

  statement {
    sid = "DenyAllExceptListedIfNoMFA"
    effect = "Deny"
    not_actions = [
      "iam:CreateVirtualMFADevice",
      "iam:EnableMFADevice",
      "iam:GetUser",
      "iam:ListMFADevices",
      "iam:ListVirtualMFADevices",
      "iam:ResyncMFADevice",
      "sts:GetSessionToken"
    ]
    resources = ["*"]
    condition {
      test     = "Bool"
      variable = "aws:MultiFactorAuthPresent"
      values   = ["false"]
    }
  }
}

resource "aws_iam_group" "support" {
  name  = "support"
}


resource "aws_iam_group_policy" "require_mfa_for_support" {
  name   = "RequireMFA"
  group  = aws_iam_group.support.name
  policy = data.aws_iam_policy_document.require_mfa_policy
}
----

We've created an IAM policy that denies all access accept the necessary permissions to set up an MFA device, then we
attached the policy to the `support` group. If a user that is a member of the `support` group logs in without MFA, they
won't have access to any services, even if the `support` group or the user had other policies attached. They will have
enough permissions to set up an MFA device, and after doing so, they can log in and will have any permissions granted to
them by other IAM policies.

Attach a policy like this one to every group in your account.

==== Password policy
The IAM password policy is perhaps the most straightforward and explicit set of recommendations (1.8-1.9 and 1.12) in the entire
Benchmark. You can invoke link:https://www.terraform.io/docs/providers/aws/r/iam_account_password_policy.html[the
Terraform `aws_iam_account_password_policy` resource] to implement the recommended policy.

For example:

[source,hcl]
----
resource "aws_iam_account_password_policy" "aws_foundations_benchmark_policy" {
  minimum_password_length        = 14
  allow_users_to_change_password = true
  hard_expiry                    = true
  max_password_age               = 90
  password_reuse_prevention      = 24
}
----

[[cleanup_expired_certs]]
==== Cleanup Expired SSL/TLS certificates
The CIS AWS v1.3 recommendations require that all expired SSL/TLS certificates stored in AWS IAM are automatically removed
(see 1.19). Unfortunately removing expired certificates via AWS Management Console is not currently supported so we must remove
then using the AWS API. To view the current certificates stored in IAM, use the AWS CLI and execute the `list-server-certificates`
command:

[source,bash]
----
aws iam list-server-certificates
----

The command output should return an array that contains all of the SSL/TLS certificates currently stored in IAM and their metadata:

[source,json]
----
{
	"ServerCertificateMetadataList": [{
		"ServerCertificateId": "EHDGFRW7EJFYTE88D",
		"ServerCertificateName": "MyServerCertificate",
		"Expiration": "2021-07-05T23:59:59Z",
		"Path": "/",
		"Arn": "arn:aws:iam::012345678910:server-certificate/MySSLCertificate",
		"UploadDate": "2018-06-10T11:56:08Z"
	}]
}
----

The `Expiration` attribute contains the expiration date for each SSL/TLS certificate which you can use to determine
if it should be removed. To remove the certificate use the `delete-server-certificate` command, making sure to
substitute `<CERTIFICATE_NAME>` with the `ServerCertificateId` attribute from the previous command:

[source,bash]
----
aws iam delete-server-certificate --server-certificate-name <CERTIFICATE_NAME>
----

To automate this process you might decide to implement a Lambda function that runs on a regular schedule and removes
all expired SSL/TLS certificates. Check out the <<apply_account_baseline_root>>, <<apply_account_baseline_logs>> and <<apply_account_baseline_security>> section of the deployment walkthrough
to see how this module is used from the Landing Zone account baselines and is deployed in each of your AWS accounts.

[[iam_access_analyzer]]
==== IAM Access Analyzer
As of version 1.3.0, the CIS recommendations stipulate that the AWS IAM Access Analyzer service is enabled across all active regions in a given
AWS Account or Organization.

To achieve this compliance requirement, enable the IAM Access Analyzer service for every AWS region you have enabled in
every one of your AWS accounts. Alternatively, you could make use of the link:https://github.com/gruntwork-io/terraform-aws-security/tree/master/modules/iam-access-analyzer-multi-region[`iam-access-analyzer-multi-region`] module
available in the Gruntwork Service Catalog, or if you're following this guide, refer to <<apply_account_baseline_root>>, <<apply_account_baseline_logs>> and <<apply_account_baseline_security>> sections of the
deployment walkthrough to see how this module is used from the Landing Zone account baselines and is deployed in each of your AWS accounts.

Once enabled, it will scan only within the boundaries of the AWS Account or Organization it has access to. Only specific
resources are analyzed and included in the results - e.g. S3 buckets, SQS, etc. (For the full list of resources supported,
please visit link:https://docs.aws.amazon.com/IAM/latest/UserGuide/access-analyzer-resources.html[the relevant AWS docs]).
This lets you identify unintended access to these resources and data by external entities.

The findings from the IAM Access Analyzer can be found in the AWS web console, and can be archived or resolved.
Please visit the link:https://docs.aws.amazon.com/IAM/latest/UserGuide/access-analyzer-findings.html[AWS guidance on how to do so].

[[manual_steps]]
==== Manual steps
A few of the recommendations in the IAM section are not achievable via API and require a one-time manual configuration.
Perform the steps in this section manually.

[[root_mfa]]
===== Enable MFA for the root account
Securing the "root" user, or the first user that is created when you set up an AWS account, is one of the
first actions you should take in any new account. Unfortunately, there is no API or automation available for
configuring an MFA device for the root user. Follow the manual steps outlined in the
link:https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user.html#id_root-user_manage_mfa[AWS docs]. Configuring a virtual MFA device will achieve recommendation 1.5. You can also refer to the link:https://gruntwork.io/guides/foundations/how-to-configure-production-grade-aws-account-structure/[production-grade AWS account structure guide.]

For the paranoid: configure a hardware MFA device, as suggested by recommendation 1.6. We suggest using a
link:https://www.yubico.com/[Yubikey] due to its reputation for strong security characteristics and multitude of form
factors. Refer to
link:https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa_enable_physical.html#enable-hw-mfa-for-root[
the documentation for more information on using a hardware device with the root user].

[[subscribe_sns]]
===== Subscribe to SNS topic
The Config alerts and CloudWatch Metric Alarms all go to an SNS topic. Unfortunately, there is no way to automate
subscribing to the SNS topic as each of the steps require validating the delivery target. Follow the steps outlined in
the link:https://docs.aws.amazon.com/sns/latest/dg/sns-user-notifications.html[AWS docs] to be notified by Email, Phone,
or SMS for each of the alerts.

You can also configure an automated system integration if you have a third party alerting system or central dashboard.
Follow the steps in the link:https://docs.aws.amazon.com/sns/latest/dg/sns-http-https-endpoint-as-subscriber.html[AWS
docs] on how to add an HTTPS endpoint as a subscriber to the alerts.


[[security_questions]]
===== Answer security questions and complete contact details
When setting up a new account, AWS asks for contact information and security questions. Unfortunately, there
is no API or automation available for this functionality. In the AWS console, visit the link:https://console.aws.amazon.com/billing/home?#/account[Account settings] page and complete the _Alternate Contacts_ and _Configure Security Challenge Questions_ questions.

For further detail, follow the manual steps outlined in the CIS Benchmark document.

=== Storage
Version 1.3.0 of the Benchmark includes a new storage section that has three recommendations pertaining to the S3 service as well as the EC2 service.
These have to do with encryption at rest and in transit.

To comply with recommendation 2.1.1, make sure to enable server side encryption on your S3 buckets. In Terraform, this
is achieved by configuring the `server_side_encryption_configuration` argument of the `aws_s3_bucket` resource.

To comply with recommendation 2.1.2, make sure that all access to your S3 buckets is over TLS. In Terraform, you will
want to attach a policy to your buckets that includes a statement similar to this:

[source,hcl]
----
statement {
  sid     = "AllowTLSRequestsOnly"
  effect  = "Deny"
  actions = ["s3:*"]
  resources = [
    <YOUR BUCKET ARN>,
    "${<YOUR BUCKET ARN>}/*"
  ]
  principals {
    type        = "*"
    identifiers = ["*"]
  }
  condition {
    test     = "Bool"
    variable = "aws:SecureTransport"
    values   = ["false"]
  }
}
----
[[configure_ebs_encryption]]
==== Configure EBS Encryption
To comply with recommendation 2.2.1 be sure to configure link:https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html[EBS volume encryption]
in all of the enabled AWS regions within your AWS Account(s). You can invoke the Terraform
`aws_ebs_encryption_by_default` resource to implement the recommendation.

For example:

[source,hcl]
----
resource "aws_ebs_encryption_by_default" "ebs_encryption" {
  enabled = true
}
----

=== Logging
In the Logging section, the Benchmark recommendations target the following services:

* link:https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-user-guide.html[AWS CloudTrail]
* link:https://docs.aws.amazon.com/config/latest/developerguide/WhatIsConfig.html[AWS Config]
* link:https://docs.aws.amazon.com/kms/latest/developerguide/rotate-keys.html[KMS key rotation]
* link:https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html[VPC Flow Logs]

We'll cover each of them in turn.

==== AWS CloudTrail
The Benchmark has specific requirements for the CloudTrail configuration, described in recommendations 3.1-4, 3.6-7 and 3.10-11.
The CloudTrail must have the following characteristics:

. Collects events
link:https://docs.aws.amazon.com/awscloudtrail/latest/userguide/receive-cloudtrail-log-files-from-multiple-regions.html[in
all regions]
. Enables
link:https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-log-file-validation-intro.html[log
file integrity validation]
. Ensures that the S3 bucket used by CloudTrail is not publicly accessible
. Integrates
link:https://docs.aws.amazon.com/awscloudtrail/latest/userguide/send-cloudtrail-events-to-cloudwatch-logs.html[CloudTrail
with CloudWatch Logs]
. link:https://docs.aws.amazon.com/awscloudtrail/latest/userguide/encrypting-cloudtrail-log-files-with-aws-kms.html[Encrypts
CloudTrail logs at rest]
. Enables link:https://docs.aws.amazon.com/AmazonS3/latest/dev/ServerLogs.html[access logging] for the CloudTrail S3 bucket
. Enables link:https://docs.aws.amazon.com/AmazonS3/latest/user-guide/enable-cloudtrail-events.html[object-level logging] for read and write events for the CloudTrail S3 bucket

Use the link:https://www.terraform.io/docs/providers/aws/r/cloudtrail.html[`aws_cloudtrail`] Terraform resource to create the CloudTrail. Include the following settings in the CloudTrail configuration:

[source,hcl]
----
is_multi_region_trail         = true
include_global_service_events = true
enable_log_file_validation    = true
s3_bucket_name                = local.cloudtrail_s3_bucket_name
cloud_watch_logs_group_arn    = local.cloudtrail_s3_bucket_arn

event_selector {
  read_write_type           = "All"
  include_management_events = true

  data_resource {
    type   = "AWS::S3::Object"
    values = ["${local.cloudtrail_s3_bucket_name}"]
  }
}
----

You'll also need the link:https://www.terraform.io/docs/providers/aws/r/s3_bucket.html[`aws_s3_bucket`],
link:https://www.terraform.io/docs/providers/aws/r/s3_account_public_access_block.html[`aws_s3_account_public_access_block`]
resources to create an S3 bucket for the CloudTrail to send its events to and to disable public access to the bucket;
you wouldn't want to expose the CloudTrail data publicly!

Finally, you'll need the
link:https://www.terraform.io/docs/providers/aws/r/cloudwatch_log_group.html[`aws_cloudwatch_log_group`] resource to
create a CloudWatch Log group as another location for CloudTrail to send events. Use this ARN for the `aws_cloudtrail`
resource `cloud_watch_logs_group_arn` parameter when creating the CloudTrail.

==== AWS Config
Benchmark recommendation 3.5 states that AWS Config be enabled in all regions. This is challenging to implement with
Terraform because running a particular configuration in all regions is not a feature that Terraform has natively.
Terraform has link:https://www.terraform.io/docs/configuration/expressions.html#for-expressions[loops], but they aren't
available for the purpose of repeating a resource in many regions. Unfortunately, at the time of writing, there isn't a
way to complete this recommendation without repetitive code.

To proceed, start by creating a Terraform module that takes the following actions:

. Creates an link:https://www.terraform.io/docs/providers/aws/r/sns_topic.html[SNS topic] for publishing Config events
. Creates an link:https://www.terraform.io/docs/providers/aws/d/s3_bucket.html[S3 bucket] for Config events and link:https://www.terraform.io/docs/providers/aws/r/s3_account_public_access_block.html[disables public access]
. Creates an link:https://www.terraform.io/docs/providers/aws/d/iam_role.html[IAM role] for the config service to access an S3 bucket and an SNS topic
. Creates a link:https://www.terraform.io/docs/providers/aws/r/config_configuration_recorder.html[configuration recorder]
. Creates a link:https://www.terraform.io/docs/providers/aws/r/config_delivery_channel.html[delivery channel]
. link:https://www.terraform.io/docs/providers/aws/r/config_configuration_recorder_status.html[Enables the configuration recorder]

When the module is working and sets up AWS Config according to the prescribed configuration, you should invoke it once
for each region in the account. One way to do this is to use
link:https://www.terraform.io/docs/configuration/providers.html#alias-multiple-provider-instances[provider aliases]. For
example, you could specify one provider for each region, then invoke the module for each provider:

[source,hcl]
----
# The default provider configuration
provider "aws" {
  alias  = "us-east-1"
  region = "us-east-1"
}

# Additional provider configuration for west coast region
provider "aws" {
  alias  = "us-west-2"
  region = "us-west-2"
}

# ... repeat the provider for each region in the AWS account

module "aws_config_us_east_1" {
  source = "/path/to/your/config/module"
  providers = {
    aws = aws.us-east-1
  }
}

module "aws_config_us_west_2" {
  source = "/path/to/your/config/module"
  providers = {
    aws = aws.us-west-2
  }
}

# ... repeat the module invocation for each provider
----

When AWS launches new regions, they are link:https://docs.aws.amazon.com/general/latest/gr/rande-manage.html[not enabled by default], so you won't need to add to this list over time.

Alternatively, you could link:https://docs.aws.amazon.com/general/latest/gr/rande-manage.html#rande-manage-disable[disable] the regions you aren't using and only enable AWS Config for those that you need.

==== KMS Key rotation
Finally, a simple recommendation! To meet recommendation 3.8, create KMS keys with key rotation enabled. Using Terraform, it looks like this:

[source,hcl]
----
resource "aws_kms_key" "example" {
  description         = "Example Key"
  enable_key_rotation = true
}
----

==== VPC Flow Logs
Under the Benchmark, all VPCs must have a Flow Log to log network traffic. Use the
link:https://www.terraform.io/docs/providers/aws/r/flow_log.html[`aws_flow_log`] Terraform resource, being sure to use
`log_destination_type=cloud-watch-logs`.
 +
 +

Because the recommendation is to attach flow logs to every single VPC, you'll need to repeat the configuration for all
the default VPCs which exist in all regions of the account. You can use the
link:https://github.com/gruntwork-io/cloud-nuke[`cloud-nuke defaults-aws` command] to easily remove all the default VPCs
(and default security groups) from all regions of an account, making it easier to achieve this recommendation.

=== Monitoring
The Monitoring section has 15 recommendations for creating specific
link:https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/MonitoringPolicyExamples.html[CloudWatch Logs metric
filters] that send alarms to an SNS topic when a particular condition is met.

The easiest way to achieve this recommendation is to create a Terraform module that creates CloudWatch Logs metrics
filters and CloudWatch Alarms, and then invoke the module once for each recommendation. You'll need the
link:https://www.terraform.io/docs/providers/aws/r/cloudwatch_log_metric_filter.html[`aws_cloudwatch_log_metric_filter`]
and link:https://www.terraform.io/docs/providers/aws/r/cloudwatch_metric_alarm.html[`aws_cloudwatch_metric_alarm`]
Terraform resources.


=== Networking
The networking section involves a paltry four recommendations. We don't consider this section to be sufficient
to ensure a secure networking configuration. For a deeper dive, refer to Gruntwork's
link:https://gruntwork.io/guides/networking/how-to-deploy-production-grade-vpc-aws/[How to deploy a
production-grade VPC on AWS] guide, which includes recommendations for segmentation using network ACLs,
security groups, and remote access. Moreover, our link:https://gruntwork.io/reference-architecture/[Reference
Architecture] can get you up and running with a secure network configuration immediately.

Recommendation 5.1 requires that you use Network ACL rules to block all access to the remote server administration ports, such as SSH to port 22 and Remote
Desktop to port 3389, by default. You can then add additional NACL rules to allow remote admin access, but only from specific CIDR blocks. Recommendation 5.2 similarly allows you to allow remote admin access from specific CIDR blocks in your Security Groups. Note that allowing remote admin access from all IPs (`0.0.0.0/0`) is NOT allowed, so instead, if you require SSH or Remote Desktop to your cloud resources, provide a more restricted CIDR
range, such as the IP addresses of your offices.

To meet recommendation 5.3, run the link:https://github.com/gruntwork-io/cloud-nuke[`cloud-nuke defaults-aws`] command
to remove the rules from all default security groups. Note that it isn't possible to actually delete the default
security group, so instead the command deletes the rules, eliminating the risk of something being mistakenly exposed.

Finally, for recommendation 5.4, the guidance is straightforward: when creating peering connections between VPCs, do not
create routes for subnets that don't need them. In other words, only create routes between subnets that need them based
on the services running on those subnets. This can help to avoid exposing services between networks unnecessarily.

[[deployment_walkthrough]]
== Deployment walkthrough
The <<production_grade_design>> section describes in detail the Terraform resources to use and the approach to take for
each recommendation, but we've already done that grunt work! This section documents how to achieve compliance using the
Infrastructure as Code modules from Gruntwork.

[[pre_requisites]]
=== Pre-requisites

This walkthrough has the following pre-requisites:

==== Gruntwork Infrastructure as Code Library
This guide uses code from the link:https://gruntwork.io/infrastructure-as-code-library/[Gruntwork Infrastructure as Code Library], as it
implements most of the production-grade design for you out of the box. Make sure to read
link:/guides/foundations/how-to-use-gruntwork-infrastructure-as-code-library[How to use the Gruntwork Infrastructure as Code Library].

==== Gruntwork Compliance for CIS AWS Foundations Benchmark
This guide also uses code from the link:https://gruntwork.io/achieve-compliance[Gruntwork CIS AWS
Foundations Benchmark repository], which contains the necessary configurations to achieve compliance.
[.exceptional]
IMPORTANT: You must be a [js-subscribe-cta]#Gruntwork Compliance subscriber# to access the Gruntwork
Infrastructure as Code Library and the CIS AWS Foundations Benchmark modules.

[[account_structure]]
==== How to configure a production-grade AWS account structure
Review the link:https://gruntwork.io/guides/foundations/how-to-configure-production-grade-aws-account-structure/[production-grade AWS account structure guide] to familiarize yourself with many of the concepts that this walkthrough depends on.

==== Terraform
This guide uses https://www.terraform.io/[Terraform] to define and manage all the infrastructure as code. If
you're not familiar with Terraform, check out
https://blog.gruntwork.io/a-comprehensive-guide-to-terraform-b3d32832baca[A Comprehensive Guide to Terraform],
https://training.gruntwork.io/p/terraform[A Crash Course on Terraform], and
link:/guides/foundations/how-to-use-gruntwork-infrastructure-as-code-library[How to Use the Gruntwork
Infrastructure as Code Library].

==== Terragrunt
This guide uses https://terragrunt.gruntwork.io/[Terragrunt] to configure the infrastructure as code. To get familiar
with Terragrunt, explore the https://terragrunt.gruntwork.io/docs/#features[features], read the https://terragrunt.gruntwork.io/docs/getting-started/quick-start/[guides],
or dive into the https://terragrunt.gruntwork.io/docs/[documentation].

==== Keybase (optional)
As part of this guide, you will create IAM users, including, optionally, credentials for those IAM users. If you
choose to create credentials, those credentials will be encrypted with a PGP key. You could provide the PGP keys
manually, but a more manageable option may be to have your team members to sign up for https://keybase.io[Keybase],
create PGP keys for themselves, and then you can provide their Keybase usernames, and the PGP keys will be retrieved
automatically.

[[gruntwork_solution]]
=== The Gruntwork solution
Gruntwork offers battle-tested infrastructure as code modules to help you create production grade infrastructure in a
fraction of the time it would take to develop from scratch. Each of the core modules are "compliance-ready"; they are
mostly unopinionated by default, but they can be configured for compliance with the right settings.

To further simplify and expedite compliance, the Gruntwork CIS Service Catalog uses both standalone compliance
modules as well as "wrappers" around the core, unopinionated modules in the Infrastructure as Code Library. The
standalone compliance modules are designed with the compliance requirements built-in, whereas the wrappers
call the core modules with configuration values that are compliant with the AWS Foundations Benchmark. You can use both
types of modules by creating a module of your own (in the case of the wrapper modules, this can be considered a second
wrapper) and using the compliance module as the `source`. Optionally, you can also use `terragrunt` to call your module,
thus creating a chain of IaC modules.
 +
 +

.Types of CIS module relationships to avoid repetitive code and minimize the amount of extra work needed to achieve compliance.
image::/assets/img/guides/cis-compliance/cis-module-relationships.png[]

Let's unpack this a bit.

[[core_modules]]
==== Core modules
Core modules are broadly applicable and can be used with or without compliance requirements. For example,
the link:https://github.com/gruntwork-io/terraform-aws-security/blob/master/modules/iam-groups/README.md[`iam-groups`
core module] creates a best practices set of IAM groups. The groups are configurable according to your needs.
You could, for example, choose to create a group with read-only access, another group with full administrator
access, and no other groups. All Gruntwork subscribers have access to the core modules, which reside in
Gruntwork's link:https://gruntwork.io/repos[infrastructure as code repositories].

[[standalone_modules]]
==== Standalone Compliance modules
The standalone compliance modules complement the modules available in the IaC Library. They have the CIS compliance requirements built right in and may combine multiple modules including Core modules for a
specific use case. For example, the link:https://github.com/gruntwork-io/terraform-aws-cis-service-catalog/tree/master/modules/cleanup-expired-certs[`cleanup-expired-certs` standalone module] deploys a Lambda function that runs regularly and automatically removes all expired SSL/TLS certificates stored in AWS IAM in compliance with recommendation 1.19 of the CIS AWS Foundations Benchmark. These modules are in the link:https://github.com/gruntwork-io/terraform-aws-cis-service-catalog[`terraform-aws-cis-service-catalog`
repository] (accessible to Gruntwork Compliance subscribers).

[[wrapper_modules]]
==== Compliance wrapper modules
The compliance wrapper modules are an extension of the IaC Library. They use the
link:https://www.terraform.io/docs/modules/sources.html[`source` argument in a Terraform module block] to invoke
the core module with a configuration that is customized for compliance with the CIS AWS Foundations Benchmark.
These modules are in the link:https://github.com/gruntwork-io/terraform-aws-cis-service-catalog[`terraform-aws-cis-service-catalog`
repository] (accessible to Gruntwork Compliance subscribers).

[[infrastructure_live]]
==== infrastructure-live
`infrastructure-live` uses link:https://github.com/gruntwork-io/terragrunt[Terragrunt] to make it easier to
work with Terraform modules in multiple environments. `infrastructure-live` is optional - you can use all of the modules
with or without Terragrunt.
 +
 +
If you're not using Terragrunt, you can use Terraform modules to call the compliance wrapper modules directly. Subscribers can refer to the
link:https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/core-concepts.md#create-your-own-service-catalog[Create your own service catalog section]
in the Gruntwork Service Catalog documentation for more information on how you might use `infrastructure-live`.

[[benefits]]
==== Benefits
This modular, decomposed approach allows for maximum code reuse. The core modules can be used with or without
compliance, depending on how they are configured. The compliance wrappers are like shadows of the core
modules; they pass through most of the variables to the core modules without alteration, but hard code any
settings needed for compliance. When you call the compliance modules from your own code, you only need to set up any variables that are custom for your environment. Often
times the default settings are good enough.
 +
 +
You can use this approach on each AWS account. In many cases, you'll only need compliance for production accounts, but the
same methodology can be applied to pre-production accounts as well.
 +
 +

If you need to brush up on how the IaC Library works, read the
link:https://gruntwork.io/guides/foundations/how-to-use-gruntwork-infrastructure-as-code-library/[How to use
the Gruntwork Infrastructure as Code Library] guide.

=== Create the root account

The first step is to create your root account. This account will be the parent of all of your other AWS accounts and
the central place where you manage billing. You create this initial account manually, via a web browser:

. Go to https://aws.amazon.com.
. Click Create an AWS Account.
. Go through the sign up flow, entering contact and billing details as requested.
. You will be asked to enter an email address and password to use as the credentials for the root user of this root
account.

[[lock_down_root_user]]
=== Lock down the root user

After signing up for an AWS account, you'll be logged in as the root user. The root user has unrestricted access to
just about everything in your AWS account (and any child accounts), so if an attacker compromises your root user, the
results can be catastrophic for your company. Therefore, you should lock down the root user as much as possible:

Use a secrets manager::
Do NOT store the root user's password, or secrets of any kind, in plain text. Instead, always use a secrets manager
such as https://1password.com[1Password], https://www.lastpass.com[LastPass], or https://www.passwordstore.org[pass]
to store the credentials in an encrypted format.

Use a strong, generated password::
Do NOT re-use passwords from other websites, or any password that you can remember at all. Instead, generate a random,
cryptographically secure, long password (20+ characters) for the root user. All the password managers mentioned above
can generate and store passwords for you in one step, so use them!

Add security questions to your root account::
The CIS benchmark suggests adding security questions when registering your AWS account so that when somebody contacts
AWS support, they will be required to complete a security challenge. To add security questions to the root account,
navigate in the AWS web console to `My Account` and then to the `Personal Information` page. There you should be able
to click on `Configure Security Challenge Questions` and add your questions.

Enable MFA::
Make sure to
https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user.html#id_root-user_manage_mfa[enable MFA for your root user].
Feel free to use a virtual or hardware MFA device, whichever is more straightforward or required by your company, as either one
dramatically improves the security of your root user. It is up to your discretion to decide which option is suitable
for your use case. The CIS benchmark recommends using a dedicated or company-owned device for MFA and not a personal
one. This applies to both virtual and hardware devices.

Disable access keys::
Make sure to
https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user.html#id_root-user_manage_delete-key[delete the root user's access keys],
so that the only way to login as the root user is via the web console, where MFA is required.

Don't use the root user again::
In the next section, you will create an IAM user in the root account with admin permissions. Once you've created that
IAM user, you should do everything as that IAM user, and more or less never touch the root user account again.
The only time you'll need it is for account recovery situations (e.g., you accidentally deleted the IAM user or lost
your credentials) or for the
https://docs.aws.amazon.com/general/latest/gr/aws_tasks-that-require-root.html[small number of tasks that require root user credentials].


[[create_iam_user_in_root]]
=== Create an IAM user in the root account

As the last action you do as the root user, you MUST create an IAM user. This is not only a better practice from a
security standpoint, but also, the `account-baseline-xxx` modules we will use below assume IAM roles, which does not
work with a root user. Later on, we'll create and manage all IAM users as code, but you should create this very first
IAM user manually by
https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html#id_users_create_console[following these instructions]:

. Enter a username for your IAM user.
. Select both "programmatic access" and "AWS Management Console access."
. On the next page, click "Attach existing policies to user directly" and attach the `AdministratorAccess` policy.
. Click next a few more times to create the IAM user.
. In a secrets manager, save the IAM sign-in URL, your IAM user's username, the password, and your Access Keys.

[[lock_down_iam_users]]
=== Lock down the root account IAM users

Although IAM users don't have the same powers as a root user, having an IAM user account compromised can still be a
huge problem for your company (especially if that IAM user had admin permissions), so it's still critical to lock down
IAM user accounts as much as possible:

Use a secrets manager::
Do NOT store the root user's password, or secrets of any kind, in plain text. Instead, always use a secrets manager
such as https://1password.com[1Password], https://www.lastpass.com[LastPass], or https://www.passwordstore.org[pass]
to store the credentials in an encrypted format.


Use a strong, generated password::
Do NOT re-use passwords from other websites, or any password that you can remember at all. Instead, generate a random,
cryptographically secure, long password (20+ characters). All the password managers mentioned above can generate and
store passwords for you in one step, so use them!


Enable MFA::
Always make sure to
https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa_enable.html[enable MFA for your IAM user].
Feel free to use a virtual or hardware MFA device—whichever is easier or required by your company—as either one
dramatically improves the security of your IAM user. Note that using SMS (text messages) for MFA is
https://www.schneier.com/blog/archives/2016/08/nist_is_no_long.html[no longer recommended by NIST] due to known
https://www.theverge.com/2017/9/18/16328172/sms-two-factor-authentication-hack-password-bitcoin[vulnerabilities with the cellular system],
so using a virtual or hardware MFA device is preferable; that said, MFA with SMS is still better than no MFA at all.

[[deployment_approach]]
== Deployment approach
Before we dive into the code and deployment for each of the resources, let's take a step back and understand how the code is structured.
Most of the features explained in the "Production-grade design" section will be deployed by using the Landing Zone solution, and some more standalone modules like the VPC module.

The Landing Zone will be deployed in three steps - the `account-baseline-root` to set up your organisation-wide configurations, and create the necessary child AWS accounts. Next, we'll need to apply the `account-baseline-app` baseline against the created logs account, which would in its turn set up the CloudTrail, AWS Config buckets and a few more settings that will be used for aggregation of logs and metrics from the whole organization. Then the `account-baseline-security` will be applied, and that's responsible to set up your IAM roles, groups that would allow you to access the rest of the accounts within your organization. And finally, the `account-baseline-app` will be applied to an AWS account with the purpose of hosting an application.

The standalone modules will follow the pattern of referencing the module and providing the necessary input variables for it, then applying with `terragrunt`.

[[deploy_landingzone]]
== Deploy Landing Zone solution

=== Configure the "account-baseline-root" baseline for the root account

[.exceptional]
IMPORTANT: You must be a [js-subscribe-cta]#Gruntwork subscriber# to access https://github.com/gruntwork-io/terraform-aws-cis-service-catalog/[`terraform-aws-cis-service-catalog`].

First, let's set consider the repository structure that is recommended by this guide. It is available for your reference in the "/examples/for-production" section in the https://github.com/gruntwork-io/terraform-aws-cis-service-catalog/tree/master/examples/for-production[`terraform-aws-cis-service-catalog` repository]. It looks like this:

[source]
----
Consider the following directory structure for your `infrastructure-live` repository. It showcases the configuration files foryour local variables.
.
└ infrastructure-live
    └ prod
        └ account.hcl
        └ global
            └ region.hcl
        └ us-east-1
            └ region.hcl
    └ common.hcl
    └ accounts.json
----

Each of the `region.hcl`, `account.hcl` and `common.hcl` should contain the relevant information, so in your modules you're able to reference the values like this:

[source, hcl]
----
locals {
  # Automatically load common variables shared across all accounts
  common_vars = read_terragrunt_config(find_in_parent_folders("common.hcl"))

  # Automatically load account-level variables
  account_vars = read_terragrunt_config(find_in_parent_folders("account.hcl"))

  # Extract the account_name for easy access
  account_name = local.account_vars.locals.account_name

  # Automatically load region-level variables
  region_vars = read_terragrunt_config(find_in_parent_folders("region.hcl"))

  # Extract the region for easy access
  aws_region = local.region_vars.locals.aws_region
}
----

You'll need to create these files in order to be able to follow the code examples following. For examples on what to put in each of these files, refer to the https://github.com/gruntwork-io/terraform-aws-cis-service-catalog/tree/master/examples/for-production[`terraform-aws-cis-service-catalog` repository]. The `locals` configuration above can be used in each of the `terragrunt.hcl` files to help you avoid repetition. Note that the examples below won't show this in the interest of clarity.

Next, we'll configure the `account-baseline-root` baseline for the root account that is responsible for creating all the child accounts.
It will also configure AWS Organizations, IAM Roles, IAM Users, IAM Groups, IAM Password Policies, Amazon GuardDuty, AWS CloudTrail, AWS Config and Security Hub.

We'll be using the `landingzone/account-baseline-root` module from https://github.com/gruntwork-io/terraform-aws-cis-service-catalog[terraform-aws-cis-service-catalog].

NOTE: This guide will use https://github.com/gruntwork-io/terragrunt[Terragrunt] and its associated file and folder
structure to deploy Terraform modules. Please note that *Terragrunt is NOT required for using Terraform modules from the Gruntwork Infrastructure as Code Library.* Check out link:/guides/foundations/how-to-use-gruntwork-infrastructure-as-code-library[How to use the Gruntwork Infrastructure as Code Library]
for instructions on alternative options, such as how to
link:/guides/foundations/how-to-use-gruntwork-infrastructure-as-code-library#deploy_using_plain_terraform[deploying how to use plain terraform].

Next, create a `terragrunt.hcl` file in `infrastructure-live`. It should go under the file path `root/_global/account-baseline`:

----
infrastructure-live
  └ prod
    └ _global
      └ region.hcl
      └ account-baseline
        └ terragrunt.hcl
----
Point the `source` URL in your `terragrunt.hcl` file to the `account-baseline-root` module in the https://github.com/gruntwork-io/terraform-aws-cis-service-catalog[terraform-aws-cis-service-catalog]
repo, setting the `ref` param to the version you require:

.infrastructure-live/prod/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
terraform {
  source = "git::git@github.com/gruntwork-io/terraform-aws-cis-service-catalog//modules/landingzone/account-baseline-root?ref=v0.22.0"

  # This module deploys some resources (e.g., AWS Config) across all AWS regions, each of which needs its own provider,
  # which in Terraform means a separate process. To avoid all these processes thrashing the CPU, which leads to network
  # connectivity issues, we limit the parallelism here.
  extra_arguments "parallelism" {
    commands  = get_terraform_commands_that_need_parallelism()
    arguments = ["-parallelism=2"]
  }
}
----

[.exceptional]
IMPORTANT: We **strongly** recommend setting Terraform parallelism to a low value (e.g., `-parallelism=2`), as shown above, with the `account-baseline-xxx` modules. This is because these modules deploy multi-region resources (e.g., GuardDuty, AWS Config, etc), and for each region, Terraform spins up a separate process, so if you don't limit the parallelism, it may peg all your CPU cores and lead to network connectivity errors.

Set the variables for the `account-baseline-root` module in this environment in the `inputs = { ... }` block of `terragrunt.hcl`:

.infrastructure-live/prod/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
locals {
  aws_region = local.aws_region

  accounts = {
    root = local.accounts.root
  }

  # Both buckets will created in the logs account by account-baseline-root
  config_s3_bucket_name     = "acme-config-bucket-logs"
  cloudtrail_s3_bucket_name = "acme-cloudtrail-logs"
}

inputs = {
  # Fill in the region you want to use (only used for API calls) and the ID of your root AWS account (see the locals above)
  aws_region     = local.aws_region
  aws_account_id = local.accounts.root

  # Prefix all resources with this name
  name_prefix = "acme-root"

  # If you've already created an AWS Organization in your root account, set this to false
  create_organization = false

  # The child AWS accounts to create in this AWS organization
  child_accounts = {
    logs = {
      email = "root-accounts+logs@acme.com"

      # Mark this account as the logs account, used to aggregate all AWS Config and CloudTrail data.
      is_logs_account = true
    },
    security = {
      email = "root-accounts+security@acme.com"
    },
    shared-services = {
      email = "root-accounts+shared-services@acme.com"
    },
    dev = {
      email = "root-accounts+dev@acme.com"
    },
    stage = {
      email = "root-accounts+stage@acme.com"
    },
    prod = {
      email = "root-accounts+prod@acme.com"
    }
  }

  # The IAM users to create in this account. Since this is the root account, you should only create IAM users for a
  # small handful of trusted admins.
  #
  # NOTE: Make sure to include the IAM user you created manually here! We'll import the user into Terraform state in
  # the next step of this guide, allowing you to manage this user as code going forward.
  users = {
    alice = {
      groups               = ["support"]
      pgp_key              = "keybase:alice"
      create_login_profile = true
      create_access_keys   = false
    },
    bob = {
      groups               = ["billing"]
      pgp_key              = "keybase:bob"
      create_login_profile = true
      create_access_keys   = false
    }
  }

  ################################
  # Parameters for AWS Config
  ################################
  # Send Config logs to the common S3 bucket.
  config_s3_bucket_name = local.config_s3_bucket_name

  ################################
  # Parameters for CloudTrail
  ################################

  # Send CloudTrail logs to the common S3 bucket.
  cloudtrail_s3_bucket_name = local.cloudtrail_s3_bucket_name

  # The ARN is a key alias, not a key ID. This variable prevents a perpetual diff when using an alias.
  cloudtrail_kms_key_arn_is_alias = true

  ##################################
  # Cross-account IAM role permissions
  ##################################

  # By granting access to the root ARN of the Security account in each of the roles below,
  # we allow administrators to further delegate access to other IAM entities

  # Assuming the developers role will grant access to these services.
  dev_permitted_services = [
    "ec2",
    "ecs",
    "lambda",
    "rds",
    "elasticache",
    "route53",
  ]

  # Assuming the auto-deploy role will grant access to these services.
  auto_deploy_permissions = [
    "iam:GetRole",
    "iam:GetRolePolicy",
  ]
}
----

The example code above does the following:

. **Create 6 child AWS accounts**. These accounts are described in more detail in the https://www.gruntwork.io/guides/foundations/how-to-configure-production-grade-aws-account-structure/#child_accounts[How to configure a production-grade AWS account structure using Gruntwork AWS Landing Zone child accounts section].

. **Associate an email address with each of the child accounts**. This will be the email address for the root user of
each account and AWS requires that the root user's email address is _globally_ unique, so it cannot be the email
address you used for the root account or any of the other child accounts. You'll have to either create multiple email
accounts in your company's email system, or, if your company uses Gmail (perhaps as part of G Suite), you can take
advantage of the fact that https://gmail.googleblog.com/2008/03/2-hidden-ways-to-get-more-from-your.html[Gmail
  ignores everything after a plus sign in an email address], so that while AWS will see
`root-accounts+security@acme.com`, `root-accounts+shared@acme.com`, and
`root-accounts+dev@acme.com` as three unique email addresses, Gmail will see them all as the same email
address, `root-accounts@acme.com`.

. **Mark one of the child accounts as a logs account**. We set `is_logs_account = true` on one of the child accounts
to indicate it is the logs account where we will aggregate AWS Config, CloudTrail, IAM Access Analyzer and Security Hub data from all the other accounts.
The `account-baseline-root` module will automatically create an S3 bucket for AWS Config and an S3 bucket and KMS CMK
= for CloudTrail in this account and configure the root account to send all the AWS Config and CloudTrail data to these
S3 buckets. Later on, you'll configure all the other accounts to send their data to these S3 buckets too.

. **Create IAM groups**. By default, `account-baseline-root` will **not** create a `full-access` IAM group as CIS requirement 1.16 guides. It will create a `support` and a `billing` IAM group (for the support and finance teams).

. **Create IAM users**. For this example, we create `alice` and `bob`, adding `alice` to the `full-access`
IAM group and `bob` to the `billing` IAM group. _Note_: your own IAM user (the one you created manually) should be
in the `users` list; we'll use the `import` command to put this user under Terraform management shortly.

. **Generate a password for each user**. We encrypt this password with that user’s PGP key from Keybase (we’ll come
back to how to handle the passwords shortly).

Pull in the https://www.terraform.io/docs/backends/[backend] settings from a root `terragrunt.hcl` file that you
`include` in each child `terragrunt.hcl`:

.infrastructure-live/root/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
include {
  path = find_in_parent_folders()
}
----

Next, you need to authenticate as your IAM user in the root account. There are
https://blog.gruntwork.io/a-comprehensive-guide-to-authenticating-to-aws-on-the-command-line-63656a686799[multiple ways to authenticate to AWS on the CLI];
in this guide, we'll use the open source tool https://github.com/99designs/aws-vault[aws-vault].
https://github.com/99designs/aws-vault#installing[Install aws-vault] and add to it the Access Keys you saved earlier
from your IAM user:

[source,bash]
----
$ aws-vault add root-iam-user
Enter Access Key Id: XXXXXXXXXXXX
Enter Secret Key: YYYYYYYYYYYY
----

You should also enable MFA for the IAM user (https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa_enable_virtual.html)[see the AWS docs on enabling a virtual MFA device]) and add the configuration to your profile as follows:
[source,bash]
----
mfa_serial=arn:aws:iam::${local.accounts.root}:mfa/<YOUR_IAM_USER>
----

Next, https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html[install the AWS CLI], and check that
authentication is working:

[source,bash]
----
aws-vault exec root-iam-user -- aws sts get-caller-identity
----

You should get JSON output with information about your IAM user:

[source,json]
----
{
  "UserId": "AIDAXXXXXXXXXXXX",
  "Account": "${local.accounts.root}",
  "Arn": "arn:aws:iam::${local.accounts.root}:user/<YOUR_IAM_USER>"
}
----

You're now almost ready to deploy the `account-baseline` module in the root account. But first, you may need to import
some existing resources.

=== Import existing resources from the root account

Before applying the security baseline to the root account, we need to import any existing resources—including the IAM
user you created manually earlier—into Terraform state, so that Terraform manages those existing resources instead of
trying to create totally new ones. You can do this using the
https://www.terraform.io/docs/import/index.html[`import` command], which uses the format:

[source,bash]
----
terraform import <ADDRESS> <ID>
----

Where `<ADDRESS>` is the https://www.terraform.io/docs/internals/resource-addressing.html[address] of the Terraform
resource you're importing and `<ID>` is a resource-specific identifier (e.g., for `aws_instance`, it's the instance ID,
whereas for `aws_lb`, it's the load balancer's name—check the docs for the resource to find out what to use).

As a first example, let's import the IAM user you created manually in the root account. IAM users are managed using the
`aws_iam_user` resource, and the
https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_user#import[documentation for that
resource] tells us to use the user's `name` as the `<ID>`; we'll assume for this example that your IAM user's name was
`alice`, who is already one of the entries in the `users` variable in `terragrunt.hcl`. So now we need the `<ADDRESS>`.
An easy way to get it is to run `plan`:

[source,bash]
----
cd infrastructure-live/prod/_global/account-baseline
aws-vault exec root-iam-user -- terragrunt plan
----

You should get a whole bunch of log output, including something that looks like this:

----
------------------------------------------------------------------------

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create
 <= read (data resources)

Terraform will perform the following actions:

# ... (ommitting lots of log output for simplicity) ...

# module.root_baseline.module.iam_users.aws_iam_user.user["alice"] will be created
  + resource "aws_iam_user" "user" {
      + arn           = (known after apply)
      + id            = (known after apply)
      + name          = "alice"
      + path          = "/"
      + unique_id     = (known after apply)
    }

# ... (ommitting lots of log output for simplicity) ...

Plan: 160 to add, 0 to change, 0 to destroy.

------------------------------------------------------------------------

Note: You didn't specify an "-out" parameter to save this plan, so Terraform
can't guarantee that exactly these actions will be performed if
"terraform apply" is subsequently run.
----

This `plan` output is telling you that Terraform will create a bunch of resources, including the `aws_iam_user` named
`alice`. Of course, this user already exists, so we want to `import` the user rather than create it again. The text
next to the `#` gives you the `<ADDRESS>` to use:

----
# module.root_baseline.module.iam_users.aws_iam_user.user["alice"] will be created
----

So the `<ADDRESS>` you want is `module.root_baseline.module.iam_users.aws_iam_user.user["alice"]`. Now, normally, you'd
run `import` right away, but due two Terraform bugs, https://github.com/hashicorp/terraform/issues/13018[#13018] and
https://github.com/hashicorp/terraform/issues/26211[#26211], `import` doesn't work on certain types of modules—namely,
those with nested `provider` blocks that use dynamic data—and will produce an error like `unknown variable accessed:
var.region in:`. One of these bugs has been open for over 3 years, so we built a workaround for it in Terragrunt: the
https://terragrunt.gruntwork.io/docs/reference/cli-options/#aws-provider-patch[`aws-provider-patch` command].

The idea behind the workaround is to temporarily hard-code the dynamic data in nested `provider` blocks. In particular,
we need to temporarily hard-code some of the `region` and `role_arn` parameters of the nested `provider` blocks used by
`account-baseline-root` as follows:

[source,bash]
----
terragrunt aws-provider-patch \
  --terragrunt-override-attr region="${local.aws_region}" \
  --terragrunt-override-attr assume_role.role_arn=""
----

_Note: You can use any region you want for the `region` parameter. It's just temporary. However, `role_arn` must be set
to an empty string or Terraform will complain._

After running this command, you can finally import your IAM user:

[source,bash]
----
aws-vault exec root-iam-user -- terragrunt import \
  'module.root_baseline.module.iam_users.aws_iam_user.user["alice"]' \
  'alice'
----

You should see log output that looks something like this:

----
[terragrunt] 2021/05/13 14:19:16 Running command: terraform import module.root_baseline.module.iam_users.aws_iam_user.user["alice"] alice
module.root_baseline.module.iam_users.aws_iam_user.user["alice"]: Importing from ID "alice"...
module.root_baseline.module.iam_users.aws_iam_user.user["alice"]: Import prepared!
  Prepared aws_iam_user for import
module.root_baseline.module.iam_users.aws_iam_user.user["alice"]: Refreshing state... [id=alice]

Import successful!

The resources that were imported are shown above. These resources are now in
your Terraform state and will henceforth be managed by Terraform.
----

You'll now be able to manage that IAM user as code going forward!

If you created other resources manually in the root account, you may want to `import` them too, so you can manage
everything as code, and so that Terraform doesn't try to create any duplicate resources.

Once you're done importing, you'll want to undo the `aws-provider-patch` workaround. The easiest way to do that is to
delete the `.terraform` or `.terragrunt-cache` folders to remove any locally cached modules, as they would've been
modified by the `aws-provider-patch` command.

[source,bash]
----
rm -rf .terragrunt-cache
----

[[apply_account_baseline_root]]
=== Apply the security baseline to the root account

You're now ready to apply the security baseline to the root account. You should be authenticated as the same IAM user
in the root account as in the previous two sections. To apply the security baseline, you run `terragrunt apply`:

[source,bash]
----
cd infrastructure-live/prod/_global/account-baseline
aws-vault exec root-iam-user -- terragrunt apply
----

[.exceptional]
IMPORTANT: On some operating systems, such as MacOS, you may also need to increase your open files limit to avoid "pipe: too many open files" errors by running: `ulimit -n 1024`.

Once `apply` completes, you should see output variables with all of your account IDs, the name of the AWS Config S3
bucket, the name of the CloudTrail S3 bucket, and the ARN of the CloudTrail KMS key:

[source,hcl]
----
# (this output has been edited to be easier to read)
child_accounts = {
  "dev" = {
    "email" = "root-accounts+dev@acme.com"
    "id" = "<DEV_ACCOUNT_ID>"
    # (...)
  }
  "logs" = {
    "email" = "root-accounts+logs@acme.com"
    "id" = "<LOGS_ACCOUNT_ID>"
    # (...)
  }
  "prod" = {
    "email" = "root-accounts+prod@acme.com"
    "id" = "<PROD_ACCOUNT_ID>"
    # (...)
  }
  "security" = {
    "email" = "root-accounts+security@acme.com"
    "id" = "<SECURITY_ACCOUNT_ID>"
    # (...)
  }
  "shared-services" = {
    "email" = "root-accounts+shared-services@acme.com"
    "id" = "<SHARED_SERVICES_ACCOUNT_ID>"
    # (...)
  }
  "stage" = {
    "email" = "root-accounts+stage@acme.com"
    "id" = "<STAGE_ACCOUNT_ID>"
    # (...)
  }
}
cloudtrail_kms_key_arn    = "<CLOUDTRAIL_KMS_KEY_ARN>"
cloudtrail_s3_bucket_name = "<CLOUDTRAIL_BUCKET_NAME>"
config_s3_bucket_name     = "<CONFIG_BUCKET_NAME>"
----

Take note of all of this data, as you'll need it again shortly! This is exactly the place where your `common.hcl` comes in handy - add all of these values in there as `locals`.

One other useful output will be the encrypted passwords for any IAM users you created:

[source,hcl]
----
user_passwords = {
  "alice" = "wcBMA7E6Kn/t1YPfAQgAVSXlUzumcs4UyO8E5q099YnnU="
  "bob" = "wcBMA7E6Kn/t1YPfAQgACgbdb1mYtQx7EL4hnVWtYAi="
}
----

Send the encrypted password to each user, along with their user name, and the IAM user sign-in URL for the root account.
Each user can then decrypt the password on their own computer (which should have their PGP key) as follows:

[source,bash]
----
echo "<PASSWORD>" | base64 --decode | keybase pgp decrypt
----

=== Reset the root user password in each child account

When creating the child accounts, you may have noticed that you provided an email address for each root user, but
confusingly, not a password. So how do you login as the root user then? It's not obvious, but the answer is that you
https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys_retrieve.html#reset-root-password[reset the root user password],
using the "Forgot your password?" prompt on the https://console.aws.amazon.com/[root user login page]. AWS will email
you a reset link, which you can click to go to a page that will allow you to configure a password for the root user.
Use this process to reset the password for the root user of each child account you created.

=== Lock down the root user in the child accounts

Once you're able to access the root user of each child account, you should follow the steps in <<lock_down_root_user>>
for each of those child accounts—including enabling MFA and deleting the root user's access keys—and (almost) never use
those root users again.

[[apply_account_baseline_logs]]
=== Apply the `account-baseline-app` baseline to the logs account

The next step is to configure the **logs** account, which is used to aggregate AWS Config and CloudTrail data from all the
other accountss.

Create a `terragrunt.hcl` file in `infrastructure-live` under the file path `logs/_global/account-baseline`:

----
infrastructure-live
  └ prod
  └ logs
    └ _global
      └ account-baseline
        └ terragrunt.hcl
----

Point the `source` URL in your `terragrunt.hcl` file to the `account-baseline-app` module in the https://github.com/gruntwork-io/terraform-aws-cis-service-catalog[terraform-aws-cis-service-catalog]
repo, setting the `ref` param to the version you require:

.infrastructure-live/logs/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
terraform {
  source = "git::git@github.com/gruntwork-io/terraform-aws-cis-service-catalog//modules/landingzone/account-baseline-app?ref=v0.22.0"

  # This module deploys some resources (e.g., AWS Config) across all AWS regions, each of which needs its own provider,
  # which in Terraform means a separate process. To avoid all these processes thrashing the CPU, which leads to network
  # connectivity issues, we limit the parallelism here.
  extra_arguments "parallelism" {
    commands  = get_terraform_commands_that_need_parallelism()
    arguments = ["-parallelism=2"]
  }
}
----

[.exceptional]
IMPORTANT: We **strongly** recommend setting Terraform parallelism to a low value (e.g., `-parallelism=2`), as shown above, with the `account-baseline-xxx` modules. This is because these modules deploy multi-region resources (e.g., GuardDuty, AWS Config, etc), and for each region, Terraform spins up a separate process, so if you don't limit the parallelism, it may peg all your CPU cores and lead to network connectivity errors.

Set the variables for the `account-baseline-app` module in this environment in the `inputs = { ... }` block of `terragrunt.hcl`:

.infrastructure-live/logs/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
locals {
  aws_region = local.aws_region

  accounts = local.accounts

  # Both buckets are created in the logs account by account-baseline-root
  config_s3_bucket_name     = local.config_s3_bucket_name
  cloudtrail_s3_bucket_name = local.cloudtrail_s3_bucket_name

  # The Cloudtrail KMS Key is deployed at the logs account but it's value is an output from the root account.
  cloudtrail_kms_key_arn = "arn:aws:kms:${local.aws_region}:${local.accounts.logs}:alias/${cloudtrail_kms_key_arn}"

  # A local for convenient access to the security account root ARN.
  security_account_root_arn = "arn:aws:iam::${local.accounts.security}:root"
}

inputs = {
  # Fill in the region you want to use (only used for API calls) and the IDs of your AWS accounts (see the locals above)
  aws_region     = local.aws_region
  aws_account_id = local.accounts.logs

  # Prefix all resources with this name
  name_prefix = "acme-logs"
 ################################
  # Parameters for AWS Config
  ################################
  # Send Config logs to the common S3 bucket.
  config_s3_bucket_name = local.config_s3_bucket_name

  # Send Config logs and events to the logs account.
  config_central_account_id = local.accounts.logs

  #  This is the Logs account, so we create the SNS topic for aggregating Config logs from all accounts.
  config_should_create_sns_topic = true

  # All of the other accounts send logs to this account.
  config_linked_accounts = [
  for name, id in local.accounts :
    id if name != "logs"
  ]

  ################################
  # Parameters for CloudTrail
  ################################

  # Send CloudTrail logs to the common S3 bucket.
  cloudtrail_s3_bucket_name = local.cloudtrail_s3_bucket_name

  # All of the other accounts send logs to this account.
  cloudtrail_allow_kms_describe_key_to_external_aws_accounts = true
  cloudtrail_external_aws_account_ids_with_write_access = [
  for name, id in local.accounts :
    id if name != "logs"
  ]

  # The ARN is a key alias, not a key ID. This variable prevents a perpetual diff when using an alias.
  cloudtrail_kms_key_arn_is_alias = true

  # By granting access to the root ARN of the Logs account, we allow administrators to further delegate to access
  # other IAM entities
  cloudtrail_kms_key_administrator_iam_arns = ["arn:aws:iam::${local.accounts.logs}:root"]
  cloudtrail_kms_key_user_iam_arns          = ["arn:aws:iam::${local.accounts.logs}:root"]

  ##################################
  # Benchmark SNS alarms configuration
  ##################################

  # Create the alarms topic in the logs account
  cloudtrail_benchmark_alarm_sns_topic_already_exists = false
  cloudtrail_benchmark_alarm_sns_topic_name           = "BenchmarkAlarmTopic"

  ##################################
  # Cross-account IAM role permissions
  ##################################

  # A role to allow users that can view and modify AWS account billing information.
  allow_billing_access_from_other_account_arns = [local.security_account_root_arn]

  # A role that allows read only access.
  allow_read_only_access_from_other_account_arns = [local.security_account_root_arn]

  # A role that allows access to support only.
  allow_support_access_from_other_account_arns = [local.security_account_root_arn]

  security_hub_associate_to_master_account_id = local.accounts.root
}
----

The example above configures the logs account of an AWS Organization as follows:

. **Aggregate CloudTrail Logs**: We configure the logs account to use the S3 bucket and KMS CMK for CloudTrail that
were already created by `account-baseline-root`.

. **Aggregate AWS Config**: We configure the logs account to use the S3 bucket for AWS Config that was already
created by `account-baseline-root`.

. **Allow access from the security account**: We configure IAM roles that IAM users in the security account will be
able to assume to get access to the logs account.

Configure your Terraform backend:

.infrastructure-live/logs/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
include {
  path = find_in_parent_folders()
}
----

You're now going to use an IAM role to authenticate to the logs account. This IAM role is created automatically in each
child account by `account-baseline-root` and has a default name of `OrganizationAccountAccessRole`. There are many ways
to https://blog.gruntwork.io/a-comprehensive-guide-to-authenticating-to-aws-on-the-command-line-63656a686799[assume an IAM role on the CLI];
for this guide, we're going to keep using `aws-vault`.

Open up `~/.aws/config` and you should see a `profile` that was created automatically when you ran
`aws-vault add root-iam-user`  earlier:

[source,text]
----
[profile root-iam-user]
----

Add a new `profile` entry in `~/.aws/config` for your logs account that uses the `root-iam-user` as the
`source_profile`:

[source,text]
----
[profile logs-from-root]
role_arn=arn:aws:iam::${local.accounts.logs}:role/OrganizationAccountAccessRole
source_profile=root-iam-user
----

Check that you're able to authenticate to the logs account:

[source,bash]
----
aws-vault exec logs-from-root -- aws sts get-caller-identity
----

You should see JSON output indicating that you've successfully assumed an IAM role:

[source,json]
----
{
  "UserId": "AIDAXXXXXXXXXXXX:1111111111111111111",
  "Account": "${local.accounts.logs}",
  "Arn": "arn:aws:sts::${local.accounts.logs}:assumed-role/OrganizationAccountAccessRole/1111111111111111111"
}
----

You're now ready to deploy the `account-baseline-app` in the logs account by running `terragrunt apply`:

[source,bash]
----
cd infrastructure-live/logs/_global/account-baseline
aws-vault exec logs-from-root -- terragrunt apply
----

[.exceptional]
IMPORTANT: On some operating systems, such as MacOS, you may also need to increase your open files limit to avoid "pipe: too many open files" errors by running: `ulimit -n 1024`.

[[apply_account_baseline_security]]
=== Apply the `account-baseline-security` to the security account

Now that your logs accounts is fully configured, you need to apply the security baseline to the security account, which
is where all your IAM users and groups will be defined and managed.

Create a `terragrunt.hcl` file in `infrastructure-live` under the file path `security/_global/account-baseline`:

----
infrastructure-live
  └ root
  └ logs
  └ security
    └ _global
      └ account-baseline
        └ terragrunt.hcl
----

Point the `source` URL in your `terragrunt.hcl` file to the `account-baseline-security` module in the https://github.com/gruntwork-io/terraform-aws-cis-service-catalog[terraform-aws-cis-service-catalog]
repo, setting the `ref` param to the version you require:

.infrastructure-live/security/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
terraform {
  source = "git::git@github.com/gruntwork-io/terraform-aws-cis-service-catalog//modules/landingzone/account-baseline-security?ref=v0.22.0"

  # This module deploys some resources (e.g., AWS Config) across all AWS regions, each of which needs its own provider,
  # which in Terraform means a separate process. To avoid all these processes thrashing the CPU, which leads to network
  # connectivity issues, we limit the parallelism here.
  extra_arguments "parallelism" {
    commands  = get_terraform_commands_that_need_parallelism()
    arguments = ["-parallelism=2"]
  }
}
----

[.exceptional]
IMPORTANT: We **strongly** recommend setting Terraform parallelism to a low value (e.g., `-parallelism=2`), as shown above, with the `account-baseline-xxx` modules. This is because these modules deploy multi-region resources (e.g., GuardDuty, AWS Config, etc), and for each region, Terraform spins up a separate process, so if you don't limit the parallelism, it may peg all your CPU cores and lead to network connectivity errors.

Set the variables for the `account-baseline-security` module in this environment in the `inputs = { ... }` block of `terragrunt.hcl`:

.infrastructure-live/security/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
locals {
  aws_region = local.aws_region

  accounts = local.accounts

  # Both buckets are created in the logs account by account-baseline-root
  config_s3_bucket_name     = local.config_s3_bucket_name
  cloudtrail_s3_bucket_name = local.cloudtrail_s3_bucket_name

  # The Cloudtrail KMS Key is deployed at the logs account but it's value is an output from the root account.
  cloudtrail_kms_key_arn = "arn:aws:kms:${local.aws_region}:${local.accounts.logs}:alias/${cloudtrail_kms_key_arn}"

  # A local for convenient access to the security account root ARN.
  security_account_root_arn = "arn:aws:iam::${local.accounts.security}:root"
}
input = {
  # Fill in the region you want to use (only used for API calls) and the IDs of your AWS accounts (see the locals above)
  aws_region     = local.aws_region
  aws_account_id = local.accounts.security

  # Prefix all resources with this name
  name_prefix = "acme-security"

  ################################
  # Parameters for AWS Config
  ################################
  # Send Config logs to the common S3 bucket.
  config_s3_bucket_name = local.config_s3_bucket_name

  # Send Config logs and events to the logs account.
  config_central_account_id = local.accounts.logs

  # This account sends logs to the Logs account.
  config_aggregate_config_data_in_external_account = true

  # The ID of the Logs account.
  config_central_account_id = local.accounts.logs

  ################################
  # Parameters for CloudTrail
  ################################

  # Send CloudTrail logs to the common S3 bucket.
  cloudtrail_s3_bucket_name = local.cloudtrail_s3_bucket_name

  # The CloudTrail bucket is created in the logs account, so don't create it here.
  cloudtrail_s3_bucket_already_exists = true

  # Encrypt CloudTrail logs using a common KMS key.
  cloudtrail_kms_key_arn = local.cloudtrail_kms_key_arn

  # The ARN is a key alias, not a key ID. This variable prevents a perpetual diff when using an alias.
  cloudtrail_kms_key_arn_is_alias = true

  ##################################
  # Benchmark SNS alarms configuration
  ##################################

  # The ARN of an SNS topic for sending alarms about CIS Benchmark compliance issues.
  # The topic exists in the logs account
  cloudtrail_benchmark_alarm_sns_topic_arn = "arn:aws:sns:${local.aws_region}:${local.accounts.logs}:BenchmarkAlarmTopic"
  ##################################
  # Cross-account IAM role permissions
  ##################################

  # Create groups that allow IAM users in this account to assume roles in your other AWS accounts.
  iam_groups_for_cross_account_access = local.cross_account_groups.cross_account_groups

  # Allow these accounts to have read access to IAM groups and the public SSH keys of users in the group.
  allow_ssh_grunt_access_from_other_account_arns = [
    for name, id in local.accounts :
      "arn:aws:iam::${id}:root" if name != "security"
  ]

  # IAM users
  users = {
    alice = {
      groups               = ["user-self-mgmt", "ssh-sudo-users"]
      pgp_key              = "keybase:alice_on_keybase"
      create_login_profile = true
      create_access_keys   = false
    }

    bob = {
      groups               = ["user-self-mgmt", "_account.prod-read-only"]
      pgp_key              = "keybase:bob_on_keybase"
      create_login_profile = true
      create_access_keys   = false
    }
  }

  security_hub_associate_to_master_account_id = local.accounts.root
}
----

The code above does the following:

. **Enable Guard Duty**. We've configured AWS Guard Duty for all enabled regions in compliance with CIS.

. **Enable CloudTrail**. We've configured CloudTrail across all enabled regions to use the S3 bucket and KMS CMK in the logs account.

. **Enable AWS Config**. We've configured AWS Config for all enabled regions and set it up to use the S3 bucket in the logs account.

. **Create IAM groups**. We've created IAM groups, both for permissions within the security account (e.g.,
`iam-admin` grants IAM admin permissions in the security account) and for permissions in other accounts (e.g.,
`ssh-grunt-users` enables users to ssh into an EC2 instance running `ssh-grunt` in a any AWS Account).

. **Create IAM users**. The example above creates IAM users for `alice`, `bob` and assigns them to
the various IAM groups. You should create an IAM user for yourself in the `full-access` group, plus IAM users for the
rest of your team in the appropriate groups. Like the root account, the code will also generate a password for each
user and encrypt it with that user’s PGP key from Keybase (see below for how to handle the passwords).

. **Create IAM Cross Account IAM roles**. We've configured IAM cross account IAM roles that will allow you to authenticate using the IAM users and roles in other AWS Accounts that have been configured with the Landing Zone setup shown in this guide.

. **Create IAM User Password Policy**. We've configured the IAM user password policy to be compliant with CIS 1.3.

. **Create a function to cleanup expired TLS certificates**. We've setup a lambda function to monitor your SSL/TLS certificates and clean them up when they've expired. This is enforced by CIS requirement 1.19.

. **Enable Security Hub**. We've enabled Security Hub across all enabled regions. For this feature to work, the `master` Security Hub account (usually the Account that has the AWS Organizations, in this case `root`) will have to invite the `members` accounts, and the `members` accounts also have to accept the invitation. This is currently done programmatically, not via `terraform`.

Configure your Terraform backend:

.infrastructure-live/security/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
include {
  path = find_in_parent_folders()
}
----

Just as with the logs account, you're going to use the `OrganizationAccountAccessRole` IAM role created by
`account-baseline-root` to authenticate to the security account. There are many ways to
https://blog.gruntwork.io/a-comprehensive-guide-to-authenticating-to-aws-on-the-command-line-63656a686799[assume an IAM role on the CLI];
for this guide, we're going to keep using `aws-vault`.

Add a new `profile` entry in `~/.aws/config` for your security account that uses the `root-iam-user` as the
`source_profile`:

[source,text]
----
[profile security-from-root]
role_arn=arn:aws:iam::${local.accounts.security}:role/OrganizationAccountAccessRole
source_profile=root-iam-user
----

Check that you're able to authenticate to the security account:

[source,bash]
----
aws-vault exec security-from-root -- aws sts get-caller-identity
----

You should see JSON output indicating that you've successfully assumed an IAM role:

[source,json]
----
{
  "UserId": "AIDAXXXXXXXXXXXX:1111111111111111111",
  "Account": "${local.accounts.security}",
  "Arn": "arn:aws:sts::${local.accounts.security}:assumed-role/OrganizationAccountAccessRole/1111111111111111111"
}
----

You're now ready to deploy the `account-baseline` module in the security account by running `terragrunt apply`:

[source,bash]
----
cd infrastructure-live/security/_global/account-baseline
aws-vault exec security-from-root -- terragrunt apply
----

[.exceptional]
IMPORTANT: On some operating systems, such as MacOS, you may also need to increase your open files limit to avoid "pipe: too many open files" errors by running: `ulimit -n 1024`.

When `apply` finishes, the module will output the encrypted passwords for the users defined above. Send the encrypted
password to each user, along with their user name, and the IAM user sign-in URL for the account. Each user can then
decrypt the password on their own computer (which should have their PGP key) as follows:

[source,bash]
----
echo "<PASSWORD>" | base64 --decode | keybase pgp decrypt
----


=== Apply the `account-baseline-app` to the other child accounts

Now that your **security** account is fully configured, you need to apply the security baseline to the remaining child
accounts (e.g., dev, stage, prod, shared-services). Feel free to adjust this as necessary based on the accounts your
company needs.

Create `terragrunt.hcl` files in `infrastructure-live` under the file paths `<ACCOUNT>/_global/account-baseline`,
where `<ACCOUNT>` is one of these other child accounts, such as `dev`, `stage`, `prod`, and `shared-services`. In the rest of
this example, we’ll look solely at the stage account, but make sure you follow the analogous steps for EACH of your
child accounts.

----
infrastructure-live
  └ root
  └ logs
  └ security
  └ stage
    └ _global
      └ account-baseline
        └ terragrunt.hcl
----

Point the `source` URL in your `terragrunt.hcl` file to the `account-baseline-app` module in the https://github.com/gruntwork-io/terraform-aws-cis-service-catalog[terraform-aws-cis-service-catalog]
repo, setting the `ref` param to the version you require:

.infrastructure-live/stage/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
terraform {
  source = "git::git@github.com/gruntwork-io/terraform-aws-cis-service-catalog//modules/landingzone/account-baseline-app?ref=v0.22.0"

  # This module deploys some resources (e.g., AWS Config) across all AWS regions, each of which needs its own provider,
  # which in Terraform means a separate process. To avoid all these processes thrashing the CPU, which leads to network
  # connectivity issues, we limit the parallelism here.
  extra_arguments "parallelism" {
    commands  = get_terraform_commands_that_need_parallelism()
    arguments = ["-parallelism=2"]
  }
}
----

[.exceptional]
IMPORTANT: We **strongly** recommend setting Terraform parallelism to a low value (e.g., `-parallelism=2`), as shown above, with the `account-baseline-xxx` modules. This is because these modules deploy multi-region resources (e.g., GuardDuty, AWS Config, etc), and for each region, Terraform spins up a separate process, so if you don't limit the parallelism, it may peg all your CPU cores and lead to network connectivity errors.

Set the variables for the `account-baseline-app` module in this environment in the `inputs = { ... }` block of `terragrunt.hcl`:

.infrastructure-live/stage/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
locals {
  aws_region = local.aws_region

  accounts = local.accounts

  # Both buckets are created in the logs account by account-baseline-root
  config_s3_bucket_name     = local.config_s3_bucket_name
  cloudtrail_s3_bucket_name = local.cloudtrail_s3_bucket_name

  # The Cloudtrail KMS Key is deployed at the logs account but it's value is an output from the root account.
  cloudtrail_kms_key_arn = "arn:aws:kms:${local.aws_region}:${local.accounts.logs}:alias/${local.cloudtrail_kms_key_arn}"

  # A local for convenient access to the security account root ARN.
  security_account_root_arn = "arn:aws:iam::${local.accounts.security}:root"
}

inputs = {
  # Fill in the region you want to use (only used for API calls) and the IDs of your AWS accounts (see the locals above)
  aws_region     = local.aws_region
  aws_account_id = local.accounts.stage

  # Prefix all resources with this name
  name_prefix = "stage-logs"
 ################################
  # Parameters for AWS Config
  ################################
  # Send Config logs to the common S3 bucket.
  config_s3_bucket_name = local.config_s3_bucket_name

  # Send Config logs and events to the logs account.
  config_central_account_id = local.accounts.logs

  # This account sends logs to the Logs account.
  config_aggregate_config_data_in_external_account = true

  # The ID of the Logs account.
  config_central_account_id = local.accounts.logs

  ################################
  # Parameters for CloudTrail
  ################################

  # Send CloudTrail logs to the common S3 bucket.
  cloudtrail_s3_bucket_name = local.cloudtrail_s3_bucket_name

  # Encrypt CloudTrail logs using a common KMS key.
  cloudtrail_kms_key_arn = local.cloudtrail_kms_key_arn

  # The ARN is a key alias, not a key ID. This variable prevents a perpetual diff when using an alias.
  cloudtrail_kms_key_arn_is_alias = true
  ##################################
  # Benchmark SNS alarms configuration
  ##################################

  # The ARN of an SNS topic for sending alarms about CIS Benchmark compliance issues.
  # The topic exists in the logs account
  cloudtrail_benchmark_alarm_sns_topic_arn = "arn:aws:sns:${local.aws_region}:${local.accounts.logs}:BenchmarkAlarmTopic"

  ##################################
  # Cross-account IAM role permissions
  ##################################
  # A role to allow users that can view and modify AWS account billing information.
  allow_billing_access_from_other_account_arns = [local.security_account_root_arn]

  # A role that allows read only access.
  allow_read_only_access_from_other_account_arns = [local.security_account_root_arn]

  # A role that allows access to support only.
  allow_support_access_from_other_account_arns = [local.security_account_root_arn]

  service_linked_roles = ["autoscaling.amazonaws.com"]

  ##################################
  # KMS grants
  ##################################

  # These grants allow the autoscaling service-linked role to access to the AMI encryption key so that it
  # can launch instances from AMIs that were shared from the shared-services account.
  kms_grant_regions = {
    ami_encryption_key = local.aws_region
  }
  kms_grants = {
    ami_encryption_key = {
      kms_cmk_arn       = "arn:aws:kms:${local.aws_region}:${local.accounts.shared}:alias/ami-encryption"
      grantee_principal = "arn:aws:iam::${local.accounts[local.account_name]}:role/aws-service-role/autoscaling.amazonaws.com/AWSServiceRoleForAutoScaling"
      granted_operations = [
        "Encrypt",
        "Decrypt",
        "ReEncryptFrom",
        "ReEncryptTo",
        "GenerateDataKey",
        "DescribeKey"
      ]
    }
  }

  security_hub_associate_to_master_account_id = local.accounts.root
}
----

The code above does the following:

. **Enable CloudTrail**. We've configured CloudTrail to use the S3 bucket and KMS CMK in the logs account.

. **Enable AWS Config**. We've configured AWS Config to use the S3 bucket in the logs account.

. **Configure the dev IAM role**. We create a `dev` IAM role in this account, which will get read and write access to
the services specified in `dev_permitted_services`.

. **Configure the Auto Deploy IAM role**. We also create an `auto-deploy` IAM role that can be assumed by a CI server
in the shared-services account to do deployments. This role will have the permissions specified in
`auto_deploy_permissions`.

. **Configure cross-account IAM roles**. We then specify which other accounts are allowed to assume the IAM roles in
this account. For the most part, we grant all permissions to the security account, so that by assigning users to IAM
groups in that account, you'll be able to access IAM roles in all the other child accounts.

Configure your Terraform backend:

.infrastructure-live/stage/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
include {
  path = find_in_parent_folders()
}
----

Just as with the **logs** and **security** accounts, you're going to use the `OrganizationAccountAccessRole` IAM role created by
`account-baseline-root` to authenticate to the stage account and all other child accounts. There are many ways to
https://blog.gruntwork.io/a-comprehensive-guide-to-authenticating-to-aws-on-the-command-line-63656a686799[assume an IAM role on the CLI];
for this guide, we're going to keep using `aws-vault`.

Add a new `profile` entry in `~/.aws/config` for your stage account that uses the `root-iam-user` as the
`source_profile`:

[source,text]
----
[profile stage-from-root]
role_arn=arn:aws:iam::${local.accounts.stage}:role/OrganizationAccountAccessRole
source_profile=root-iam-user
----

Check that you're able to authenticate to the stage account:

[source,bash]
----
aws-vault exec stage-from-root -- aws sts get-caller-identity
----

You should see JSON output indicating that you've successfully assumed an IAM role:

[source,json]
----
{
  "UserId": "AIDAXXXXXXXXXXXX:1111111111111111111",
  "Account": "${local.accounts.stage}",
  "Arn": "arn:aws:sts::${local.accounts.stage}:assumed-role/OrganizationAccountAccessRole/1111111111111111111"
}
----

You're now ready to deploy the `account-baseline-app` in the **stage** account by running `terragrunt apply`:

[source,bash]
----
cd infrastructure-live/stage/_global/account-baseline
aws-vault exec stage-from-root -- terragrunt apply
----

[.exceptional]
IMPORTANT: On some operating systems, such as MacOS, you may also need to increase your open files limit to avoid "pipe: too many open files" errors by running: `ulimit -n 1024`.

Remember to repeat this process in the other child accounts too (i.e., dev, prod, shared-services, etc)!

=== Try authenticating as an IAM user to the child accounts

Now that you have IAM users in the security account and IAM roles in the other accounts, it's time to practice
authenticating:

. Use your IAM user's user name and password (decrypted using keybase) to log into the web console of the security
  account (remember to use the IAM user sign-in URL for the security account).
. Follow the steps in <<lock_down_iam_users>> to lock down your IAM user in the security account. This includes
  configuring an MFA device for your IAM user.
. After configuring an MFA device, log out, and then log back into the security account again, this time providing your
  MFA token. If you don't do this, attempting to assume IAM roles in other accounts won't work, as those roles require
  an MFA token to be present.
. Try to https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-console.html[switch to a role] in
  one of the other child accounts using the AWS Web Console. For example, authenticate as one of the IAM users in the
  security account, and then assume the `allow-full-access-from-other-accounts` role in the dev account (you can find
  the default list of IAM roles created in each account
  https://github.com/gruntwork-io/module-security/tree/master/modules/cross-account-iam-roles#resources-created[here]).
. Alternatively, you can use the `aws-vault login xxx` command to login to the AWS Web Console for any profile `xxx`
  that you've configured in `aws-vault`. For example, `aws-vault login logs-from-root` will open up your web browser
  and log you into the logs account using the `OrganizationAccountAccessRole` IAM Role.

[[configure_security_hub]]
=== Configure AWS Security Hub in the root account

Next, we'll configure link:https://aws.amazon.com/security-hub/[AWS Security Hub] in the root account. AWS Security Hub
is deployed by the account baselines in every enabled region of an AWS account to check your account link:https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-standards.html[for compliance]
with the AWS CIS Foundations Benchmark. The Security Hub runs the exact audit steps specified in the Benchmark using AWS
Config managed rules. _Note: Security Hub is not explicitly required by the Benchmark, however we suggest enabling it,
so you can track your compliance efforts and be notified if any recommendations have not been implemented._

In order to ensure the Security Hub dashboard shows a positive score, you will need to follow these link:https://gruntwork.io/guides/compliance/how-to-achieve-cis-benchmark-compliance/#identity-and-access-management-2[Manual Steps]
to complete CIS compliance. These steps cannot be automated using AWS APIs. Additionally, in the AWS Console UI, AWS Security
Hub will show a low security score for the CIS AWS Foundations Benchmark v1.2.0. This is due to AWS limitations on
checking compliance standards for cross-region/cross-account rules. This does not indicate that the accounts are not in
compliance; it is a failure of the AWS audit tool. Note also that the accounts are configured for the latest version of
the benchmark, v1.3.0; the AWS Security Hub does not support this version at the current time.

[[iam_roles_for_instances]]
=== Use IAM roles for EC2 instances
All Gruntwork modules that require AWS API access use roles rather than an IAM user with static API credentials for
authentication. For example:

* link:https://github.com/gruntwork-io/terraform-aws-server/blob/master/modules/single-server/main.tf[`terraform-aws-server`]
 is used to manage a single EC2 instance with an IAM role attached.
* link:https://github.com/gruntwork-io/terraform-aws-asg[`terraform-aws-asg`] applies IAM roles to instances in auto-scaling
 group.
* link:https://github.com/gruntwork-io/terraform-aws-eks/blob/master/modules/eks-cluster-workers/main.tf[`terraform-aws-eks`]
 uses IAM roles for EKS cluster workers.
* link:https://github.com/gruntwork-io/terraform-aws-ecs/tree/master/modules/ecs-cluster[`ecs-cluster`] creates IAM
 roles for ECS instances
* link:https://github.com/gruntwork-io/terraform-aws-lambda/tree/master/modules/lambda[`lambda`] creates IAM
 roles for Lambda functions

Use these modules whenever possible. You should always use IAM roles in your own modules any time you need to provide
access to the AWS API. Using static API credentials should be avoided whenever possible.

[[maintain_compliance_iam]]
=== Maintaining compliance by following IAM best practices
We conclude the IAM section with a few parting words of wisdom for maintaining compliance over time:

. Do not attach any policies without requiring MFA.
. Never use the `AdministratorAccess` AWS managed policy with any users, groups, or roles.
. Refrain from granting inline permissions or attaching managed policies directly to IAM users. Permissions
should be granted exclusively via IAM groups and roles.
. Never use static IAM user access keys to allow an application to access AWS, whether that application is hosted on an EC2 instance or anywhere else!
. Avoid logging in as the root user. Unfortunately, there is nothing built-in to AWS to prevent use of the
root user. It cannot be locked or removed from the account. In fact, there are
link:https://docs.aws.amazon.com/general/latest/gr/aws_tasks-that-require-root.html[several tasks that require
the use of root].  Fortunately, most of these activities are rare, so usage of the root account can be kept to
a minimum.

[[maintain_compliance_storage]]
=== Maintaining compliance by following Storage best practices

[[s3_buckets_deployment]]
==== S3 Buckets
To make sure your S3 buckets are compliant with the benchmark, use the
link:https://github.com/gruntwork-io/terraform-aws-security/tree/master/modules/private-s3-bucket[`private-s3-bucket` module]
to create and manage all of your S3 buckets. This module blocks public access and enforces encryption by default. Note
that all Gruntwork modules that create S3 buckets use this module under the hood.

You can either use the `private-s3-bucket` module in your own modules, or, if you wish to deploy a standalone S3 bucket, use the https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/modules/data-stores/s3-bucket/[`s3-bucket` service]
from the Gruntwork Service Catalog.

[[maintain_compliance_logging]]
=== Maintaining compliance by following Logging best practices

The logging section of the Benchmark includes configurations for CloudTrail, AWS Config, KMS keys, and VPC
flow logs.

[[kms]]
==== Enable key rotation for KMS keys
To make sure your KMS keys are compliant with the benchmark, use the
link:https://github.com/gruntwork-io/terraform-aws-security/blob/master/modules/kms-master-key/README.md[`kms-master-key` module]
to create KMS keys with key rotation enabled by default.

[[vpc_flow_logs]]
== Create VPC flow logs
The Benchmark recommends enabling link:https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html[VPC Flow Logs]
for all VPCs in all regions. You can use the
link:https://github.com/gruntwork-io/terraform-aws-cis-service-catalog/blob/master/modules/networking/vpc[`vpc` service]
in the AWS CIS Service Catalog to create your VPCs. This service is configured for CIS compliance, and as such has VPC flow
logs enabled. See the examples below:

.infrastructure-live/prod/us-east-1/prod/networking/vpc/terragrunt.hcl
[source,hcl]
----
# ---------------------------------------------------------------------------------------------------------------------
# MODULE PARAMETERS
# These are the variables we have to pass in to use the module specified in the terragrunt configuration above
# ---------------------------------------------------------------------------------------------------------------------
inputs = {
  vpc_name         = "app"
  num_nat_gateways = 1
  cidr_block       = local.cidr_block
  kms_key_user_iam_arns = [
    "arn:aws:iam::${local.common_vars.locals.accounts[local.account_name]}:root",
  ]
  eks_cluster_names    = ["${local.name_prefix}-${local.account_name}"]
  tag_for_use_with_eks = true

  allow_administrative_remote_access_cidrs_public_subnets = merge(
    {
      for cidr in local.common_vars.locals.ip_allow_list
      : index(local.common_vars.locals.ip_allow_list, cidr) => cidr
    },
    { length(local.common_vars.locals.ip_allow_list) = local.cidr_block }
  )
}
----

In here you'll still need to reference the `locals` configuration, and ensure that you're setting the right `source` to the module, so add this to your `terragrunt.hcl` file too:

[source,hcl]
----
# Terragrunt will copy the Terraform configurations specified by the source parameter, along with any files in the
# working directory, into a temporary folder, and execute your Terraform commands in that folder. If you're iterating
# locally, you can use --terragrunt-source /path/to/local/checkout/of/module to override the source parameter to a
# local check out of the module for faster iteration.
terraform {
  # We're using a local file path here just so our automated tests run against the absolute latest code. However, when
  # using these modules in your code, you should use a Git URL with a ref attribute that pins you to a specific version:
  # source = "git::git@github.com:gruntwork-io/terraform-aws-cis-service-catalog.git//modules/networking/vpc?ref=v0.20.0"
  source = "${get_parent_terragrunt_dir()}/../../..//modules/networking/vpc"
}

# Include all settings from the root terragrunt.hcl file
include {
  path = find_in_parent_folders()
}

# ---------------------------------------------------------------------------------------------------------------------
# Locals are named constants that are reusable within the configuration.
# ---------------------------------------------------------------------------------------------------------------------
locals {
  # Automatically load common variables shared across all accounts
  common_vars = read_terragrunt_config(find_in_parent_folders("common.hcl"))

  # Extract the name prefix for easy access
  name_prefix = local.common_vars.locals.name_prefix

  # Automatically load account-level variables
  account_vars = read_terragrunt_config(find_in_parent_folders("account.hcl"))

  # Extract the account_name for easy access
  account_name = local.account_vars.locals.account_name

  # Automatically load region-level variables
  region_vars = read_terragrunt_config(find_in_parent_folders("region.hcl"))

  # Extract the region for easy access
  aws_region = local.region_vars.locals.aws_region

  cidr_block = local.common_vars.locals.app_vpc_cidrs[local.account_name]
}
----

To limit the number of flow logs, you may want to use the
link:https://github.com/gruntwork-io/cloud-nuke[`cloud-nuke defaults-aws`] command. It will remove the default VPC from
all regions in an account, saving you the hassle of creating flow logs in each default VPC.

[[maintain_compliance_monitoring]]
=== Maintaining compliance by following Monitoring best practices
The Monitoring section of the Benchmark centers on a collection of
link:https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/MonitoringLogData.html[CloudWatch Logs Metric
Filters]. Gruntwork has simplified this section to a single module: the
link:https://github.com/gruntwork-io/terraform-aws-cis-service-catalog/blob/master/modules/cloudwatch-logs-metric-filters/README.adoc[`cloudwatch-logs-metric
-filters` wrapper module]. It will create and configure all the CloudWatch Logs metric filters necessary for
compliance with the Benchmark. Note that when you deploy the CIS account baseline modules, the CloudWatch Logs metric
filters will be created and configured automatically, so that you don't have to do anything special to enable the metric filters on the
deployed CloudTrail configuration.

Note that you must have a subscriber on the SNS topic to be compliant. Refer to <<subscribe_sns>> for details on how to
setup a subscriber to the SNS topics that are created.

[[maintain_compliance_networking]]
=== Maintaining compliance by following Networking best practices

To ensure all the networking recommendations are satisfied, use the
link:https://github.com/gruntwork-io/terraform-aws-cis-service-catalog/tree/master/modules/networking/vpc[`vpc`] (and/or
link:https://github.com/gruntwork-io/terraform-aws-cis-service-catalog/tree/master/modules/networking/vpc-mgmt[`vpc-mgmt`])
service from Gruntwork's AWS CIS Service Catalog to create all your VPCs. These services are specifically configured for
CIS compliance, and as such they don't allow security groups to access ports 22 or 3389 from the world. In addition,
our architecture has a least-privileges-based routing configuration by default.

To meet the 5.1 recommendation, you'll need to provide values for the `allow_administrative_remote_access_*` variables
when creating VPCs. These variables are used to create appropriate Network ACL Rules. For example, you might create a
VPC using the `vpc` service from `terraform-aws-cis-service-catalog`:

----
infrastructure-live
└── prod
    └── us-east-1
        └── prod
            └─ networking
                └─ vpc
                    └─ terragrunt.hcl
----

.infrastructure-modules/networking/vpc/myvpc/main.tf
[source,hcl]
----
terraform { # We're using a local file path here just so our automated tests run against the absolute latest code. However, when
  # using these modules in your code, you should use a Git URL with a ref attribute that pins you to a specific version:
  # source = "git::git@github.com:gruntwork-io/terraform-aws-cis-service-catalog.git//modules/networking/vpc-mgmt?ref=v0.20.0"
  source = "${get_parent_terragrunt_dir()}/../../..//modules/networking/vpc-mgmt"
----
[source, hcl]
----
inputs = {
  vpc_name         = "mgmt"
  num_nat_gateways = 1
  cidr_block       = local.cidr_block
  kms_key_user_iam_arns = [
    "arn:aws:iam::${local.common_vars.locals.accounts[local.account_name]}:root",
  ]

  # Next, pass values for the allow_administrative_remote_access_* variables, thus creating the NACL rules under the hood
  allow_administrative_remote_access_cidrs_private_app_subnets         = { all_app_vpc_cidrs  = module.vpc.vpc_cidr_block }
  allow_administrative_remote_access_cidrs_private_persistence_subnets = { all_app_vpc_cidrs  = module.vpc.vpc_cidr_block }

  allow_administrative_remote_access_cidrs_public_subnets = merge(
    {
      for cidr in local.common_vars.locals.ip_allow_list
      : index(local.common_vars.locals.ip_allow_list, cidr) => cidr
    },
    { length(local.common_vars.locals.ip_allow_list) = local.cidr_block }
  )
}
----

Refer to the https://github.com/gruntwork-io/terraform-aws-cis-service-catalog/tree/master/examples/for-learning-and-testing/networking/vpc/terraform[terraform-aws-cis-service-catalog]
repo for a more comprehensive example.

Finally, run the link:https://github.com/gruntwork-io/cloud-nuke[`cloud-nuke defaults-aws`] command to remove all
default security groups from all VPCs in all regions.

[[next_steps]]
== Next steps

Congratulations! If you've made it this far, you should have achieved compliance with the CIS AWS Foundations
Benchmark. Now it's time to confirm that your configurations are correct and you didn't miss any steps.
 +
 +


[[traceability_matrix]]
== Traceability matrix
Use the table below as a quick reference to map the CIS AWS Foundations Benchmark recommendations to the
sections above.

[cols="^1,<10,15",format=csv,separator=;]
|===
#;Section;Description
1.1;<<security_questions>>;Complete the contact details on the AWS account page
1.2;<<security_questions>>;Complete the security contact information on the AWS account page
1.3;<<security_questions>>;Answer the security questions on the AWS account page
1.4;<<configure_security_hub>>;Use the Gruntwork Security Hub module to enable AWS Security Hub to ensure you are notified if the root user has access keys set
1.5;<<root_mfa>>;Manually configure MFA for the root user
1.6;<<root_mfa>>;Use a Yubikey (or other hardware MFA) for the root user
1.7;<<manual_steps>>;Take manual steps to complete this recommendation
1.8-9;<<apply_account_baseline_security>>;Use the `account-baseline-security` module to set up the IAM password policy
1.10;<<configure_authentication>>;Configure authentication using SAML or IAM
1.11;<<apply_account_baseline_security>>;Use the `account-baseline-security` module to create users
1.12;<<apply_account_baseline_root>>, <<apply_account_baseline_security>>, <<apply_account_baseline_logs>>;Use the `account-basline-*` modules to set up your accounts. This will ensure that there are no unused credentials
1.13;<<apply_account_baseline_root>>, <<apply_account_baseline_security>>, <<apply_account_baseline_logs>>;Use the `account-basline-*` modules to set up your accounts. This will ensure that there are no extra access keys
1.14;<<apply_account_baseline_root>>, <<apply_account_baseline_security>>, <<apply_account_baseline_logs>>;Use the `account-basline-*` modules to set up your accounts. This will ensure that there are no unused access keys
1.15;<<apply_account_baseline_security>>;Use the `account-baseline-security` module to create users and groups
1.16;<<apply_account_baseline_security>>;Use the `account-baseline-security` module to ensure no full-access policies are attached to any groups or users
1.17;<<apply_account_baseline_security>>;Use the `account-baseline-security` module to create a support group
1.18;<<iam_roles_for_instances>>;Use Gruntwork modules to ensure EC2 instances use roles for access
1.19;<<cleanup_expired_certs>>;Use Gruntwork modules to automatically remove expired certificates from IAM
1.20;<<s3_buckets_deployment>>;Use the `private-s3-bucket` module
1.21;<<iam_access_analyzer>>;Use Gruntwork modules to enable IAM Access Analyzer across regions
1.22;<<account_structure>>;Use the security AWS account as described in the Gruntwork production-grade AWS account structure
2.1.1-2.1.2;<<s3_buckets_deployment>>;Use the `private-s3-bucket` module
2.2.1;<<configure_ebs_encryption>>;Use Gruntwork modules to configure AWS EBS encryption
3.1-3.4;<<apply_account_baseline_logs>>;Use the `account-baseline-*` modules to ensure Cloudtrail is enabled and configured in all regions
3.5;<<apply_account_baseline_security>>;Use the `account-baseline-security` module to ensure AWS Config is enabled in all regions
3.6;<<apply_account_baseline_logs>>;Use the `account-baseline-*` modules to ensure Cloudtrail S3 bucket has access logging enabled
3.7;<<apply_account_baseline_logs>>;Use the `account-baseline-*` modules to ensure Cloudtrail logs are encrypted at rest using KMS CMKs
3.8;<<kms>>;Use the KMS module
3.9;<<vpc_flow_logs>>;Use the Gruntwork CIS-compliant `vpc` service to provision VPCs with flow logs enabled
3.10-3.11;<<apply_account_baseline_logs>>;Use the `account-baseline-*` modules to ensure Object-level logging is enabled for S3 buckets for read and write events
4.1-4.15;<<maintain_compliance_monitoring>>;The CloudWatch Logs metrics filters wrapper module will satisfy each recommendation
5.1;<<maintain_compliance_networking>>;Use the Gruntwork CIS-compliant `vpc` service to ensure there is no public remote access
5.2;<<maintain_compliance_networking>>;Use the Gruntwork CIS-compliant `vpc` service for a secure network configuration
5.3;<<maintain_compliance_networking>>;Use the `cloud-nuke` tool to remove all default security groups
5.4;<<maintain_compliance_networking>>;Use the Gruntwork CIS-compliant `vpc` service to configure least-privilege routing by default
|===

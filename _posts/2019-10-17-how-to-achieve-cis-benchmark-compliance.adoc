---
title: How to achieve compliance with the CIS AWS Foundations Benchmark
categories: Compliance
image: /assets/img/guides/cis-compliance/cis-logo.png
excerpt: Learn how to achieve and maintain compliance with each of the CIS AWS Foundations Benchmark recommendations.
tags: ["aws", "security", "compliance"]
cloud: ["aws"]
redirect_from: /static/guides/compliance/how-to-achieve-cis-benchmark-compliance/
---
:page-type: guide
:page-layout: post

:toc:
:toc-placement!:

// GitHub specific settings. See https://gist.github.com/dcode/0cfbf2699a1fe9b46ff04c41721dda74 for details.
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
toc::[]
endif::[]

== Intro
This is a complete guide to help you achieve compliance with the
link:https://www.cisecurity.org/benchmark/amazon_web_services/[CIS AWS Foundations Benchmark]. By following this guide,
you can launch infrastructure that is compliant with the Benchmark recommendations, and you'll be set to retain a
compliant state over time because all of the infrastructure is defined as code. This guide targets version 1.3.0 of the Benchmark.

NOTE: Previously, we supported version 1.2.0 of the Benchmark. If you are looking to upgrade from v1.2.0 to v1.3.0,
please follow link:/guides/upgrades/how-to-update-to-cis-13/[the upgrade guide] instead.

image:/assets/img/guides/cis-compliance/cis-account-architecture.png[CIS Benchmark Architecture]

=== What is the CIS AWS Foundations Benchmark?
The link:https://www.cisecurity.org/resources/?type=benchmark[CIS Benchmarks] are objective, consensus-driven
configuration guidelines developed by security experts to help organizations improve their security posture.
The AWS Foundations Benchmark is a set of configuration best practices for hardening AWS accounts to establish
a secure foundation for running workloads on AWS. It also provides ongoing monitoring to ensure that the
account remains secure.

=== What you'll learn in this guide

This guide consists of five main sections:

<<core_concepts>>::
  An overview of the AWS Foundations Benchmark, including its control sections and structure.

<<production_grade_design>>::
  How to use infrastructure as code to achieve compliance with minimal redundancy and maximum flexibility.

<<deployment_walkthrough>>::
  A step-by-step guide to achieving compliance using the Gruntwork Infrastructure as Code Library and the
  Gruntwork CIS AWS Foundations Benchmark wrapper modules.

<<next_steps>>::
  How to measure and maintain compliance.

<<traceability_matrix>>::
  A reference table that maps each Benchmark recommendation to the corresponding section in the deployment
walkthrough.


Feel free to read the guide from start to finish or skip around to whatever part interests you!

[[core_concepts]]
== Core concepts

The CIS AWS Foundations Benchmark is organized into the following sections:
 +
 +

. Identity and Access Management
. Storage
. Logging
. Monitoring
. Networking

There are multiple recommendations within each section. Note the use of the term _recommendation_ as opposed
to _control_ or _requirement_. This reinforces the point that CIS is a self-imposed, best-practices standard,
as opposed to compulsory or regulated and centralized standards such as the
link:https://www.pcisecuritystandards.org/[PCI DSS] for the payment card industry or
link:https://www.hhs.gov/hipaa/for-professionals/security/laws-regulations/index.html[HIPAA] for covered
health care entities.

=== Assessment Status
Each recommendation is classified as either _Automated_ or _Manual_. _Automated_ recommendations indicate that
the check for the recommendation may be accessed programmatically (e.g., an API exists to validate or enable
the recommendation). _Manual_ recommendations must be checked and remediated manually.

=== Profiles
The Benchmark defines two profile levels. Level one recommendations are easier to implement, incur less
overhead, but still substantially improve security. Level two recommendations are meant for highly sensitive
environments with a lower risk appetite. They may be more difficult to implement and/or cause more overhead in
day-to-day usage.

=== CIS Controls

Each recommendation is also linked to a corresponding link:https://www.cisecurity.org/controls/[CIS Control]. The
controls are distinct from the Benchmark. They're described by CIS as "a prioritized set of actions that collectively
form a defense-in-depth set of best practices that mitigate the most common attacks against systems and networks."
Organizations seeking to implement a comprehensive security program or framework can use the controls to measure their
progress and prioritize security efforts. The Foundations Benchmark is just one of several guidelines that can help
reach the bar set by the CIS Controls. Refer to the Benchmark document directly to view how the recommendations map to
controls.

=== Recommendation sections

==== Identity and Access Management
_Number of recommendations: 22_

The recommendations in this section involve the use of identity, accounts, authentication, and authorization.
On AWS, most identity and access control related concerns are managed using the
link:https://aws.amazon.com/iam/[eponymous IAM service]. Hence, most (but not all) of the recommendations in
this section discuss particular IAM configurations, such as the configuration of the password policy, the use
of various groups and roles, and the configuration of multi-factor authentication (MFA) devices.

==== Storage
_Number of recommendations: 3_

This section was added in the version 1.3.0 and involves the use of storage capabilities of AWS. The relevant
services for this section are link:https://aws.amazon.com/s3/[S3] and link:https://aws.amazon.com/ec2/[EC2]. The
recommendations in this section pertain to in-transit and at-rest encryption.

==== Logging
_Number of recommendations: 11_

AWS has a variety of logging, monitoring, and auditing features, and the Benchmark has recommendations for
several of them:

* link:https://aws.amazon.com/cloudtrail/[AWS CloudTrail] tracks user activity and API usage
* link:https://aws.amazon.com/config/[AWS Config] records and evaluates resource configurations
* link:https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html[VPC Flow Logs] capture network traffic information
  in VPCs

AWS has several other logging related features that are not covered directly by the Benchmark. For example,
the primary log ingestion and query service, link:https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html[Amazon CloudWatch
Logs], is integrated with many other AWS services. The Benchmark does not contain any recommendations
specifically for CloudWatch Logs, though many recommendations do make mention of it.

==== Monitoring
_Number of recommendations: 15_

Monitoring is an overloaded term in the industry. In the context of the AWS Foundations Benchmark, the
monitoring section is exclusively about monitoring for specific API calls using the CloudTrail service paired
with link:https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/MonitoringLogData.html[CloudWatch Logs
filter metrics]. Each recommendation in this section spells out a specific filter and an associated alarm.

==== Networking
_Number of recommendations: 4_

The Benchmark is uncomfortably light on networking, considering its central role in the security of any
distributed system. The recommendations merely limit traffic from the zero network (`0.0.0.0/0`) and
suggest limiting routing for VPC peering connections based on link:https://en.wikipedia.org/wiki/Principle_of_least_privilege[the principle of least-privilege].

[[production_grade_design]]
== Production-grade design
In <<core_concepts>> we discussed the basics of the AWS Foundations Benchmark. Although it's possible to achieve
compliance with the Benchmark by manually configuring each setting in the web console or entering the CLI commands, we
strongly discourage this approach. It precludes
link:https://gruntwork.io/guides/foundations/how-to-use-gruntwork-infrastructure-as-code-library/#infrastructure-as-code[the
myriad benefits of using code to manage infrastructure].
 +
 +

Instead, we advise using link:https://www.terraform.io[Terraform] (or similar tools, such as
link:https://aws.amazon.com/cloudformation/[CloudFormation] or link:https://www.pulumi.com/[Pulumi]) to configure cloud
resources programmatically. This section will cover the Terraform resources you can use to implement each of the
recommendations. We assume that you're familiar with the basics of Terraform. If you aren't, read our
link:https://blog.gruntwork.io/an-introduction-to-terraform-f17df9c6d180[Introduction to Terraform blog post], or pick
up the link:https://blog.gruntwork.io/terraform-up-running-2nd-edition-early-release-is-now-available-b104fc29783f[2nd
edition of Terraform Up & Running].

=== Identity and Access Management
The first section of the Benchmark centers on Identity and Access Management, including the following:

* Avoiding usage of the "root" account
* Requiring MFA for IAM users
* Setting a specific password policy
* Disabling administrative permissions
* Limiting the use of API access keys
* Using IAM roles
* Removing expired SSL/TLS certificates
* Enabling IAM Access Analyzer

In the subsequent sections, we'll review the recommendations and discuss how to implement them using Terraform resources and data sources.

[[configure_authentication]]
==== Configure authentication
One of main areas of concern in the IAM section relates to authentication. The Benchmark has recommendations for IAM
users and the root user account, password policy, and multi-factor authentication. There is more than one way to
authenticate to AWS, and the method you choose determines how to implement these recommendations in your code.

===== Federated authentication using SAML
Perhaps the most robust and secure method for authenticating to AWS is to use
link:https://aws.amazon.com/identity/saml/[federated SAML authentication] with an identity provider (IdP) like Okta,
Google, or Active Directory. In this configuration, users authenticate to the IdP and assume IAM roles to obtain
permissions in AWS. All user management is handled in the IdP, where you can assign roles to users according to their
needs. If you use this approach, several of the Benchmark recommendations, including recommendations 1.10,
1.15, and 1.11, are not applicable (assuming you have no IAM users at all).

Configuring SAML is a multi-step process that is outside the scope of this guide. Familiarize yourself with the
process by reviewing the link:https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_create_saml.html[AWS
documentation on the matter]. You can use the
link:https://www.terraform.io/docs/providers/aws/r/iam_saml_provider.html[`aws_iam_saml_provider`] and
link:https://www.terraform.io/docs/providers/aws/d/iam_policy_document.html[`aws_iam_policy_document`] Terraform
resources to manage your SAML provider via code.

===== IAM user authentication
Another option is to authenticate using IAM users. The accounts are created and managed directly in AWS as opposed to a
third-party provider. IAM users log in to AWS with a password and an optional MFA device. IAM users are easier to get
started with than SAML, and they're also free to use. However, to avoid unauthorized access, it's crucial to configure
the IAM user settings securely. IAM users may be more suitable for smaller environments with only a few users.

A few tips on creating IAM users with Terraform:

* To create IAM users, use the link:https://www.terraform.io/docs/providers/aws/r/iam_user.html[`aws_iam_user`] and
link:https://www.terraform.io/docs/providers/aws/r/iam_user_login_profile.html[`aws_iam_user_login_profile`] resources.

* As instructed by recommendation 1.11, do not create API access keys for new users automatically. The intent is that
users should create them on their own if and when needed.

* To stay compliant with recommendation 1.15, be sure to never attach IAM policies directly to IAM users. Instead, create IAM groups, attach policies to those groups, and add the user to groups using the link:https://www.terraform.io/docs/providers/aws/r/iam_user_group_membership.html[`aws_iam_user_group_membership`]. This helps to avoid scenarios where auditing the exact permissions of IAM users becomes difficult and unmaintainable.

Consider the following example which creates a user with access to AWS Support:

[source,hcl]
----
resource "aws_iam_user" "support_user" {
  name = "support"
}

resource "aws_iam_group" "example_group" {
  name = "support-group"
}

resource "aws_iam_group_policy_attachment" "support_group_attach" {
  group      = aws_iam_group.example_group.name
  policy_arn = "arn:aws:iam::aws:policy/AWSSupportAccess"
}

resource "aws_iam_user_group_membership" "example" {
  user = aws_iam_user.example_user.name
  groups = [aws_iam_group.example_group.name]
}

----

This code creates an IAM user called `support`, adds them to a new group called `support-group`, and attaches the
`AWSSupportAccess` managed policy to the group. It demonstrates how to meet a few of the Benchmark recommendations:

1. The user is created without an API access key (recommendation 1.11). Access keys should only be created by the user later.
2. The policy is attached to an IAM group, not directly to the IAM user (recommendation 1.15).
3. Recommendation 1.17 specifically requires that the Support policy be used. You should attach it to a group, as
shown here.

==== Do not use full administrator privileges
Recommendation 1.16 states that no IAM policies with full administrator privileges be assigned. However, some
administrator access is needed to maintain the account on an ongoing basis, and use of the root account is also
prohibited. What to do?

One approach is to create an IAM policy with full permissions to IAM and nothing else. Attach the policy to a group,
and give access only to trusted users. This allows _effective_ administrator access without an _explicit_
administrator policy. For example, you could use the following Terraform code to create such a policy:

[source,hcl]
----
data "aws_iam_policy_document" "iam_admin" {
  statement {
    sid = "iamAdmin"
    actions = [
      "iam:*",
    ]
    resources = ["*"]
    effect = "Allow"
  }
}
----

You can then attach that policy to a group:

[source,hcl]
----
resource "aws_iam_policy" "iam_admin" {
  name   = "iam_admin"
  path   = "/"
  policy = data.aws_iam_policy_document.iam_admin.json
}

resource "aws_iam_group" "iam_admin" {
  name = "iam-admins"
}

resource "aws_iam_group_policy_attachment" "iam_admin_group_attach" {
  group      = aws_iam_group.iam_admin.name
  policy_arn = aws_iam_policy.iam_admin.arn
}
----

In this example, any IAM user that is a member of the `iam-admins` group will have has permissions to access all
functionality in the IAM service, make them an effective administrator of the account.

==== Enabling multi-factor authentication for IAM users
Recommendation 1.10, which requires all IAM users to have MFA enabled, seems straightforward on the surface, but in AWS,
there's no way to explicitly require MFA for log in. Instead, you can make sure that all groups and roles have a
conditional IAM policy attached that explicitly denies all actions unless MFA is enabled. This way, whenever a user logs
in without MFA, all services will show a permission denied error if the user didn't use MFA.

The
link:https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_aws_my-sec-creds-self-manage-mfa-only.html[AWS
documentation has an example of this policy]. Create the policy with Terraform, and attach it to every group
you create - including the `iam-admins` and `support` groups we created above. Here's an example:

[source,hcl]
----
data "aws_iam_policy_document" "require_mfa_policy" {
  statement {
    sid = "AllowViewAccountInfo"
    effect = "Allow"
    actions = ["iam:ListVirtualMFADevices"]
    resources = ["*"]
  }

  statement {
    sid = "AllowManageOwnVirtualMFADevice"
    effect = "Allow"
    actions = [
      "iam:CreateVirtualMFADevice",
      "iam:DeleteVirtualMFADevice"
    ]
    resources = [
      "arn:aws:iam::${var.aws_account_id}:mfa/$${aws:username}",
    ]
  }

  statement {
    sid = "AllowManageOwnUserMFA"
    effect = "Allow"
    actions = [
      "iam:DeactivateMFADevice",
      "iam:EnableMFADevice",
      "iam:GetUser",
      "iam:ListMFADevices",
      "iam:ResyncMFADevice"
    ]
    resources = [
      "arn:aws:iam::${var.aws_account_id}:user/$${aws:username}",
      "arn:aws:iam::${var.aws_account_id}:mfa/$${aws:username}"
    ]
  }

  statement {
    sid = "DenyAllExceptListedIfNoMFA"
    effect = "Deny"
    not_actions = [
      "iam:CreateVirtualMFADevice",
      "iam:EnableMFADevice",
      "iam:GetUser",
      "iam:ListMFADevices",
      "iam:ListVirtualMFADevices",
      "iam:ResyncMFADevice",
      "sts:GetSessionToken"
    ]
    resources = ["*"]
    condition {
      test     = "Bool"
      variable = "aws:MultiFactorAuthPresent"
      values   = ["false"]
    }
  }
}

resource "aws_iam_group" "support" {
  name  = "support"
}


resource "aws_iam_group_policy" "require_mfa_for_support" {
  name   = "RequireMFA"
  group  = aws_iam_group.support.name
  policy = data.aws_iam_policy_document.require_mfa_policy
}
----

We've created an IAM policy that denies all access accept the necessary permissions to set up an MFA device, then we
attached the policy to the `support` group. If a user that is a member of the `support` group logs in without MFA, they
won't have access to any services, even if the `support` group or the user had other policies attached. They will have
enough permissions to set up an MFA device, and after doing so, they can log in and will have any permissions granted to
them by other IAM policies.

Attach a policy like this one to every group in your account.

==== Password policy
The IAM password policy is perhaps the most straightforward and explicit set of recommendations (1.8-1.9 and 1.12) in the entire
Benchmark. You can invoke link:https://www.terraform.io/docs/providers/aws/r/iam_account_password_policy.html[the
Terraform `aws_iam_account_password_policy` resource] to implement the recommended policy.

For example:

[source,hcl]
----
resource "aws_iam_account_password_policy" "aws_foundations_benchmark_policy" {
  minimum_password_length        = 14
  allow_users_to_change_password = true
  hard_expiry                    = true
  max_password_age               = 90
  password_reuse_prevention      = 24
}
----

[[cleanup_expired_certs]]
==== Cleanup Expired SSL/TLS certificates
The CIS AWS v1.3 recommendations require that all expired SSL/TLS certificates stored in AWS IAM are automatically removed
(see 1.19). Unfortunately removing expired certificates via AWS Management Console is not currently supported so we must remove
then using the AWS API. To view the current certificates stored in IAM, use the AWS CLI and execute the `list-server-certificates`
command:

[source,bash]
----
aws iam list-server-certificates
----

The command output should return an array that contains all of the SSL/TLS certificates currently stored in IAM and their metadata:

[source,json]
----
{
	"ServerCertificateMetadataList": [{
		"ServerCertificateId": "EHDGFRW7EJFYTE88D",
		"ServerCertificateName": "MyServerCertificate",
		"Expiration": "2020-07-10T23:59:59Z",
		"Path": "/",
		"Arn": "arn:aws:iam::012345678910:server-
		certificate / MySSLCertificate ",
		"UploadDate": "2018-06-10T11:56:08Z"
	}]
}
----

The `Expiration` attribute contains the expiration date for each SSL/TLS certificate which you can use to determine
if it should be removed. To remove the certificate use the `delete-server-certificate` command, making sure to
substitute `<CERTIFICATE_NAME>` with the `ServerCertificateId` attribute from the previous command:

[source,bash]
----
aws iam delete-server-certificate --server-certificate-name <CERTIFICATE_NAME>
----

To automate this process you might decide to implement a Lambda function that runs on a regular schedule and removes
all expired SSL/TLS certificates. Check out the <<cleanup_expired_certs_deployment>> section of the deployment walkthrough
to see how to deploy a ready-made module that can be deployed in each of your AWS accounts.

[[iam_access_analyzer]]
==== IAM Access Analyzer
As of version 1.3.0, the CIS recommendations stipulate that the AWS IAM Access Analyzer service is enabled across all active regions in a given
AWS Account or Organization.

To achieve this compliance requirement, enable the IAM Access Analyzer service for every AWS region you have enabled in
every one of your AWS accounts. Alternatively, you could make use of the `iam-access-analyzer-multi-region` module
available in the Gruntwork Service Catalog, as described in the <<iam_access_analyzer_deployment>> section of the
deployment walkthrough.

Once enabled, it will scan only within the boundaries of the AWS Account or Organization it has access to. Only specific
resources are analyzed and included in the results - e.g. S3 buckets, SQS, etc. (For the full list of resources supported,
please visit link:https://docs.aws.amazon.com/IAM/latest/UserGuide/access-analyzer-resources.html[the relevant AWS docs]).
This lets you identify unintended access to these resources and data by external entities.

The findings from the IAM Access Analyzer can be found in the AWS web console, and can be archived or resolved.
Please visit the link:https://docs.aws.amazon.com/IAM/latest/UserGuide/access-analyzer-findings.html[AWS guidance on how to do so].

[[manual_steps]]
==== Manual steps
A few of the recommendations in the IAM section are not achievable via API and require a one-time manual configuration.
Perform the steps in this section manually.

[[root_mfa]]
===== Enable MFA for the root account
Securing the "root" user, or the first user that is created when you set up an AWS account, is one of the
first actions you should take in any new account. Unfortunately, there is no API or automation available for
configuring an MFA device for the root user. Follow the manual steps outlined in the
link:https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user.html#id_root-user_manage_mfa[AWS docs]. Configuring a virtual MFA device will achieve recommendation 1.5. You can also refer to the link:https://gruntwork.io/guides/foundations/how-to-configure-production-grade-aws-account-structure/[production-grade AWS account structure guide.]

For the paranoid: configure a hardware MFA device, as suggested by recommendation 1.6. We suggest using a
link:https://www.yubico.com/[Yubikey] due to its reputation for strong security characteristics and multitude of form
factors. Refer to
link:https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa_enable_physical.html#enable-hw-mfa-for-root[
the documentation for more information on using a hardware device with the root user].

[[subscribe_sns]]
===== Subscribe to SNS topic
The Config alerts and CloudWatch Metric Alarms all go to an SNS topic. Unfortunately, there is no way to automate
subscribing to the SNS topic as each of the steps require validating the delivery target. Follow the steps outlined in
the link:https://docs.aws.amazon.com/sns/latest/dg/sns-user-notifications.html[AWS docs] to be notified by Email, Phone,
or SMS for each of the alerts.

You can also configure an automated system integration if you have a third party alerting system or central dashboard.
Follow the steps in the link:https://docs.aws.amazon.com/sns/latest/dg/sns-http-https-endpoint-as-subscriber.html[AWS
docs] on how to add an HTTPS endpoint as a subscriber to the alerts.


[[security_questions]]
===== Answer security questions and complete contact details
When setting up a new account, AWS asks for contact information and security questions. Unfortunately, there
is no API or automation available for this functionality. In the AWS console, visit the link:https://console.aws.amazon.com/billing/home?#/account[Account settings] page and complete the _Alternate Contacts_ and _Configure Security Challenge Questions_ questions.

For further detail, follow the manual steps outlined in the CIS Benchmark document and refer to the
link:https://aws.amazon.com/answers/security/aws-secure-account-setup/[AWS Secure Account Setup steps].

=== Storage
Version 1.3.0 of the Benchmark includes a new storage section that has three recommendations pertaining to the S3 service as well as the EC2 service.
These have to do with encryption at rest and in transit.

To comply with recommendation 2.1.1, make sure to enable server side encryption on your S3 buckets. In Terraform, this
is achieved by configuring the `server_side_encryption_configuration` argument of the `aws_s3_bucket` resource.

To comply with recommendation 2.1.2, make sure that all access to your S3 buckets is over TLS. In Terraform, you will
want to attach a policy to your buckets that includes a statement similar to this:

[source,hcl]
----
statement {
  sid     = "AllowTLSRequestsOnly"
  effect  = "Deny"
  actions = ["s3:*"]
  resources = [
    <YOUR BUCKET ARN>,
    "${<YOUR BUCKET ARN>}/*"
  ]
  principals {
    type        = "*"
    identifiers = ["*"]
  }
  condition {
    test     = "Bool"
    variable = "aws:SecureTransport"
    values   = ["false"]
  }
}
----

To comply with recommendation 2.2.1 be sure to configure link:https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html[EBS volume encryption]
in all of the enabled AWS regions within your AWS Account(s). You can invoke the Terraform
`aws_ebs_encryption_by_default` resource to implement the recommendation.

For example:

[source,hcl]
----
resource "aws_ebs_encryption_by_default" "ebs_encryption" {
  enabled = true
}
----

=== Logging
In the Logging section, the Benchmark recommendations target the following services:

* link:https://aws.amazon.com/cloudtrail/[AWS CloudTrail]
* link:https://aws.amazon.com/config/[AWS Config]
* KMS key rotation
* VPC Flow logs

We'll cover each of them in turn.

==== AWS CloudTrail
The Benchmark has specific requirements for the CloudTrail configuration, described in recommendations 3.1-4, 3.6-7 and 3.10-11.
The CloudTrail must have the following characteristics:

. Collects events
link:https://docs.aws.amazon.com/awscloudtrail/latest/userguide/receive-cloudtrail-log-files-from-multiple-regions.html[in
all regions]
. Enables
link:https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-log-file-validation-intro.html[log
file integrity validation]
. Ensures that the S3 bucket used by CloudTrail is not publicly accessible
. Integrates
link:https://docs.aws.amazon.com/awscloudtrail/latest/userguide/send-cloudtrail-events-to-cloudwatch-logs.html[CloudTrail
with CloudWatch Logs]
. link:https://docs.aws.amazon.com/awscloudtrail/latest/userguide/encrypting-cloudtrail-log-files-with-aws-kms.html[Encrypts
CloudTrail logs at rest]
. Enables link:https://docs.aws.amazon.com/AmazonS3/latest/dev/ServerLogs.html[access logging] for the CloudTrail S3 bucket
. Enables link:https://docs.aws.amazon.com/AmazonS3/latest/user-guide/enable-cloudtrail-events.html[object-level logging] for read and write events for the CloudTrail S3 bucket

Use the link:https://www.terraform.io/docs/providers/aws/r/cloudtrail.html[`aws_cloudtrail`] Terraform resource to create the CloudTrail. Include the following settings in the CloudTrail configuration:

[source,hcl]
----
is_multi_region_trail         = true
include_global_service_events = true
enable_log_file_validation    = true
s3_bucket_name                = <YOUR BUCKET NAME>
cloud_watch_logs_group_arn    = <YOUR CLOUDWATCH LOGS GROUP ARN>

event_selector {
  read_write_type           = "All"
  include_management_events = true

  data_resource {
    type   = "AWS::S3::Object"
    values = [<YOUR BUCKET ARN>]
  }
}
----

You'll also need the link:https://www.terraform.io/docs/providers/aws/r/s3_bucket.html[`aws_s3_bucket`],
link:https://www.terraform.io/docs/providers/aws/r/s3_account_public_access_block.html[`aws_s3_account_public_access_block`]
resources to create an S3 bucket for the CloudTrail to send its events to and to disable public access to the bucket;
you wouldn't want to expose the CloudTrail data publicly!

Finally, you'll need the
link:https://www.terraform.io/docs/providers/aws/r/cloudwatch_log_group.html[`aws_cloudwatch_log_group`] resource to
create a CloudWatch Log group as another location for CloudTrail to send events. Use this ARN for the `aws_cloudtrail`
resource `cloud_watch_logs_group_arn` parameter when creating the CloudTrail.

==== AWS Config
Benchmark recommendation 3.5 states that AWS Config be enabled in all regions. This is challenging to implement with
Terraform because running a particular configuration in all regions is not a feature that Terraform has natively.
Terraform has link:https://www.terraform.io/docs/configuration/expressions.html#for-expressions[loops], but they aren't
available for the purpose of repeating a resource in many regions. Unfortunately, at the time of writing, there isn't a
way to complete this recommendation without repetitive code.

To proceed, start by creating a Terraform module that takes the following actions:

. Creates an link:https://www.terraform.io/docs/providers/aws/r/sns_topic.html[SNS topic] for publishing Config events
. Creates an link:https://www.terraform.io/docs/providers/aws/d/s3_bucket.html[S3 bucket] for Config events and link:https://www.terraform.io/docs/providers/aws/r/s3_account_public_access_block.html[disables public access]
. Creates an link:https://www.terraform.io/docs/providers/aws/d/iam_role.html[IAM role] for the config service to access an S3 bucket and an SNS topic
. Creates a link:https://www.terraform.io/docs/providers/aws/r/config_configuration_recorder.html[configuration recorder]
. Creates a link:https://www.terraform.io/docs/providers/aws/r/config_delivery_channel.html[delivery channel]
. link:https://www.terraform.io/docs/providers/aws/r/config_configuration_recorder_status.html[Enables the configuration recorder]

When the module is working and sets up AWS Config according to the prescribed configuration, you should invoke it once
for each region in the account. One way to do this is to use
link:https://www.terraform.io/docs/configuration/providers.html#alias-multiple-provider-instances[provider aliases]. For
example, you could specify one provider for each region, then invoke the module for each provider:

[source,hcl]
----
# The default provider configuration
provider "aws" {
  alias  = "us-east-1"
  region = "us-east-1"
}

# Additional provider configuration for west coast region
provider "aws" {
  alias  = "us-west-2"
  region = "us-west-2"
}

# ... repeat the provider for each region in the AWS account

module "aws_config_us_east_1" {
  source = "/path/to/your/config/module"
  providers = {
    aws = aws.us-east-1
  }
}

module "aws_config_us_west_2" {
  source = "/path/to/your/config/module"
  providers = {
    aws = aws.us-west-2
  }
}

# ... repeat the module invocation for each provider
----

When AWS launches new regions, they are link:https://docs.aws.amazon.com/general/latest/gr/rande-manage.html[not enabled by default], so you won't need to add to this list over time.

Alternatively, you could link:https://docs.aws.amazon.com/general/latest/gr/rande-manage.html#rande-manage-disable[disable] the regions you aren't using and only enable AWS Config for those that you need.

==== KMS Key rotation
Finally, a simple recommendation! To meet recommendation 3.8, create KMS keys with key rotation enabled. Using Terraform, it looks like this:

[source,hcl]
----
resource "aws_kms_key" "example" {
  description         = "Example Key"
  enable_key_rotation = true
}
----

==== VPC Flow Logs
Under the Benchmark, all VPCs must have a Flow Log to log network traffic. Use the
link:https://www.terraform.io/docs/providers/aws/r/flow_log.html[`aws_flow_log`] Terraform resource, being sure to use
`log_destination_type=cloud-watch-logs`.
 +
 +

Because the recommendation is to attach flow logs to every single VPC, you'll need to repeat the configuration for all
the default VPCs which exist in all regions of the account. You can use the
link:https://github.com/gruntwork-io/cloud-nuke[`cloud-nuke defaults-aws` command] to easily remove all the default VPCs
(and default security groups) from all regions of an account, making it easier to achieve this recommendation.

=== Monitoring
The Monitoring section has 15 recommendations for creating specific
link:https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/MonitoringPolicyExamples.html[CloudWatch Logs metric
filters] that send alarms to an SNS topic when a particular condition is met.

The easiest way to achieve this recommendation is to create a Terraform module that creates CloudWatch Logs metrics
filters and CloudWatch Alarms, and then invoke the module once for each recommendation. You'll need the
link:https://www.terraform.io/docs/providers/aws/r/cloudwatch_log_metric_filter.html[`aws_cloudwatch_log_metric_filter`]
and link:https://www.terraform.io/docs/providers/aws/r/cloudwatch_metric_alarm.html[`aws_cloudwatch_metric_alarm`]
Terraform resources.


=== Networking
The networking section involves a paltry four recommendations. We don't consider this section to be sufficient
to ensure a secure networking configuration. For a deeper dive, refer to Gruntwork's
link:https://gruntwork.io/guides/networking/how-to-deploy-production-grade-vpc-aws/[How to deploy a
production-grade VPC on AWS] guide, which includes recommendations for segmentation using network ACLs,
security groups, and remote access. Moreover, our link:https://gruntwork.io/reference-architecture/[Reference
Architecture] can get you up and running with a secure network configuration immediately.

Recommendation 5.1 requires that you use Network ACL rules to block all access to the remote server administration ports, such as SSH to port 22 and Remote
Desktop to port 3389, by default. You can then add additional NACL rules to allow remote admin access, but only from specific CIDR blocks. Recommendation 5.2 similarly allows you to allow remote admin access from specific CIDR blocks in your Security Groups. Note that allowing remote admin access from all IPs (`0.0.0.0/0`) is NOT allowed, so instead, if you require SSH or Remote Desktop to your cloud resources, provide a more restricted CIDR
range, such as the IP addresses of your offices.

To meet recommendation 5.3, run the link:https://github.com/gruntwork-io/cloud-nuke[`cloud-nuke defaults-aws`] command
to remove the rules from all default security groups. Note that it isn't possible to actually delete the default
security group, so instead the command deletes the rules, eliminating the risk of something being mistakenly exposed.

Finally, for recommendation 5.4, the guidance is straightforward: when creating peering connections between VPCs, do not
create routes for subnets that don't need them. In other words, only create routes between subnets that need them based
on the services running on those subnets. This can help to avoid exposing services between networks unnecessarily.

[[deployment_walkthrough]]
== Deployment walkthrough
The <<production_grade_design>> section describes in detail the Terraform resources to use and the approach to take for
each recommendation, but we've already done that grunt work! This section documents how to achieve compliance using the
Infrastructure as Code modules from Gruntwork.

[[pre_requisites]]
=== Pre-requisites

This walkthrough has the following pre-requisites:

Gruntwork Infrastructure as Code Library::
  This guide uses code from the link:https://gruntwork.io/infrastructure-as-code-library/[Gruntwork Infrastructure as Code Library], as it
  implements most of the production-grade design for you out of the box. Make sure to read
  link:/guides/foundations/how-to-use-gruntwork-infrastructure-as-code-library[How to use the Gruntwork Infrastructure as Code Library].

Gruntwork Compliance for CIS AWS Foundations Benchmark::
  This guide also uses code from the link:https://gruntwork.io/achieve-compliance[Gruntwork CIS AWS
  Foundations Benchmark repository], which contains the necessary configurations to achieve compliance.
+
[.exceptional]
IMPORTANT: You must be a [js-subscribe-cta]#Gruntwork Compliance subscriber# to access the Gruntwork
Infrastructure as Code Library and the CIS AWS Foundations Benchmark modules.

[[account_structure]]
How to configure a production-grade AWS account structure::
  Review the link:https://gruntwork.io/guides/foundations/how-to-configure-production-grade-aws-account-structure/[production-grade AWS account structure guide] to familiarize yourself with many of the concepts that this walkthrough depends on.


Terraform::
  This guide uses https://www.terraform.io/[Terraform] to define and manage all the infrastructure as code. If
  you're not familiar with Terraform, check out
  https://blog.gruntwork.io/a-comprehensive-guide-to-terraform-b3d32832baca[A Comprehensive Guide to Terraform],
  https://training.gruntwork.io/p/terraform[A Crash Course on Terraform], and
  link:/guides/foundations/how-to-use-gruntwork-infrastructure-as-code-library[How to Use the Gruntwork
  Infrastructure as Code Library].

Keybase (optional)::
  As part of this guide, you will create IAM users, including, optionally, credentials for those IAM users. If you
  choose to create credentials, those credentials will be encrypted with a PGP key. You could provide the PGP keys
  manually, but a more manageable option may be to have your team members to sign up for https://keybase.io[Keybase],
  create PGP keys for themselves, and then you can provide their Keybase usernames, and the PGP keys will be retrieved
  automatically.

[[gruntwork_solution]]
=== The Gruntwork solution
Gruntwork offers battle-tested infrastructure as code modules to help you create production grade infrastructure in a
fraction of the time it would take to develop from scratch. Each of the code modules are "compliance-ready"; they are
mostly unopinionated by default, but they can be configured for compliance with the right settings.

To further simplify and expedite compliance, the Gruntwork CIS Service Catalog uses both standalone compliance
modules as well as "wrappers" around the core, unopinionated modules in the Infrastructure as Code Library. The
standalone compliance modules are designed with the compliance requirements built-in, whereas the wrappers
call the core modules with configuration values that are compliant with the AWS Foundations Benchmark. You can use both
types of modules by creating a module of your own (in the case of the wrapper modules, this can be considered a second
wrapper) and using the compliance module as the `source`. Optionally, you can also use `terragrunt` to call your module,
thus creating a chain of IaC modules. For more information on creating your own service catalog of modules please refer
to the link:https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/core-concepts.md#create-your-own-service-catalog[Create your own service catalog section]
in the Gruntwork Service Catalog documentation.
 +
 +

.Types of CIS module relationships to avoid repetitive code and minimize the amount of extra work needed to achieve compliance.
image::/assets/img/guides/cis-compliance/cis-module-relationships.png[]

Let's unpack this a bit.

[[core_modules]]
==== Core modules
Core modules are broadly applicable and can be used with or without compliance requirements. For example,
the link:https://github.com/gruntwork-io/terraform-aws-security/blob/master/modules/iam-groups/README.md[`iam-groups`
core module] creates a best practices set of IAM groups. The groups are configurable according to your needs.
You could, for example, choose to create a group with read-only access, another group with full administrator
access, and no other groups. All Gruntwork subscribers have access to the core modules, which reside in
Gruntwork's link:https://gruntwork.io/repos[infrastructure as code repositories].

[[standalone_modules]]
==== Standalone Compliance modules
The standalone compliance modules complement the modules available in the IaC Library. They have the CIS compliance requirements built right in and may combine multiple modules including Core modules for a
specific use case. For example, the link:https://github.com/gruntwork-io/terraform-aws-cis-service-catalog/tree/master/modules/cleanup-expired-certs[`cleanup-expired-certs` standalone module] deploys a Lambda function that runs regularly and automatically removes all expired SSL/TLS certificates stored in AWS IAM in compliance with recommendation 1.19 of the CIS AWS Foundations Benchmark. These modules are in the link:https://github.com/gruntwork-io/terraform-aws-cis-service-catalog[`terraform-aws-cis-service-catalog`
repository] (accessible to Gruntwork Compliance subscribers).

[[wrapper_modules]]
==== Compliance wrapper modules
The compliance wrapper modules are an extension of the IaC Library. They use the
link:https://www.terraform.io/docs/modules/sources.html[`source` argument in a Terraform module block] to invoke
the core module with a configuration that is customized for compliance with the CIS AWS Foundations Benchmark.
These modules are in the link:https://github.com/gruntwork-io/terraform-aws-cis-service-catalog[`terraform-aws-cis-service-catalog`
repository] (accessible to Gruntwork Compliance subscribers).

[[infrastructure_modules]]
==== infrastructure-modules
The `infrastructure-modules` are your organization's "blueprint" for how to deploy infrastructure. You can
use `infrastructure-modules` to customize the settings according to the needs of your environment. Subscribers can refer to
the link:https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/core-concepts.md#create-your-own-service-catalog[Create your own service catalog section]
in the Gruntwork Service Catalog documentation for more information on how you might use `infrastructure-modules`.
 +
 +
If you're using Terragrunt, the `infrastructure-modules` are optional; you can call the compliance
wrapper modules directly as the `source` from a Terragrunt configuration. The benefit of this is that you have less code to maintain by depending directly on Gruntwork's upstream compliance modules.

[[infrastructure_live]]
==== infrastructure-live
`infrastructure-live` uses link:https://github.com/gruntwork-io/terragrunt[Terragrunt] to make it easier to
work with Terraform modules in multiple environments. `infrastructure-live` is optional - you can use all of the modules
with or without Terragrunt.
 +
 +
If you're not using Terragrunt, you can use `infrastructure-modules` to call the compliance wrapper modules. Subscribers can refer to the
link:https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/core-concepts.md#create-your-own-service-catalog[Create your own service catalog section]
in the Gruntwork Service Catalog documentation for more information on how you might use `infrastructure-live`.

[[benefits]]
==== Benefits
This modular, decomposed approach allows for maximum code reuse. The core modules can be used with or without
compliance, depending on how they are configured. The compliance wrappers are like shadows of the core
modules; they pass through most of the variables to the core modules without alteration, but hard code any
settings needed for compliance. When you call the compliance modules from your own code in
`infrastructure-modules`, you only need to set up any variables that are custom for your environment. Often
times the default settings are good enough.
 +
 +
You can use this approach on each AWS account. In many cases, you'll only need compliance for production accounts, but the
same methodology can be applied to pre-production accounts as well.
 +
 +

If you need to brush up on how the IaC Library works, read the
link:https://gruntwork.io/guides/foundations/how-to-use-gruntwork-infrastructure-as-code-library/[How to use
the Gruntwork Infrastructure as Code Library] guide.

=== Create the root account

The first step is to create your root account. This account will be the parent of all of your other AWS accounts and
the central place where you manage billing. You create this initial account manually, via a web browser:

. Go to https://aws.amazon.com.
. Click Create an AWS Account.
. Go through the sign up flow, entering contact and billing details as requested.
. You will be asked to enter an email address and password to use as the credentials for the root user of this root
account.

[[lock_down_root_user]]
=== Lock down the root user

After signing up for an AWS account, you'll be logged in as the root user. The root user has unrestricted access to
just about everything in your AWS account (and any child accounts), so if an attacker compromises your root user, the
results can be catastrophic for your company. Therefore, you should lock down the root user as much as possible:

Use a secrets manager::
Do NOT store the root user's password, or secrets of any kind, in plain text. Instead, always use a secrets manager
such as https://1password.com[1Password], https://www.lastpass.com[LastPass], or https://www.passwordstore.org[pass]
to store the credentials in an encrypted format.

Use a strong, generated password::
Do NOT re-use passwords from other websites, or any password that you can remember at all. Instead, generate a random,
cryptographically secure, long password (20+ characters) for the root user. All the password managers mentioned above
can generate and store passwords for you in one step, so use them!

Add security questions to your root account::
The CIS benchmark suggests adding security questions when registering your AWS account so that when somebody contacts
AWS support, they will be required to complete a security challenge. To add security questions to the root account,
navigate in the AWS web console to `My Account` and then to the `Personal Information` page. There you should be able
to click on `Configure Security Challenge Questions` and add your questions.

Enable MFA::
Make sure to
https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user.html#id_root-user_manage_mfa[enable MFA for your root user].
Feel free to use a virtual or hardware MFA device, whichever is more straightforward or required by your company, as either one
dramatically improves the security of your root user. It is up to your discretion to decide which option is suitable
for your use case. The CIS benchmark recommends using a dedicated or company-owned device for MFA and not a personal
one. This applies to both virtual and hardware devices.

Disable access keys::
Make sure to
https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user.html#id_root-user_manage_delete-key[delete the root user's access keys],
so that the only way to login as the root user is via the web console, where MFA is required.

Don't use the root user again::
In the next section, you will create an IAM user in the root account with admin permissions. Once you've created that
IAM user, you should do everything as that IAM user, and more or less never touch the root user account again.
The only time you'll need it is for account recovery situations (e.g., you accidentally deleted the IAM user or lost
your credentials) or for the
https://docs.aws.amazon.com/general/latest/gr/aws_tasks-that-require-root.html[small number of tasks that require root user credentials].

_This fulfils requirement #1.7 from the CIS 1.3.0 benchmark._

[[create_iam_user_in_root]]
=== Create an IAM user in the root account

As the last action you do as the root user, you MUST create an IAM user. This is not only a better practice from a
security standpoint, but also, the `account-baseline-xxx` modules we will use below assume IAM roles, which does not
work with a root user. Later on, we'll create and manage all IAM users as code, but you should create this very first
IAM user manually by
https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html#id_users_create_console[following these instructions]:

. Enter a username for your IAM user.
. Select both "programmatic access" and "AWS Management Console access."
. On the next page, click "Attach existing policies to user directly" and attach the `AdministratorAccess` policy.
. Click next a few more times to create the IAM user.
. In a secrets manager, save the IAM sign-in URL, your IAM user's username, the password, and your Access Keys.

[[lock_down_iam_users]]
=== Lock down the root account IAM users

Although IAM users don't have the same powers as a root user, having an IAM user account compromised can still be a
huge problem for your company (especially if that IAM user had admin permissions), so it's still critical to lock down
IAM user accounts as much as possible:

Use a secrets manager::
Do NOT store the root user's password, or secrets of any kind, in plain text. Instead, always use a secrets manager
such as https://1password.com[1Password], https://www.lastpass.com[LastPass], or https://www.passwordstore.org[pass]
to store the credentials in an encrypted format.


Use a strong, generated password::
Do NOT re-use passwords from other websites, or any password that you can remember at all. Instead, generate a random,
cryptographically secure, long password (20+ characters). All the password managers mentioned above can generate and
store passwords for you in one step, so use them!


Enable MFA::
Always make sure to
https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa_enable.html[enable MFA for your IAM user].
Feel free to use a virtual or hardware MFA devicewhichever is easier or required by your companyas either one
dramatically improves the security of your IAM user. Note that using SMS (text messages) for MFA is
https://www.schneier.com/blog/archives/2016/08/nist_is_no_long.html[no longer recommended by NIST] due to known
https://www.theverge.com/2017/9/18/16328172/sms-two-factor-authentication-hack-password-bitcoin[vulnerabilities with the cellular system],
so using a virtual or hardware MFA device is preferable; that said, MFA with SMS is still better than no MFA at all.

wrapper module]. Complete this step before creating any IAM users!
=== Configure the security baseline for the root account

Next, we'll configure a security baseline for the root account that is responsible for creating all the child accounts.
It will also configure AWS Organizations, IAM Roles, IAM Users, IAM Groups, IAM Password Policies, Amazon GuardDuty, AWS CloudTrail, AWS Config and Security Hub.

We'll be using the `account-baseline-root` module from https://github.com/gruntwork-io/terraform-aws-cis-service-catalog[terraform-aws-cis-service-catalog].

[.exceptional]
IMPORTANT: You must be a [js-subscribe-cta]#Gruntwork subscriber# to access `terraform-aws-service-catalog`.

First, create a _wrapper module_ called `account-baseline-root` in your `infrastructure-modules` repo under the `landingzone` subdirectory:

----
infrastructure-modules
   landingzone
     account-baseline-root
       main.tf
       outputs.tf
       variables.tf
----

Inside of `main.tf`, configure your AWS provider and Terraform settings:

.infrastructure-modules/landingzone/account-baseline-root/main.tf
[source,hcl]
----
provider "aws" {
  # The AWS region in which all resources will be created
  region = var.aws_region

  # Require a 3.x version of the AWS provider
  version = "~> 3.40"

  # Only these AWS Account IDs may be operated on by this template
  allowed_account_ids = [var.aws_account_id]
}

terraform {
  # The configuration for this backend will be filled in by Terragrunt or via a backend.hcl file. See
  # https://www.terraform.io/docs/backends/config.html#partial-configuration
  backend "s3" {}

  # Only allow this Terraform version. Note that if you upgrade to a newer version, Terraform won't allow you to use an
  # older version, so when you upgrade, you should upgrade everyone on your team and your CI servers all at once.
  required_version = "= 0.12.26"
}
----

Next, use the `account-baseline-root` module from the Gruntwork Infrastructure as Code Library:

.infrastructure-modules/landingzone/account-baseline-root/main.tf
[source,hcl]
----
module "root_baseline" {
  source = "git::git@github.com:gruntwork-io/terraform-aws-cis-service-catalog.git//modules/landingzone/account-baseline-root?ref=v0.44.10"

  aws_account_id = var.aws_account_id
  aws_region     = var.aws_region
  name_prefix    = var.name_prefix

  # If you're running the example against an account that doesn't have AWS Organization created, change the following value to true
  create_organization = var.create_organization

  # The child accounts to create
  child_accounts = var.child_accounts

  # IAM users to create in this account
  users = var.users

  # These are variables you only need to set at test time so that everything can be deleted cleanly.
  # You will likely NOT need to set this in any real environments.
  force_destroy_users      = var.force_destroy
  cloudtrail_force_destroy = var.force_destroy
  config_force_destroy     = var.force_destroy

  # Enable IAM Access Analyzer
  iam_access_analyzer_type   = var.iam_access_analyzer_type
  iam_access_analyzer_name   = var.iam_access_analyzer_name
  enable_iam_access_analyzer = var.enable_iam_access_analyzer
}
----

Create all the corresponding input variables for `account-baseline-root` in `variables.tf`:

.infrastructure-modules/landingzone/account-baseline-root/variables.tf
[source,hcl]
----
# ---------------------------------------------------------------------------------------------------------------------
# REQUIRED PARAMETERS
# ---------------------------------------------------------------------------------------------------------------------

variable "name_prefix" {
  description = "The name used to prefix AWS Config and Cloudtrail resources, including the S3 bucket names and SNS topics used for each."
  type        = string
}

variable "aws_region" {
  description = "The AWS Region to use as the global config recorder and seed region for AWS GuardDuty."
  type        = string
}

variable "aws_account_id" {
  description = "The AWS Account ID the template should be operated on. This avoids misconfiguration errors caused by environment variables."
  type        = string
}

variable "child_accounts" {
  description = "Map of child accounts to create. The map key is the name of the account and the value is an object containing account configuration variables. See the comments below for what keys and values this object should contain."

  # Ideally, this would be a map of (string, object), but object does not support optional properties, and we want
  # users to be able to specify, say, tags for some accounts, but not for others. We can't use a map(any) either, as that
  # would require the values to all have the same type, and due to optional parameters, that wouldn't work either. So,
  # we have to lamely fall back to any.
  type = any

  # Expected value for the `child_accounts` is a map of child accounts. The map key is the name of the account and
  # the value is another map with one required key (email) and several optional keys:
  #
  # - email (required):
  #   Email address for the account.
  #
  # - is_logs_account:
  #   Set to `true` to mark this account as the "logs" account, which is the one to use to aggregate AWS Config and
  #   CloudTrail data. This module will create an S3 bucket for AWS Config and an S3 bucket and KMS CMK for CloudTrail
  #   in this child account, configure the root account to send all its AWS Config and CloudTrail data there, and return
  #   the names of the buckets and ARN of the KMS CMK as output variables. When you apply account baselines to the
  #   other child accounts (e.g., using the account-baseline-app or account-baseline-security modules), you'll want to
  #   configure those accounts to send AWS Config and CloudTrail data to the same S3 buckets and use the same KMS CMK.
  #   If is_logs_account is not set on any child account (not recommended!), then either you must disable AWS Config
  #   and CloudTrail (via the enable_config and enable_cloudtrail variables) or configure this module to use S3 buckets
  #   and a KMS CMK that ALREADY exist!
  #
  # - parent_id:
  #   Parent Organizational Unit ID or Root ID for the account
  #   Defaults to the Organization default Root ID.
  #
  # - role_name:
  #   The name of an IAM role that Organizations automatically preconfigures in the new member account. This role trusts
  #   the master account, allowing users in the master account to assume the role, as permitted by the master account
  #   administrator. The role has administrator permissions in the new member account. Note that the Organizations API
  #   provides no method for reading this information after account creation.
  #   If no value is present and no default_role_name is provided, AWS automatically assigns a value.
  #
  # - iam_user_access_to_billing:
  #   If set to ALLOW, the new account enables IAM users to access account billing information if they have the required
  #   permissions. If set to DENY, then only the root user of the new account can access account billing information.
  #   Defaults to default_iam_user_access_to_billing.
  #
  #
  # - enable_config_rules:
  #   Set to `true` to enable org-level AWS Config Rules for this child account. This is only used if
  #   var.config_create_account_rules is false (which is NOT recommened) to force org-level rules. If you do go with
  #   org-level rules, you can only set enable_config_rules to true after deploying a Config Recorder in the child
  #   account. That means you have to: (1) initially set enable_config_rules to false, (2) run 'apply' in this root
  #   module to create the child account, (3) go to the child account and create a config recorder in it, e.g., by
  #   running 'apply' on a security baseline in that account, (4) come back to this root module and set
  #   enable_config_rules to true, (5) run 'apply' again. This is a brittle, error-prone, multi-step process, which is
  #   why we recommend using account-level rules (the default) and avoiding it entirely!
  #
  # - tags:
  #   Key-value mapping of resource tags.
  #
  #
  # Example:
  #
  # child_accounts = {
  #   logs = {
  #     email                       = "root-accounts+logs@acme.com"
  #     is_logs_account             = true
  #   }
  #   security = {
  #     email                       = "root-accounts+security@acme.com"
  #     role_name                   = "OrganizationAccountAccessRole"
  #     iam_user_access_to_billing  = "DENY"
  #     tags = {
  #       Tag-Key = "tag-value"
  #     }
  #   }
  #   shared-services = {
  #     email                       = "root-accounts+shared-services@acme.com"
  #   }
  #   dev = {
  #     email                       = "root-accounts+dev@acme.com"
  #   }
  #   stage = {
  #     email                       = "root-accounts+stage@acme.com"
  #   }
  #   prod = {
  #     email                       = "root-accounts+prod@acme.com"
  #   }
  # }
}

# ---------------------------------------------------------------------------------------------------------------------
# OPTIONAL PARAMETERS
# ---------------------------------------------------------------------------------------------------------------------

variable "create_organization" {
  description = "Set to true to create/configure AWS Organizations for the first time in this account. If you already configured AWS Organizations in your account, set this to false; alternatively, you could set it to true and run 'terraform import' to import you existing Organization."
  type        = bool
  default     = false
}

variable "users" {
  description = "A map of users to create. The keys are the user names and the values are an object with the optional keys 'groups' (a list of IAM groups to add the user to), 'tags' (a map of tags to apply to the user), 'pgp_key' (either a base-64 encoded PGP public key, or a keybase username in the form keybase:username, used to encrypt the user's credentials; required if create_login_profile or create_access_keys is true), 'create_login_profile' (if set to true, create a password to login to the AWS Web Console), 'create_access_keys' (if set to true, create access keys for the user), 'path' (the path), and 'permissions_boundary' (the ARN of the policy that is used to set the permissions boundary for the user)."

  # Ideally, this would be a map of (string, object), but object does not support optional properties, and we want
  # users to be able to specify, say, tags for some users, but not for others. We can't use a map(any) either, as that
  # would require the values to all have the same type, and due to optional parameters, that wouldn't work either. So,
  # we have to lamely fall back to any.
  type = any

  # Example:
  # default = {
  #   alice = {
  #     groups = ["user-self-mgmt", "developers", "ssh-sudo-users"]
  #   }
  #
  #   bob = {
  #     path   = "/"
  #     groups = ["user-self-mgmt", "ops", "admins"]
  #     tags   = {
  #       foo = "bar"
  #     }
  #   }
  #
  #   carol = {
  #     groups               = ["user-self-mgmt", "developers", "ssh-users"]
  #     pgp_key              = "keybase:carol_on_keybase"
  #     create_login_profile = true
  #     create_access_keys   = true
  #   }
  # }

  default = {}
}

variable "force_destroy" {
  description = "If set to true, when you run 'terraform destroy', delete all objects from all S3 buckets and any IAM users created by this module so that everything can be destroyed without error. Warning: these objects are not recoverable so only use this if you're absolutely sure you want to permanently delete everything! This is mostly useful when testing."
  type        = bool
  default     = false
}

# ---------------------------------------------------------------------------------------------------------------------
# IAM ACCESS ANALYZER MODULE EXAMPLE PARAMETERS
# ---------------------------------------------------------------------------------------------------------------------

variable "enable_iam_access_analyzer" {
  description = "A feature flag to enable or disable this module."
  type        = bool
  default     = false
// TODO -> this needs to be true, as IAM Access Analyzer needs to be enabled for CIS across all regions. Maybe we should even remove this variable from the example?
}

# This variable sets the type of the IAM Access Analyzer. Depending on the trust zone required for the analyzer to cover,
# the possible values are:
# - ACCOUNT;
# - ORGANIZATION.
# When set to ACCOUNT - the trust zone for the IAM Access Analyzer will be limited to just the account and resources
# only within this account will be scanned, instead of the organizational boundaries and its policies.
# When set to ORGANIZATION - the trust zone will be set to the whole organization, which allows the IAM Access Analyzer
# to scan relevant resources shared and applicable within the bounds of the organization. The AWS account with type of
# IAM Access Analyzer type set to ORGANIZATION, must
# - an AWS organization master account;
# - or be part of an AWS organization & set as a delegated admin for this feature.
#
# For more information, please read here: https://docs.aws.amazon.com/IAM/latest/UserGuide/what-is-access-analyzer.html
variable "iam_access_analyzer_type" {
  description = "If set to ORGANIZATION, the analyzer will be scanning the current organization and any policies that refer to linked resources and their policies within the organization's boundaries."
  type        = string
  default     = "ORGANIZATION"
}

variable "iam_access_analyzer_name" {
  description = "The name of the IAM Access Analyzer module"
  type        = string
  default     = "baseline_root-iam_access_analyzer"
}
----

Finally, add some useful outputs in `outputs.tf`:

.infrastructure-modules/landingzone/account-baseline-root/outputs.tf
[source,hcl]
----
# ---------------------------------------------------------------------------------------------------------------------
# CONFIG OUTPUTS
# ---------------------------------------------------------------------------------------------------------------------

//TODO -> this needs fixing in the example - currently not referencing a real output
//output "config_s3_bucket_name" {
//  description = "The name of the S3 bucket used by AWS Config to store configuration items."
//  value       = module.root_baseline.config_s3_bucket_name
//}
//
//output "config_s3_bucket_arn" {
//  description = "The ARN of the S3 bucket used by AWS Config to store configuration items."
//  value       = module.root_baseline.config_s3_bucket_arn
//}

output "config_iam_role_arns" {
  description = "The ARNs of the IAM role used by the config recorder."
  value       = module.root_baseline.config_iam_role_arns
}

output "config_sns_topic_arns" {
  description = "The ARNs of the SNS Topic used by the config notifications."
  value       = module.root_baseline.config_sns_topic_arns
}

output "config_recorder_names" {
  description = "The names of the configuration recorder."
  value       = module.root_baseline.config_recorder_names
}

# ---------------------------------------------------------------------------------------------------------------------
# ORGANIZATIONS OUTPUTS
# ---------------------------------------------------------------------------------------------------------------------

output "organization_arn" {
  description = "ARN of the organization."
  value       = module.root_baseline.organization_arn
}

output "organization_id" {
  description = "Identifier of the organization."
  value       = module.root_baseline.organization_id
}

output "master_account_arn" {
  description = "ARN of the master account."
  value       = module.root_baseline.master_account_arn
}

output "master_account_id" {
  description = "Identifier of the master account."
  value       = module.root_baseline.master_account_id
}

output "master_account_email" {
  description = "Email address of the master account."
  value       = module.root_baseline.master_account_email
}

output "child_accounts" {
  description = "A map of all accounts created by this module (NOT including the root account). The keys are the names of the accounts and the values are the attributes for the account as defined in the aws_organizations_account resource."
  value       = module.root_baseline.child_accounts
}

# ---------------------------------------------------------------------------------------------------------------------
# CLOUDTRAIL OUTPUTS
# ---------------------------------------------------------------------------------------------------------------------

output "cloudtrail_trail_arn" {
  description = "The ARN of the cloudtrail trail."
  value       = module.root_baseline.cloudtrail_trail_arn
}

output "cloudtrail_s3_bucket_name" {
  description = "The name of the S3 bucket where cloudtrail logs are delivered."
  value       = module.root_baseline.cloudtrail_s3_bucket_name
}

output "cloudtrail_s3_bucket_arn" {
  description = "The ARN of the S3 bucket where cloudtrail logs are delivered."
  value       = module.root_baseline.cloudtrail_s3_bucket_arn
}
//todo -> same as last
//output "cloudtrail_kms_key_arn" {
//  description = "The ARN of the KMS key used by the S3 bucket to encrypt cloudtrail logs."
//  value       = module.root_baseline.cloudtrail_kms_key_arn
//}
//
//output "cloudtrail_kms_key_alias_name" {
//  description = "The alias of the KMS key used by the S3 bucket to encrypt cloudtrail logs."
//  value       = module.root_baseline.cloudtrail_kms_key_alias_name
//}

output "cloudtrail_iam_role_name" {
  description = "The name of the IAM role used by the cloudwatch log group."
  value       = module.root_baseline.cloudtrail_iam_role_name
}

output "cloudtrail_iam_role_arn" {
  description = "The ARN of the IAM role used by the cloudwatch log group."
  value       = module.root_baseline.cloudtrail_iam_role_arn
}
----

At this point, you'll want to test your code. See
link:/guides/foundations/how-to-use-gruntwork-infrastructure-as-code-library#manual_tests_terraform[Manual tests for Terraform code] and
link:/guides/foundations/how-to-use-gruntwork-infrastructure-as-code-library#automated_tests_terraform[Automated tests for Terraform code]
for instructions.

Once the module is working the way you want, submit a pull request, get your changes merged into the master branch, and create a new versioned release by using a Git tag. For example, to create a v0.3.0 release:

[source,bash]
----
git add landingzone/account-baseline-root
git commit -m "Add root account baseline wrapper module"
git tag -a "v0.3.0" -m "Created root account baseline module"
git push --follow-tags
----

NOTE: This guide will use https://github.com/gruntwork-io/terragrunt[Terragrunt] and its associated file and folder
structure to deploy Terraform modules. Please note that *Terragrunt is NOT required for using Terraform modules from the Gruntwork Infrastructure as Code Library.* Check out `link`:/guides/foundations/how-to-use-gruntwork-infrastructure-as-code-library[How to use the Gruntwork Infrastructure as Code Library]
for instructions on alternative options, such as how to
link:/guides/foundations/how-to-use-gruntwork-infrastructure-as-code-library#deploy_using_plain_terraform[deploying how to use plain terraform].

Next, create a `terragrunt.hcl` file in `infrastructure-live`. It should go under the file path `root/_global/account-baseline`:

----
infrastructure-live
   root
     _global
       account-baseline
         terragrunt.hcl
----

Point the `source` URL in your `terragrunt.hcl` file to your `account-baseline` wrapper module in the `infrastructure-modules`
repo, setting the `ref` param to the version you released earlier:

.infrastructure-live/root/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
terraform {
  source = "git::git@github.com/<YOUR_ORG>/infrastructure-modules.git//landingzone/account-baseline-root?ref=v0.3.0"

  # This module deploys some resources (e.g., AWS Config) across all AWS regions, each of which needs its own provider,
  # which in Terraform means a separate process. To avoid all these processes thrashing the CPU, which leads to network
  # connectivity issues, we limit the parallelism here.
  extra_arguments "parallelism" {
    commands  = get_terraform_commands_that_need_parallelism()
    arguments = ["-parallelism=2"]
  }
}
----

[.exceptional]
IMPORTANT: We **strongly** recommend setting Terraform parallelism to a low value (e.g., `-parallelism=2`), as shown above, with the `account-baseline-xxx` modules. This is because these modules deploy multi-region resources (e.g., GuardDuty, AWS Config, etc), and for each region, Terraform spins up a separate process, so if you don't limit the parallelism, it may peg all your CPU cores and lead to network connectivity errors.

Set the variables for the `account-baseline-root` module in this environment in the `inputs = { ... }` block of `terragrunt.hcl`:

.infrastructure-live/root/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
inputs = {
  # Fill in your region you want to use (only used for API calls) and the ID of your root AWS account
  aws_region     = "us-east-2"
  aws_account_id = "<ROOT_ACCOUNT_ID>"

  # Prefix all resources with this name
  name_prefix = "<COMPANY_NAME>-root"

  # If you've already created an AWS Organization in your root account, set this to false and you'll be able to import it later in this guide
  create_organization = true

  # The child AWS accounts to create in this AWS organization
  child_accounts = {
    logs = {
      email = "root-accounts+logs@acme.com"

      # Mark this account as the logs account, used to aggregate all AWS Config and CloudTrail data.
      is_logs_account = true
    },
    security = {
      email = "root-accounts+security@acme.com"
    },
    shared-services = {
      email = "root-accounts+shared-services@acme.com"
    },
    dev = {
      email = "root-accounts+dev@acme.com"
    },
    stage = {
      email = "root-accounts+stage@acme.com"
    },
    prod = {
      email = "root-accounts+prod@acme.com"
    }
  }

  # The IAM users to create in this account. Since this is the root account, you should only create IAM users for a
  # small handful of trusted admins.
  #
  # NOTE: Make sure to include the IAM user you created manually here! We'll import the user into Terraform state in
  # the next step of this guide, allowing you to manage this user as code going forward.
  users = {
    alice = {
      groups               = ["support"]
      pgp_key              = "keybase:alice"
      create_login_profile = true
      create_access_keys   = false
    },
    bob = {
      groups               = ["billing"]
      pgp_key              = "keybase:bob"
      create_login_profile = true
      create_access_keys   = false
    }
  }
}
----

The example code above does the following:

. **Create 6 child AWS accounts**. These are the accounts described in the <<child_accounts>> sections.

. **Associate an email address with each of the child accounts**. This will be the email address for the root user of
each account and AWS requires that the root user's email address is _globally_ unique, so it cannot be the email
address you used for the root account or any of the other child accounts. You'll have to either create multiple email
accounts in your company's email system, or, if your company uses Gmail (perhaps as part of G Suite), you can take
advantage of the fact that https://gmail.googleblog.com/2008/03/2-hidden-ways-to-get-more-from-your.html[Gmail
  ignores everything after a plus sign in an email address], so that while AWS will see
`root-accounts+security@your-company.com`, `root-accounts+shared@your-company.com`, and
`root-accounts+dev@your-company.com` as three unique email addresses, Gmail will see them all as the same email
address, `root-accounts@your-company.com`.

. **Mark one of the child accounts as a logs account**. We set `is_logs_account = true` on one of the child accounts
to indicate it is the logs account where we will aggregate AWS Config, CloudTrail, IAM Access Analyzer and Security Hub data from all the other accounts.
The `account-baseline-root` module will automatically create an S3 bucket for AWS Config and an S3 bucket and KMS CMK
for CloudTrail in this account and configure the root account to send all the AWS Config and CloudTrail data to these
S3 buckets. Later on, you'll configure all the other accounts to send their data to these S3 buckets too.

. **Create IAM groups**. By default, `account-baseline-root` will **not** create a `full-access` IAM group as CIS requirement 1.16 guides. It will create a `support` and a `billing` IAM group (for the support and finance teams).

. **Create IAM users**. For this example, we create `alice` and `bob`, adding `alice` to the `full-access`
IAM group and `carol` to the `billing` IAM group. _Note_: your own IAM user (the one you created manually) should be
in the `users` list; we'll use the `import` command to put this user under Terraform management shortly.

. **Generate a password for each user**. We encrypt this password with that users PGP key from Keybase (well come
back to how to handle the passwords shortly).

Pull in the https://www.terraform.io/docs/backends/[backend] settings from a root `terragrunt.hcl` file that you
`include` in each child `terragrunt.hcl`:

.infrastructure-live/root/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
include {
  path = find_in_parent_folders()
}
----

Next, you need to authenticate as your IAM user in the root account. There are
https://blog.gruntwork.io/a-comprehensive-guide-to-authenticating-to-aws-on-the-command-line-63656a686799[multiple ways to authenticate to AWS on the CLI];
in this guide, we'll use the open source tool https://github.com/99designs/aws-vault[aws-vault].
https://github.com/99designs/aws-vault#installing[Install aws-vault] and add to it the Access Keys you saved earlier
from your IAM user:

[source,bash]
----
$ aws-vault add root-iam-user
Enter Access Key Id: XXXXXXXXXXXX
Enter Secret Key: YYYYYYYYYYYY
----

You should also enable MFA for the IAM user (https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa_enable_virtual.html)[see the AWS docs on enabling a virtual MFA device]) and add the configuration to your profile as follows:
[source,bash]
----
mfa_serial=arn:aws:iam::<YOUR_ROOT_ACCOUNT_ID>:mfa/<YOUR_IAM_USER>
----

Next, https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html[install the AWS CLI], and check that
authentication is working:

[source,bash]
----
aws-vault exec root-iam-user -- aws sts get-caller-identity
----

You should get JSON output with information about your IAM user:

[source,json]
----
{
  "UserId": "AIDAXXXXXXXXXXXX",
  "Account": "<ROOT_ACCOUNT_ID>",
  "Arn": "arn:aws:iam::<ROOT_ACCOUNT_ID>:user/<YOUR_IAM_USER>"
}
----

You're now almost ready to deploy the `account-baseline` module in the root account. But first, you may need to import
some existing resources.

=== Import existing resources from the root account

Before applying the security baseline to the root account, we need to import any existing resourcesincluding the IAM
user you created manually earlierinto Terraform state, so that Terraform manages those existing resources instead of
trying to create totally new ones. You can do this using the
https://www.terraform.io/docs/import/index.html[`import` command], which uses the format:

[source,bash]
----
terraform import <ADDRESS> <ID>
----

Where `<ADDRESS>` is the https://www.terraform.io/docs/internals/resource-addressing.html[address] of the Terraform
resource you're importing and `<ID>` is a resource-specific identifier (e.g., for `aws_instance`, it's the instance ID,
whereas for `aws_lb`, it's the load balancer's namecheck the docs for the resource to find out what to use).

As a first example, let's import the IAM user you created manually in the root account. IAM users are managed using the
`aws_iam_user` resource, and the
https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_user#import[documentation for that
resource] tells us to use the user's `name` as the `<ID>`; we'll assume for this example that your IAM user's name was
`alice`, who is already one of the entries in the `users` variable in `terragrunt.hcl`. So now we need the `<ADDRESS>`.
An easy way to get it is to run `plan`:

[source,bash]
----
cd infrastructure-live/root/_global/account-baseline
aws-vault exec root-iam-user -- terragrunt plan
----

You should get a whole bunch of log output, including something that looks like this:

----
------------------------------------------------------------------------

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create
 <= read (data resources)

Terraform will perform the following actions:

# ... (ommitting lots of log output for simplicity) ...

# module.root_baseline.module.iam_users.aws_iam_user.user["alice"] will be created
  + resource "aws_iam_user" "user" {
      + arn           = (known after apply)
      + force_destroy = true
      + id            = (known after apply)
      + name          = "alice"
      + path          = "/"
      + unique_id     = (known after apply)
    }

# ... (ommitting lots of log output for simplicity) ...

Plan: 160 to add, 0 to change, 0 to destroy.

------------------------------------------------------------------------

Note: You didn't specify an "-out" parameter to save this plan, so Terraform
can't guarantee that exactly these actions will be performed if
"terraform apply" is subsequently run.
----

This `plan` output is telling you that Terraform will create a bunch of resources, including the `aws_iam_user` named
`alice`. Of course, this user already exists, so we want to `import` the user rather than create it again. The text
next to the `#` gives you the `<ADDRESS>` to use:

----
# module.root_baseline.module.iam_users.aws_iam_user.user["alice"] will be created
----

So the `<ADDRESS>` you want is `module.root_baseline.module.iam_users.aws_iam_user.user["alice"]`. Now, normally, you'd
run `import` right away, but due two Terraform bugs, https://github.com/hashicorp/terraform/issues/13018[#13018] and
https://github.com/hashicorp/terraform/issues/26211[#26211], `import` doesn't work on certain types of modulesnamely,
those with nested `provider` blocks that use dynamic dataand will produce an error like `unknown variable accessed:
var.region in:`. One of these bugs has been open for over 3 years, so we built a workaround for it in Terragrunt: the
https://terragrunt.gruntwork.io/docs/reference/cli-options/#aws-provider-patch[`aws-provider-patch` command].

The idea behind the workaround is to temporarily hard-code the dynamic data in nested `provider` blocks. In particular,
we need to temporarily hard-code some of the `region` and `role_arn` parameters of the nested `provider` blocks used by
`account-baseline-root` as follows:

[source,bash]
----
terragrunt aws-provider-patch \
  --terragrunt-override-attr region="eu-west-1" \
  --terragrunt-override-attr assume_role.role_arn=""
----

_Note: You can use any region you want for the `region` parameter. It's just temporary. However, `role_arn` must be set
to an empty string or Terraform will complain._

After running this command, you can finally import your IAM user:

[source,bash]
----
aws-vault exec root-iam-user -- terragrunt import \
  'module.root_baseline.module.iam_users.aws_iam_user.user["alice"]' \
  'alice'
----

You should see log output that looks something like this:

----
[terragrunt] 2020/10/13 14:19:16 Running command: terraform import module.root_baseline.module.iam_users.aws_iam_user.user["alice"] alice
module.root_baseline.module.iam_users.aws_iam_user.user["alice"]: Importing from ID "alice"...
module.root_baseline.module.iam_users.aws_iam_user.user["alice"]: Import prepared!
  Prepared aws_iam_user for import
module.root_baseline.module.iam_users.aws_iam_user.user["alice"]: Refreshing state... [id=alice]

Import successful!

The resources that were imported are shown above. These resources are now in
your Terraform state and will henceforth be managed by Terraform.
----

You'll now be able to manage that IAM user as code going forward!

If you created other resources manually in the root account, you may want to `import` them too, so you can manage
everything as code, and so that Terraform doesn't try to create any duplicate resources. For example, if you already
manually created an AWS Organization in your root account, you'll need to import it using a command that looks like
this:

[source,bash]
----
aws-vault exec root-iam-user -- terragrunt import \
  'module.root_baseline.module.organization.aws_organizations_organization.root[0]' \
  '<ORG_ID>'
----

Where `<ORG_ID>` is the ID of your AWS Organization. Note that this is NOT the same as the AWS account ID, but a
separate ID you can find by going to the https://console.aws.amazon.com/organizations/home[AWS Organizations] page in
the AWS console, clicking on your root account (the one with a star to the left of it), and looking at the root
account's ARN, which will look something like, `arn:aws:organizations::<ACCOUNT_ID>:account/<ORG_ID>/<ACCOUNT_ID>`. The
`<ORG_ID>` is the part between slashes, and it'll look something like `o-a2lce3bbqq`.

You may also want to import child accounts you created manually. You'll need to add each of these to the
`child_accounts` variable in `terragrunt.hcl`, and you can then import each one as follows:

[source,bash]
----
aws-vault exec root-iam-user -- terragrunt import \
  'module.root_baseline.module.organization.aws_organizations_account.child_accounts["<ACCOUNT_NAME>"]' \
  '<ACCOUNT_ID>'
----

Where `<ACCOUNT_NAME>` is the name you used for the account in the `child_accounts` variable and `<ACCOUNT_ID>` is the
12-digit ID of that AWS account.

Once you're done importing, you'll want to undo the `aws-provider-patch` workaround. The easiest way to do that is to
delete the `.terraform` or `.terragrunt-cache` folders to remove any locally cached modules, as they would've been
modified by the `aws-provider-patch` command.

[source,bash]
----
rm -rf .terragrunt-cache
----

=== Apply the security baseline to the root account

You're now ready to apply the security baseline to the root account. You should be authenticated as the same IAM user
in the root account as in the previous two sections. To apply the security baseline, you run `terragrunt apply`:

[source,bash]
----
cd infrastructure-live/root/_global/account-baseline
aws-vault exec root-iam-user -- terragrunt apply
----

[.exceptional]
IMPORTANT: On some operating systems, such as MacOS, you may also need to increase your open files limit to avoid "pipe: too many open files" errors by running: `ulimit -n 1024`.

Once `apply` completes, you should see output variables with all of your account IDs, the name of the AWS Config S3
bucket, the name of the CloudTrail S3 bucket, and the ARN of the CloudTrail KMS key:

[source,hcl]
----
# (this output has been edited to be easier to read)
child_accounts = {
  "dev" = {
    "email" = "root-accounts+dev@acme.com"
    "id" = "<DEV_ACCOUNT_ID>"
    # (...)
  }
  "logs" = {
    "email" = "root-accounts+logs@acme.com"
    "id" = "<LOGS_ACCOUNT_ID>"
    # (...)
  }
  "prod" = {
    "email" = "root-accounts+prod@acme.com"
    "id" = "<PROD_ACCOUNT_ID>"
    # (...)
  }
  "security" = {
    "email" = "root-accounts+security@acme.com"
    "id" = "<SECURITY_ACCOUNT_ID>"
    # (...)
  }
  "shared-services" = {
    "email" = "root-accounts+shared-services@acme.com"
    "id" = "<SHARED_SERVICES_ACCOUNT_ID>"
    # (...)
  }
  "stage" = {
    "email" = "root-accounts+stage@acme.com"
    "id" = "<STAGE_ACCOUNT_ID>"
    # (...)
  }
}
cloudtrail_kms_key_arn    = "<CLOUDTRAIL_KMS_KEY_ARN>"
cloudtrail_s3_bucket_name = "<CLOUDTRAIL_BUCKET_NAME>"
config_s3_bucket_name     = "<CONFIG_BUCKET_NAME>"
----

Take note of all of this data, as you'll need it again shortly!

One other useful output will be the encrypted passwords for any IAM users you created:

[source,hcl]
----
user_passwords = {
  "alice" = "wcBMA7E6Kn/t1YPfAQgAVSXlUzumcs4UyO8E5q099YnnU="
  "bob" = "wcBMA7E6Kn/t1YPfAQgACgbdb1mYtQx7EL4hnVWtYAi="
}
----

Send the encrypted password to each user, along with their user name, and the IAM user sign-in URL for the root account.
Each user can then decrypt the password on their own computer (which should have their PGP key) as follows:

[source,bash]
----
echo "<PASSWORD>" | base64 --decode | keybase pgp decrypt
----

=== Reset the root user password in each child account

When creating the child accounts, you may have noticed that you provided an email address for each root user, but
confusingly, not a password. So how do you login as the root user then? It's not obvious, but the answer is that you
https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys_retrieve.html#reset-root-password[reset the root user password],
using the "Forgot your password?" prompt on the https://console.aws.amazon.com/[root user login page]. AWS will email
you a reset link, which you can click to go to a page that will allow you to configure a password for the root user.
Use this process to reset the password for the root user of each child account you created.

=== Lock down the root user in the child accounts

Once you're able to access the root user of each child account, you should follow the steps in <<lock_down_root_user>>
for each of those child accountsincluding enabling MFA and deleting the root user's access keysand (almost) never use
those root users again.

=== Apply the security baseline to the logs account

The next step is to configure the logs account, which is used to aggregate AWS Config and CloudTrail data from all the
other accountss. To do this, create a new module called `account-baseline-app`  in your `infrastructure-modules` repo:

----
infrastructure-modules
   landingzone
     account-baseline-root
     account-baseline-app
       main.tf
       outputs.tf
       variables.tf
----

Inside of `main.tf`, configure your AWS provider and Terraform settings:

.infrastructure-modules/landingzone/account-baseline-app/main.tf
[source,hcl]
----
provider "aws" {
  # The AWS region in which all resources will be created
  region = var.aws_region

  # Require a 3.x version of the AWS provider
  version = "~> 3.40"

  # Only these AWS Account IDs may be operated on by this template
  allowed_account_ids = [var.aws_account_id]
}

terraform {
  # The configuration for this backend will be filled in by Terragrunt or via a backend.hcl file. See
  # https://www.terraform.io/docs/backends/config.html#partial-configuration
  backend "s3" {}

  # Only allow this Terraform version. Note that if you upgrade to a newer version, Terraform won't allow you to use an
  # older version, so when you upgrade, you should upgrade everyone on your team and your CI servers all at once.
  required_version = "= 0.12.26"
}
----

Next, use the `account-baseline-app` module from the Gruntwork Infrastructure as Code Library:

.infrastructure-modules/landingzone/account-baseline-app/main.tf
[source,hcl]
----
module "app_baseline" {
  # When using these modules in your own templates, you will need to use a Git URL with a ref attribute that pins you
  # to a specific version of the modules, such as the following example:
  source = "git::git@github.com:gruntwork-io/terraform-aws-cis-service-catalog.git//modules/landingzone/account-baseline-app?ref=v1.0.0"

  aws_account_id = data.aws_caller_identity.current.account_id
  aws_region     = var.aws_region
  name_prefix    = var.name_prefix

  allow_read_only_access_from_other_account_arns = var.allow_read_only_access_from_other_account_arns
  allow_billing_access_from_other_account_arns   = var.allow_billing_access_from_other_account_arns
  allow_support_access_from_other_account_arns   = var.allow_support_access_from_other_account_arns
  allow_logs_access_from_other_account_arns      = var.allow_logs_access_from_other_account_arns
  allow_ssh_grunt_access_from_other_account_arns = var.allow_ssh_grunt_access_from_other_account_arns
  allow_dev_access_from_other_account_arns       = var.allow_dev_access_from_other_account_arns
  allow_full_access_from_other_account_arns      = var.allow_full_access_from_other_account_arns
  allow_auto_deploy_from_other_account_arns      = var.allow_auto_deploy_from_other_account_arns

  auto_deploy_permissions = var.auto_deploy_permissions
  dev_permitted_services  = var.dev_permitted_services

  # We assume the S3 bucket for AWS Config has already been created by account-baseline-root
  config_s3_bucket_name                            = var.config_s3_bucket_name
  config_should_create_s3_bucket                   = var.config_should_create_s3_bucket
  config_should_create_sns_topic                   = var.config_should_create_sns_topic
  config_sns_topic_name                            = var.config_sns_topic_name
  config_central_account_id                        = var.config_central_account_id
  config_aggregate_config_data_in_external_account = var.config_aggregate_config_data_in_external_account
  config_linked_accounts                           = var.config_linked_accounts

  # We assume the S3 bucket and KMS key for CloudTrail have already been created by account-baseline-root
  cloudtrail_s3_bucket_name                             = var.cloudtrail_s3_bucket_name
  cloudtrail_s3_bucket_already_exists                   = var.cloudtrail_s3_bucket_already_exists
  cloudtrail_kms_key_arn                                = var.cloudtrail_kms_key_arn
  cloudtrail_kms_key_administrator_iam_arns             = var.cloudtrail_kms_key_administrator_iam_arns
  cloudtrail_kms_key_user_iam_arns                      = var.cloudtrail_kms_key_user_iam_arns
  cloudtrail_external_aws_account_ids_with_write_access = var.cloudtrail_external_aws_account_ids_with_write_access

  # Cloudtrail Benchmark Alarms
  cloudtrail_benchmark_alarm_sns_topic_already_exists    = var.cloudtrail_benchmark_alarm_sns_topic_already_exists
  cloudtrail_benchmark_alarm_sns_topic_arn               = var.cloudtrail_benchmark_alarm_sns_topic_arn
  cloudtrail_benchmark_alarm_sns_topic_name              = var.cloudtrail_benchmark_alarm_sns_topic_name
  cloudtrail_benchmark_alarm_sns_topic_kms_master_key_id = var.cloudtrail_benchmark_alarm_sns_topic_kms_master_key_id

  # Security Hub
  security_hub_seed_region                    = var.aws_region
  security_hub_associate_to_master_account_id = var.security_hub_associate_to_master_account_id
  security_hub_external_member_accounts       = var.security_hub_external_member_accounts

  # These are variables you only need to set at test time so that everything can be deleted cleanly. You will likely
  # NOT need to set this in any real environments.
  cloudtrail_force_destroy = var.force_destroy
  config_force_destroy     = var.force_destroy
}
----

Create all the corresponding input variables for `account-baseline-app` in `variables.tf`:

.infrastructure-modules/landingzone/account-baseline-app/variables.tf
[source,hcl]
----
# ---------------------------------------------------------------------------------------------------------------------
# REQUIRED PARAMETERS
# ---------------------------------------------------------------------------------------------------------------------

variable "name_prefix" {
  description = "The name used to prefix AWS Config and Cloudtrail resources, including the S3 bucket names and SNS topics used for each."
  type        = string
}

# ---------------------------------------------------------------------------------------------------------------------
# OPTIONAL MODULE PARAMETERS
# These variables have defaults, but may be overridden by the operator.
# ---------------------------------------------------------------------------------------------------------------------

variable "aws_region" {
  description = "The AWS region in which all resources will be created"
  type        = string
  default     = "us-east-1"
}

variable "force_destroy" {
  description = "If set to true, when you run 'terraform destroy', delete all objects from all S3 buckets and any IAM users created by this module so that everything can be destroyed without error. Warning: these objects are not recoverable so only use this if you're absolutely sure you want to permanently delete everything! This is mostly useful when testing."
  type        = bool
  default     = false
}

# ---------------------------------------------------------------------------------------------------------------------
# OPTIONAL AWS CONFIG PARAMETERS
# These variables must be passed in by the operator. In a real-world usage, some of these variables might not be needed
# and you can instead inline the values directly in main.tf.
# ---------------------------------------------------------------------------------------------------------------------

variable "config_should_create_sns_topic" {
  description = "Set to true to create an sns topic in this account for sending AWS Config notifications (e.g., if this is the logs account). Set to false to assume the topic specified in var.config_sns_topic_name already exists in another AWS account (e.g., if this is the stage or prod account and var.config_sns_topic_name is the name of an sns topic in the logs account)."
  type        = bool
  default     = false
}

variable "config_s3_bucket_name" {
  description = "The name of the S3 Bucket where Config items will be stored. In this example code, we're assuming this bucket has already been created (e.g., by the account-baseline-root module)."
  type        = string
  default     = null
}

variable "config_should_create_s3_bucket" {
  description = "Set to true to create an S3 bucket of name var.config_s3_bucket_name in this account for storing AWS Config data (e.g., if this is the logs account). Set to false to assume the bucket specified in var.config_s3_bucket_name already exists in another AWS account (e.g., if this is the stage or prod account and var.config_s3_bucket_name is the name of a bucket in the logs account)."
  type        = bool
  default     = false
}

variable "config_linked_accounts" {
  description = "Provide a list of AWS account IDs that will be allowed to send AWS Config data to this account. This is only required if you are aggregating config data in this account (e.g., this is the logs account) from other accounts."
  type        = list(string)
  default     = []
}

variable "config_aggregate_config_data_in_external_account" {
  description = "Set to true to send the AWS Config data to another account (e.g., a logs account) for aggregation purposes. You must set the ID of that other account via the config_central_account_id variable. This redundant variable has to exist because Terraform does not allow computed data in count and for_each parameters and var.config_central_account_id may be computed if its the ID of a newly-created AWS account."
  type        = bool
  default     = false
}

variable "config_central_account_id" {
  description = "Set this variable to the ID of the account where the S3 bucket and SNS topics used for AWS Config lives (e.g., set this to the ID of the logs account, or if you don't have one, the root account). "
  type        = string
  default     = null
}

variable "config_sns_topic_name" {
  description = "the name of the sns topic in where aws config notifications will be sent. can be in the same account or in another account."
  type        = string
  default     = "configtopic"
}

# ---------------------------------------------------------------------------------------------------------------------
# OPTIONAL CLOUDTRAIL PARAMETERS
# These variables must be passed in by the operator. In a real-world usage, some of these variables might not be needed
# and you can instead inline the values directly in main.tf.
# ---------------------------------------------------------------------------------------------------------------------

variable "cloudtrail_s3_bucket_name" {
  description = "The name of the S3 Bucket where CloudTrail logs will be stored. In this example code, we're assuming this bucket has already been created (e.g., by the account-baseline-root module)."
  type        = string
  default     = null
}

variable "cloudtrail_s3_bucket_already_exists" {
  description = "Set to false to create an S3 bucket of name var.cloudtrail_s3_bucket_name in this account for storing CloudTrail logs (e.g., if this is the logs account). Set to true to assume the bucket specified in var.cloudtrail_s3_bucket_name already exists in another AWS account (e.g., if this is the stage or prod account and var.cloudtrail_s3_bucket_name is the name of a bucket in the logs account)."
  type        = bool
  default     = true
}

variable "cloudtrail_external_aws_account_ids_with_write_access" {
  description = "Provide a list of AWS account IDs that will be allowed to send CloudTrail logs to this account. This is only required if you are aggregating CloudTrail logs in this account (e.g., this is the logs account) from other accounts."
  type        = list(string)
  default     = []
}

variable "cloudtrail_kms_key_arn" {
  description = "All CloudTrail Logs will be encrypted with a KMS CMK (Customer Master Key) that governs access to write API calls older than 7 days and all read API calls. In this example code, we're assuming this CMK has already been created (e.g., by the account-baseline-root module), so set this to the ARN of that CMK."
  type        = string
  default     = null
}

variable "cloudtrail_kms_key_administrator_iam_arns" {
  description = "All CloudTrail Logs will be encrypted with a KMS CMK (Customer Master Key) that governs access to write API calls older than 7 days and all read API calls. If you are aggregating CloudTrail logs and creating the CMK in this account (e.g., if this is the logs account), you MUST specify at least one IAM user (or other IAM ARN) that will be given administrator permissions for CMK, including the ability to change who can access this CMK and the extended log data it protects. If you are aggregating CloudTrail logs in another AWS account and the CMK already exists (e.g., if this is the stage or prod account), set this parameter to an empty list."
  type        = list(string)
  # example = ["arn:aws:iam::<aws-account-id>:user/<iam-user-name>"]
  default = []
}

variable "cloudtrail_kms_key_user_iam_arns" {
  description = "All CloudTrail Logs will be encrypted with a KMS CMK (Customer Master Key) that governs access to write API calls older than 7 days and all read API calls. If you are aggregating CloudTrail logs and creating the CMK in this account (e.g., this is the logs account), you MUST specify at least one IAM user (or other IAM ARN) that will be given user access to this CMK, which will allow this user to read CloudTrail Logs. If you are aggregating CloudTrail logs in another AWS account and the CMK already exists, set this parameter to an empty list (e.g., if this is the stage or prod account)."
  type        = list(string)
  # example = ["arn:aws:iam::<aws-account-id>:user/<iam-user-name>"]
  default = []
}

# Benchmark Alarms Config
variable "cloudtrail_benchmark_alarm_sns_topic_already_exists" {
  description = "If set to true, that means the SNS topic for reporting CIS benchmark alerts already exists and does not need to be created. You must set var.benchmark_alarm_sns_topic_arn when this is set to true."
  # Ideally, this variable isn't necessary but this works around an issue with terraform count where it cannot evaluate
  # counts when they depend on resources that haven't been applied yet. This situation arises when
  # `benchmark_alarm_sns_topic_arn` is an interpolation for an SNS topic resource created in the calling module.
  type    = bool
  default = true
}

variable "cloudtrail_benchmark_alarm_sns_topic_arn" {
  description = "The ARN of an existing SNS topic to notify of alarm status changes."
  type        = string
  default     = null
}

variable "cloudtrail_benchmark_alarm_sns_topic_name" {
  description = "The name of an SNS topic to notify of alarm status changes."
  type        = string
  default     = null
}

variable "cloudtrail_benchmark_alarm_sns_topic_kms_master_key_id" {
  description = "The ID of an AWS-managed or customer-managed customer master key (CMK) to use for encrypting the Amazon SNS topic. Only used if var.benchmark_alarm_sns_topic_already_exists is false."
  type        = string
  default     = null
}

# ---------------------------------------------------------------------------------------------------------------------
#  Modify the following variables to allow users from the security account to assume IAM roles in this account
# ---------------------------------------------------------------------------------------------------------------------

variable "allow_read_only_access_from_other_account_arns" {
  description = "A list of IAM ARNs from other AWS accounts that will be allowed read-only access to this account."
  type        = list(string)
  default     = []
  # Example:
  # default = [
  #   "arn:aws:iam::123445678910:root"
  # ]
}

variable "allow_billing_access_from_other_account_arns" {
  description = "A list of IAM ARNs from other AWS accounts that will be allowed full (read and write) access to the billing info for this account."
  type        = list(string)
  default     = []
  # Example:
  # default = [
  #   "arn:aws:iam::123445678910:root"
  # ]
}

variable "allow_support_access_from_other_account_arns" {
  description = "A list of IAM ARNs from other AWS accounts that will be allowed access to AWS support for this account."
  type        = list(string)
  default     = []
  # Example:
  # default = [
  #   "arn:aws:iam::123445678910:root"
  # ]
}

variable "allow_logs_access_from_other_account_arns" {
  description = "A list of IAM ARNs from other AWS accounts that will be allowed read access to the logs in CloudTrail, AWS Config, and CloudWatch in this account."
  type        = list(string)
  default     = []
  # Example:
  # default = [
  #   "arn:aws:iam::123445678910:root"
  # ]
}

variable "allow_ssh_grunt_access_from_other_account_arns" {
  description = "A list of IAM ARNs from other AWS accounts that will be allowed read access to IAM groups and publish SSH keys. This is used for ssh-grunt."
  type        = list(string)
  default     = []
  # Example:
  # default = [
  #   "arn:aws:iam::123445678910:root"
  # ]
}

variable "allow_dev_access_from_other_account_arns" {
  description = "A list of IAM ARNs from other AWS accounts that will be allowed full (read and write) access to the services in this account specified in var.dev_permitted_services."
  type        = list(string)
  default     = []
  # Example:
  # default = [
  #   "arn:aws:iam::123445678910:root"
  # ]
}

variable "allow_full_access_from_other_account_arns" {
  description = "A list of IAM ARNs from other AWS accounts that will be allowed full (read and write) access to this account."
  type        = list(string)
  default     = []
  # Example:
  # default = [
  #   "arn:aws:iam::123445678910:root"
  # ]
}

variable "allow_auto_deploy_from_other_account_arns" {
  description = "A list of IAM ARNs from other AWS accounts that will be allowed to assume the auto deploy IAM role that has the permissions in var.auto_deploy_permissions."
  type        = list(string)
  default     = []
  # Example:
  # default = [
  #   "arn:aws:iam::123445678910:role/jenkins"
  # ]
}

variable "auto_deploy_permissions" {
  description = "A list of IAM permissions (e.g. ec2:*) that will be added to an IAM Group for doing automated deployments. NOTE: If var.should_create_iam_group_auto_deploy is true, the list must have at least one element (e.g. '*')."
  type        = list(string)
  default     = []
}

variable "dev_permitted_services" {
  description = "A list of AWS services for which the developers from the accounts in var.allow_dev_access_from_other_account_arns will receive full permissions. See https://goo.gl/ZyoHlz to find the IAM Service name. For example, to grant developers access only to EC2 and Amazon Machine Learning, use the value [\"ec2\",\"machinelearning\"]. Do NOT add iam to the list of services, or that will grant Developers de facto admin access."
  type        = list(string)
  default     = []
}

# ---------------------------------------------------------------------------------------------------------------------
# OPTIONAL SECURITY HUB PARAMETERS
# These variables must be passed in by the operator. In a real-world usage, some of these variables might not be needed
# and you can instead inline the values directly in main.tf.
# ---------------------------------------------------------------------------------------------------------------------

variable "security_hub_external_member_accounts" {
  description = "Map of AWS Accounts to add as members to this account's SecurityHub configuration. The keys in this map should each be a unique value (e.g., the account name) and the values should be objects that contain the account ID and Email for sending the invitation."
  # Example:
  # external_member_accounts = {
  #   dev = {
  #     account_id = "210987654321"
  #     email      = "domains+sandbox@acme.com"
  #   },
  #   logs = {
  #     account_id = "902390843483"
  #     email      = "domains+sandbox@acme.com"
  #   },
  # }
  type = map(object({
    account_id = string
    email      = string
  }))
  default = {}
}

variable "security_hub_seed_region" {
  description = "The AWS Region to use as a seed to discover other regions."
  type        = string
  default     = "us-east-1"
}

variable "security_hub_associate_to_master_account_id" {
  description = "AWS Account to join this account's SecurityHub to. Must have already received an invite from this account."
  type        = string
  default     = ""
}
----

At this point, you'll want to test your code. See
link:/guides/foundations/how-to-use-gruntwork-infrastructure-as-code-library#manual_tests_terraform[Manual tests for Terraform code] and
link:/guides/foundations/how-to-use-gruntwork-infrastructure-as-code-library#automated_tests_terraform[Automated tests for Terraform code]
for instructions.

When you're done testing, commit and release your changes:

[source,bash]
----
git add landingzone/account-baseline-app
git commit -m "Add app account baseline wrapper module"
git tag -a "v0.3.1" -m "Created app account baseline module"
git push --follow-tags
----

Create a `terragrunt.hcl` file in `infrastructure-live` under the file path `logs/_global/account-baseline`:

----
infrastructure-live
   root
   logs
     _global
       account-baseline
         terragrunt.hcl
----

Point the `source` URL in your `terragrunt.hcl` file to your `account-baseline-app` wrapper module in the `infrastructure-modules`
repo, setting the `ref` param to the version you released earlier:

.infrastructure-live/logs/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
terraform {
  source = "git::git@github.com/<YOUR_ORG>/infrastructure-modules.git//landingzone/account-baseline-app?ref=v0.3.1"

  # This module deploys some resources (e.g., AWS Config) across all AWS regions, each of which needs its own provider,
  # which in Terraform means a separate process. To avoid all these processes thrashing the CPU, which leads to network
  # connectivity issues, we limit the parallelism here.
  extra_arguments "parallelism" {
    commands  = get_terraform_commands_that_need_parallelism()
    arguments = ["-parallelism=2"]
  }
}
----

[.exceptional]
IMPORTANT: We **strongly** recommend setting Terraform parallelism to a low value (e.g., `-parallelism=2`), as shown above, with the `account-baseline-xxx` modules. This is because these modules deploy multi-region resources (e.g., GuardDuty, AWS Config, etc), and for each region, Terraform spins up a separate process, so if you don't limit the parallelism, it may peg all your CPU cores and lead to network connectivity errors.

Set the variables for the `account-baseline-app` module in this environment in the `inputs = { ... }` block of `terragrunt.hcl`:

.infrastructure-live/logs/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
inputs = {
  # Fill in your region you want to use (only used for API calls) and the ID of your logs AWS account
  aws_region     = "us-east-2"
  aws_account_id = "<LOGS_ACCOUNT_ID>"

  # Prefix all resources with this name
  name_prefix    = "<COMPANY_NAME>-logs"

  # Set to true to create an sns topic in this account for sending AWS Config notifications (e.g., if this is the logs account).
  config_should_create_sns_topic = true

  # Use the S3 bucket that was already created in this logs account by account-baseline-root
  config_s3_bucket_name = "<CONFIG_BUCKET_NAME>"

  config_aggregate_config_data_in_external_account = false
  config_central_account_id                        = null

  # Set to true to create an S3 bucket of name var.config_s3_bucket_name in this account for storing AWS Config data (e.g., if this is the logs account). Set to false to assume the bucket specified in var.config_s3_bucket_name already exists in another AWS account (e.g., if this is the stage or prod account and var.config_s3_bucket_name is the name of a bucket in the logs account).
  config_should_create_s3_bucket = true

  # The name of the SNS topic in where AWS Config notifications will be sent. Can be in the same account or in another account.
  config_sns_topic_name = "<DEFINE_SNS_TOPIC_NAME>"

  # Specify all of the account IDs that should be able to write to the AWS Config in the `logs` account. You might want to set this to the `security` child account, or `dev`, `prod` or `stage` AWS Account IDs.
  config_linked_accounts = ["<ANY_CHILD_AWS_ACCOUNT_ID>", "<SECURITY_ACCOUNT_ID>", "<DEV_ACCOUNT_ID>"]

  # Create a KMS master key that can be used to encrypt CloudTrail data. Make the logs account the admin/user of this key.
  # In practice, this means you can use IAM policies in the logs account to specify who has access to this key.
  cloudtrail_kms_key_administrator_iam_arns = ["arn:aws:iam::<LOGS_ACCOUNT_ID>:root"]
  cloudtrail_kms_key_user_iam_arns          = ["arn:aws:iam::<LOGS_ACCOUNT_ID>:root"]

  # Allow other accounts to write Cloudtrail logs to this account
  # Specify all of the account IDs that should be able to write to the logs account. You might want to set this to the `security` child account, or `dev`, `prod` or `stage` AWS Account IDs.
  cloudtrail_external_aws_account_ids_with_write_access = ["<ANY_CHILD_AWS_ACCOUNT_ID>", "<SECURITY_ACCOUNT_ID>", "<DEV_ACCOUNT_ID>"]

  # Set to false to create an S3 bucket of name var.cloudtrail_s3_bucket_name in this account for storing CloudTrail logs (e.g., if this is the logs account). Set to true to assume the bucket specified in var.cloudtrail_s3_bucket_name already exists in another AWS account (e.g., if this is the stage or prod account and var.cloudtrail_s3_bucket_name is the name of a bucket in the logs account).
  cloudtrail_s3_bucket_already_exists = false
  cloudtrail_kms_key_already_exists = false

  # Use the S3 bucket and KMS key that were already created in this logs account by account-baseline-root
  cloudtrail_s3_bucket_name = "<CLOUDTRAIL_BUCKET_NAME>"
  cloudtrail_kms_key_arn    = "<CLOUDTRAIL_KMS_KEY_ARN>"

  cloudtrail_benchmark_alarm_sns_topic_already_exists = false

  # Set to point to the AWS Account that has set up the Security Hub organisation and has sent out invitations to other AWS Child accounts. For example, get the `root` account to send invitations to `security`, `logs`, `dev`, etc.
  security_hub_associate_to_master_account_id = "<ROOT_ACCOUNT_ID>"
  security_hub_external_member_accounts = { security = {
                                               account_id = "<LOGS_ACCOUNT_ID>"
                                               email      = "root-accounts+logs@acme.com"
                                             }
                                        }

  # Allow users in the security account to assume IAM roles in this account
  allow_read_only_access_from_other_account_arns = ["arn:aws:iam::<SECURITY_ACCOUNT_ID>:root"]
  allow_logs_access_from_other_account_arns      = ["arn:aws:iam::<SECURITY_ACCOUNT_ID>:root"]
}
----

The example above configures the logs account of an AWS Organization as follows:

. **Aggregate CloudTrail Logs**: We configure the logs account to use the S3 bucket and KMS CMK for CloudTrail that
were already created by `account-baseline-root`.

. **Aggregate AWS Config**: We configure the logs account to use the S3 bucket for AWS Config that was already
created by `account-baseline-root`.

. **Allow access from the security account**: We configure IAM roles that IAM users in the security account will be
able to assume to get access to the logs account.

Configure your Terraform backend:

.infrastructure-live/logs/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
include {
  path = find_in_parent_folders()
}
----

You're now going to use an IAM role to authenticate to the logs account. This IAM role is created automatically in each
child account by `account-baseline-root` and has a default name of `OrganizationAccountAccessRole`. There are many ways
to https://blog.gruntwork.io/a-comprehensive-guide-to-authenticating-to-aws-on-the-command-line-63656a686799[assume an IAM role on the CLI];
for this guide, we're going to keep using `aws-vault`.

Open up `~/.aws/config` and you should see a `profile` that was created automatically when you ran
`aws-vault add root-iam-user`  earlier:

[source,text]
----
[profile root-iam-user]
----

Add a new `profile` entry in `~/.aws/config` for your logs account that uses the `root-iam-user` as the
`source_profile`:

[source,text]
----
[profile logs-from-root]
role_arn=arn:aws:iam::<LOGS_ACCOUNT_ID>:role/OrganizationAccountAccessRole
source_profile=root-iam-user
----

Check that you're able to authenticate to the logs account:

[source,bash]
----
aws-vault exec logs-from-root -- aws sts get-caller-identity
----

You should see JSON output indicating that you've successfully assumed an IAM role:

[source,json]
----
{
  "UserId": "AIDAXXXXXXXXXXXX:1597932316055520000",
  "Account": "<LOGS_ACCOUNT_ID>",
  "Arn": "arn:aws:sts::<LOGS_ACCOUNT_ID>:assumed-role/OrganizationAccountAccessRole/1597932316055520000"
}
----

You're now ready to deploy the `account-baseline` module in the logs account by running `terragrunt apply`:

[source,bash]
----
cd infrastructure-live/logs/_global/account-baseline
aws-vault exec logs-from-root -- terragrunt apply
----

[.exceptional]
IMPORTANT: On some operating systems, such as MacOS, you may also need to increase your open files limit to avoid "pipe: too many open files" errors by running: `ulimit -n 1024`.


=== Apply the security baseline to the security account

Now that your logs accounts is fully configured, you need to apply the security baseline to the security account, which
is where all your IAM users and groups will be defined and managed.

Create a new module called `account-baseline-security` in your `infrastructure-modules` repo:

----
infrastructure-modules
   landingzone
     account-baseline-root
     account-baseline-app
     account-baseline-security
       main.tf
       outputs.tf
       variables.tf
----

Inside of `main.tf`, configure your AWS provider and Terraform settings:

.infrastructure-modules/landingzone/account-baseline-security/main.tf
[source,hcl]
----
provider "aws" {
  # The AWS region in which all resources will be created
  region = var.aws_region

  # Require a 2.x version of the AWS provider
  version = "~> 2.6"

  # Only these AWS Account IDs may be operated on by this template
  allowed_account_ids = [var.aws_account_id]
}

terraform {
  # The configuration for this backend will be filled in by Terragrunt or via a backend.hcl file. See
  # https://www.terraform.io/docs/backends/config.html#partial-configuration
  backend "s3" {}

  # Only allow this Terraform version. Note that if you upgrade to a newer version, Terraform won't allow you to use an
  # older version, so when you upgrade, you should upgrade everyone on your team and your CI servers all at once.
  required_version = "= 0.12.26"
}
----

Next, use the `account-baseline-security` module from the Gruntwork Infrastructure as Code Library:

.infrastructure-modules/landingzone/account-baseline-security/main.tf
[source,hcl]
----
module "security_baseline" {
  source = "git::git@github.com:gruntwork-io/terraform-aws-cis-service-catalog.git//modules/landingzone/account-baseline-security?ref=v1.0.0"

  aws_account_id = data.aws_caller_identity.current.account_id
  aws_region     = var.aws_region
  name_prefix    = var.name_prefix

  # Config
  config_central_account_id = var.config_central_account_id
  config_s3_bucket_name     = var.config_s3_bucket_name

  # Cloudtrail
  cloudtrail_s3_bucket_name = var.cloudtrail_s3_bucket_name
  cloudtrail_kms_key_arn    = var.cloudtrail_kms_key_arn

  # IAM Users
  users = var.users

  # Cleanup expired certificates
  cleanup_expired_certs_schedule_expression = var.schedule_expression

  cleanup_expired_certs_report_cloudwatch_metric_namespace = "custom/cis"
  cleanup_expired_certs_report_cloudwatch_metric_name      = "cleanup-expired-iam-certs-count"

  # Security Hub
  security_hub_seed_region                    = var.aws_region
  security_hub_associate_to_master_account_id = var.security_hub_associate_to_master_account_id
}
----

Create all the corresponding input variables for `account-baseline-security` in `variables.tf`:

.infrastructure-modules/landingzone/account-baseline-security/variables.tf
[source,hcl]
----
# ---------------------------------------------------------------------------------------------------------------------
# CIS LANDING-ZONE SECURITY BASELINE MODULE
# ---------------------------------------------------------------------------------------------------------------------
# REQUIRED PARAMETERS
# These variables must be passed in by the operator.
# ---------------------------------------------------------------------------------------------------------------------

variable "name_prefix" {
  description = "The name used to prefix AWS Config and Cloudtrail resources, including the S3 bucket names and SNS topics used for each."
  type        = string
}

variable "aws_region" {
  description = "The AWS Region to use as the global config recorder and seed region for GuardDuty."
  type        = string
}

# AWS Config
variable "config_s3_bucket_name" {
  description = "The name of the S3 Bucket where AWS Config logs will be stored. This could be a bucket in this AWS account or the name of a bucket in another AWS account where logs should be sent. We recommend setting this to the name of a bucket in a separate logs account."
  type        = string
}

variable "config_central_account_id" {
  description = "If the S3 bucket and SNS topics used for AWS Config live in a different AWS account, set this variable to the ID of that account. If the S3 bucket and SNS topics live in this account, set this variable to null. We recommend setting this to the ID of a separate logs account. Only used if var.config_aggregate_config_data_in_external_account is true."
  type        = string
  default     = null
}

# Cloudtrail
variable "cloudtrail_s3_bucket_name" {
  description = "The name of the S3 Bucket where CloudTrail logs will be stored. If value is `null`, defaults to `var.name_prefix`-cloudtrail"
  type        = string
}

variable "cloudtrail_kms_key_arn" {
  description = "All CloudTrail Logs will be encrypted with a KMS CMK (Customer Master Key) that governs access to write API calls older than 7 days and all read API calls. If that CMK already exists, set this to the ARN of that CMK. Otherwise, set this to null, and a new CMK will be created. We recommend setting this to the ARN of a CMK that already exists in a separate logs account."
  type        = string
}

# TLS Expired Certificates
variable "schedule_expression" {
  description = "An expression that defines how often to run the Lambda function to clean up expired IAM certs. For example, cron(0 20 * * ? *) or rate(5 minutes)."
  type        = string
  # Use this default value in case there's no clear guidance how often to cleanup the expired certificates
  default = "rate(5 minutes)"
}

# Security Hub
variable "security_hub_associate_to_master_account_id" {
  description = "AWS Account to join this account's SecurityHub to. Must have already received an invite from this account."
  type        = string
}

# ---------------------------------------------------------------------------------------------------------------------
# OPTIONAL USERS MODULE PARAMETERS
# These variables have defaults, but may be overridden by the operator.
# ---------------------------------------------------------------------------------------------------------------------

variable "users" {
  description = "A map of users to create. The keys are the user names and the values are an object with the optional keys 'groups' (a list of IAM groups to add the user to), 'tags' (a map of tags to apply to the user), 'pgp_key' (either a base-64 encoded PGP public key, or a keybase username in the form keybase:username, used to encrypt the user's credentials; required if create_login_profile or create_access_keys is true), 'create_login_profile' (if set to true, create a password to login to the AWS Web Console), 'create_access_keys' (if set to true, create access keys for the user), 'path' (the path), and 'permissions_boundary' (the ARN of the policy that is used to set the permissions boundary for the user)."

  # Ideally, this would be a map of (string, object), but object does not support optional properties, and we want
  # users to be able to specify, say, tags for some users, but not for others. We can't use a map(any) either, as that
  # would require the values to all have the same type, and due to optional parameters, that wouldn't work either. So,
  # we have to lamely fall back to any.
  type = any

  # Example:
  # users = {
  #   alice = {
  #     groups = ["ssh-sudo-users"]
  #   }
  #
  #   bob = {
  #     path   = "/"
  #     groups = ["iam-admin"]
  #     tags   = {
  #       foo = "bar"
  #     }
  #   }
  # }

  default = {}
}

# ---------------------------------------------------------------------------------------------------------------------
# OPTIONAL CROSS ACCOUNT IAM ROLES PARAMETERS
# These variables have defaults, but may be overridden by the operator.
# ---------------------------------------------------------------------------------------------------------------------

variable "allow_ssh_grunt_access_from_other_account_arns" {
  description = "A list of IAM ARNs from other AWS accounts that will be allowed read access to IAM groups and publish SSH keys. This is used for ssh-grunt."
  type        = list(string)
  default     = []
  # Example:
  # default = [
  #   "arn:aws:iam::123445678910:root"
  # ]
}
----

Finally, add some useful outputs in `outputs.tf`:

.infrastructure-modules/landingzone/account-baseline-security/outputs.tf
[source,hcl]
----
# ---------------------------------------------------------------------------------------------------------------------
# CONFIG OUTPUTS
# ---------------------------------------------------------------------------------------------------------------------

output "config_s3_bucket_names" {
  description = "The names of the S3 bucket used by AWS Config to store configuration items."
  value       = module.security_baseline.config_s3_bucket_names
}

output "config_iam_role_arns" {
  description = "The ARNs of the IAM role used by the config recorder."
  value       = module.security_baseline.config_iam_role_arns
}

output "config_sns_topic_arns" {
  description = "The ARNs of the SNS Topic used by the config notifications."
  value       = module.security_baseline.config_sns_topic_arns
}

output "config_recorder_names" {
  description = "The names of the configuration recorder."
  value       = module.security_baseline.config_recorder_names
}

# ---------------------------------------------------------------------------------------------------------------------
# CLOUDTRAIL OUTPUTS
# ---------------------------------------------------------------------------------------------------------------------

output "cloudtrail_trail_arn" {
  description = "The ARN of the cloudtrail trail."
  value       = module.security_baseline.cloudtrail_trail_arn
}

output "cloudtrail_s3_bucket_name" {
  description = "The name of the S3 bucket where cloudtrail logs are delivered."
  value       = module.security_baseline.cloudtrail_s3_bucket_name
}

output "cloudtrail_kms_key_arn" {
  description = "The ARN of the KMS key used by the S3 bucket to encrypt cloudtrail logs."
  value       = module.security_baseline.cloudtrail_kms_key_arn
}

output "cloudtrail_kms_key_alias_name" {
  description = "The alias of the KMS key used by the S3 bucket to encrypt cloudtrail logs."
  value       = module.security_baseline.cloudtrail_kms_key_alias_name
}

output "cloudtrail_cloudwatch_group_name" {
  description = "The name of the cloudwatch log group."
  value       = module.security_baseline.cloudtrail_cloudwatch_group_name
}

output "cloudtrail_cloudwatch_group_arn" {
  description = "The ARN of the cloudwatch log group."
  value       = module.security_baseline.cloudtrail_cloudwatch_group_arn
}

# ---------------------------------------------------------------------------------------------------------------------
# CROSS ACCOUNT IAM ROLES OUTPUTS
# ---------------------------------------------------------------------------------------------------------------------

output "allow_read_only_access_from_other_accounts_iam_role_arn" {
  description = "IAM ARNs from other AWS accounts that will be allowed read-only access to this account."
  value       = module.security_baseline.allow_read_only_access_from_other_accounts_iam_role_arn
}

output "allow_billing_access_from_other_accounts_iam_role_arn" {
  description = "IAM ARNs from other AWS accounts that will be allowed full (read and write) access to the billing info for this account."
  value       = module.security_baseline.allow_billing_access_from_other_accounts_iam_role_arn
}

output "allow_logs_access_from_other_accounts_iam_role_arn" {
  description = "IAM ARNs from other AWS accounts that will be allowed read access to the logs in CloudTrail, AWS Config, and CloudWatch in this account."
  value       = module.security_baseline.allow_billing_access_from_other_accounts_iam_role_arn
}

output "allow_ssh_grunt_access_from_other_accounts_iam_role_arn" {
  description = "IAM ARNs from other AWS accounts that will be allowed read access to IAM groups and publish SSH keys. This is used for ssh-grunt."
  value       = module.security_baseline.allow_ssh_grunt_access_from_other_accounts_iam_role_arn
}

output "allow_dev_access_from_other_accounts_iam_role_arn" {
  description = "IAM ARNs from other AWS accounts that will be allowed full (read and write) access to the services in this account specified in var.dev_permitted_services."
  value       = module.security_baseline.allow_dev_access_from_other_accounts_iam_role_arn
}

output "allow_iam_admin_access_from_other_accounts_iam_role_arn" {
  description = "IAM ARNs from other AWS accounts that will be allowed IAM administrator (effectively the same as administrator) access to this account."
  value       = module.security_baseline.allow_iam_admin_access_from_other_accounts_iam_role_arn
}

output "allow_support_access_from_other_accounts_iam_role_arn" {
  description = "IAM ARNs from other AWS accounts that will be allowed support access to this account."
  value       = module.security_baseline.allow_support_access_from_other_accounts_iam_role_arn
}

output "allow_auto_deploy_access_from_other_accounts_iam_role_arn" {
  description = "IAM ARNs from other AWS accounts that will be allowed assume the auto deploy IAM role that has the permissions in var.auto_deploy_permissions."
  value       = module.security_baseline.allow_auto_deploy_access_from_other_accounts_iam_role_arn
}

output "allow_read_only_access_from_other_accounts_iam_role_id" {
  description = "IAM IDs (names) from other AWS accounts that will be allowed read-only access to this account."
  value       = module.security_baseline.allow_read_only_access_from_other_accounts_iam_role_id
}

output "allow_billing_access_from_other_accounts_iam_role_id" {
  description = "IAM IDs (names) from other AWS accounts that will be allowed full (read and write) access to the billing info for this account."
  value       = module.security_baseline.allow_billing_access_from_other_accounts_iam_role_id
}

output "allow_logs_access_from_other_accounts_iam_role_id" {
  description = "IAM IDs (names) from other AWS accounts that will be allowed read access to the logs in CloudTrail, AWS Config, and CloudWatch in this account."
  value       = module.security_baseline.allow_logs_access_from_other_accounts_iam_role_id
}

output "allow_ssh_grunt_access_from_other_accounts_iam_role_id" {
  description = "IAM IDs (names) from other AWS accounts that will be allowed read access to IAM groups and publish SSH keys. This is used for ssh-grunt."
  value       = module.security_baseline.allow_ssh_grunt_access_from_other_accounts_iam_role_id
}

output "allow_dev_access_from_other_accounts_iam_role_id" {
  description = "IAM IDs (names) from other AWS accounts that will be allowed full (read and write) access to the services in this account specified in var.dev_permitted_services."
  value       = module.security_baseline.allow_dev_access_from_other_accounts_iam_role_id
}

output "allow_iam_admin_access_from_other_accounts_iam_role_id" {
  description = "IAM IDs (names) from other AWS accounts that will be allowed IAM administrator (effectively the same as administrator) access to this account."
  value       = module.security_baseline.allow_iam_admin_access_from_other_accounts_iam_role_id
}

output "allow_support_access_from_other_accounts_iam_role_id" {
  description = "IAM IDs (names) from other AWS accounts that will be allowed support access to this account."
  value       = module.security_baseline.allow_support_access_from_other_accounts_iam_role_id
}

output "allow_auto_deploy_access_from_other_accounts_iam_role_id" {
  description = "IAM IDs (names) from other AWS accounts that will be allowed assume the auto deploy IAM role that has the permissions in var.auto_deploy_permissions."
  value       = module.security_baseline.allow_auto_deploy_access_from_other_accounts_iam_role_id
}

output "allow_read_only_access_sign_in_url" {
  description = "The URL for signing in with read-only access."
  value       = module.security_baseline.allow_read_only_access_sign_in_url
}

output "allow_billing_access_sign_in_url" {
  description = "The URL for signing in with billing access."
  value       = module.security_baseline.allow_billing_access_sign_in_url
}

output "allow_logs_access_sign_in_url" {
  description = "The URL for signing in with logs access."
  value       = module.security_baseline.allow_logs_access_sign_in_url
}

output "allow_ssh_grunt_access_sign_in_url" {
  description = "The URL for signing in with ssh-grunt access."
  value       = module.security_baseline.allow_ssh_grunt_access_sign_in_url
}

output "allow_dev_access_sign_in_url" {
  description = "The URL for signing in with dev access."
  value       = module.security_baseline.allow_dev_access_sign_in_url
}

output "allow_iam_admin_access_sign_in_url" {
  description = "The URL for signing in with IAM Admin access."
  value       = module.security_baseline.allow_iam_admin_access_sign_in_url
}

output "allow_support_access_sign_in_url" {
  description = "The URL for signing in with support access."
  value       = module.security_baseline.allow_support_access_sign_in_url
}

# ---------------------------------------------------------------------------------------------------------------------
# IAM USERS OUTPUTS
# ---------------------------------------------------------------------------------------------------------------------

output "user_arns" {
  description = "A map of usernames to the ARN for that IAM user."
  value       = module.security_baseline.user_arns
}

output "user_passwords" {
  description = "A map of usernames to that user's AWS Web Console password, encrypted with that user's PGP key (only shows up for users with create_login_profile = true). You can decrypt the password on the CLI: echo <password> | base64 --decode | keybase pgp decrypt"
  value       = module.security_baseline.user_passwords
}

output "user_access_keys" {
  description = "A map of usernames to that user's access keys (a map with keys access_key_id and secret_access_key), with the secret_access_key encrypted with that user's PGP key (only shows up for users with create_access_keys = true). You can decrypt the secret_access_key on the CLI: echo <secret_access_key> | base64 --decode | keybase pgp decrypt"
  value       = module.security_baseline.user_access_keys
}

# ---------------------------------------------------------------------------------------------------------------------
# KMS CMK OUTPUTS
# ---------------------------------------------------------------------------------------------------------------------

output "kms_key_arns" {
  description = "A map from region to ARNs of the KMS CMKs that were created. The value will also be a map mapping the keys from the var.kms_customer_master_keys input variable to the corresponding ARN."
  value       = module.security_baseline.kms_key_arns
}

# ---------------------------------------------------------------------------------------------------------------------
# CLEANUP EXPIRED CERTS OUTPUTS
# ---------------------------------------------------------------------------------------------------------------------

output "lambda_function_arn" {
  value = module.security_baseline.lambda_function_arn
}
----

At this point, you'll want to test your code. See
link:/guides/foundations/how-to-use-gruntwork-infrastructure-as-code-library#manual_tests_terraform[Manual tests for Terraform code] and
link:/guides/foundations/how-to-use-gruntwork-infrastructure-as-code-library#automated_tests_terraform[Automated tests for Terraform code]
for instructions.

When you're done testing, commit and release your changes:

[source,bash]
----
git add landingzone/account-baseline-security
git commit -m "Add security account baseline wrapper module"
git tag -a "v0.3.2" -m "Created security account baseline module"
git push --follow-tags
----

Create a `terragrunt.hcl` file in `infrastructure-live` under the file path `security/_global/account-baseline`:

----
infrastructure-live
   root
   logs
   security
     _global
       account-baseline
         terragrunt.hcl
----

Point the `source` URL in your `terragrunt.hcl` file to your `account-baseline-security` wrapper module in the `infrastructure-modules`
repo, setting the `ref` param to the version you released earlier:

.infrastructure-live/security/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
terraform {
  source = "git::git@github.com/<YOUR_ORG>/infrastructure-modules.git//landingzone/account-baseline-security?ref=v0.3.2"

  # This module deploys some resources (e.g., AWS Config) across all AWS regions, each of which needs its own provider,
  # which in Terraform means a separate process. To avoid all these processes thrashing the CPU, which leads to network
  # connectivity issues, we limit the parallelism here.
  extra_arguments "parallelism" {
    commands  = get_terraform_commands_that_need_parallelism()
    arguments = ["-parallelism=2"]
  }
}
----

[.exceptional]
IMPORTANT: We **strongly** recommend setting Terraform parallelism to a low value (e.g., `-parallelism=2`), as shown above, with the `account-baseline-xxx` modules. This is because these modules deploy multi-region resources (e.g., GuardDuty, AWS Config, etc), and for each region, Terraform spins up a separate process, so if you don't limit the parallelism, it may peg all your CPU cores and lead to network connectivity errors.

Set the variables for the `account-baseline-security` module in this environment in the `inputs = { ... }` block of `terragrunt.hcl`:

.infrastructure-live/security/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
inputs = {
  # Fill in your region you want to use (only used for API calls) and the ID of your security AWS account
  aws_region     = "us-east-2"
  aws_account_id = "<SECURITY_ACCOUNT_ID>"

  # Prefix all resources with this name
  name_prefix = "<COMPANY_NAME>-security"

  # Use the S3 bucket and KMS key that were already created in this logs account by account-baseline-root
  cloudtrail_s3_bucket_name = "<CLOUDTRAIL_BUCKET_NAME>"
  cloudtrail_kms_key_arn    = "<CLOUDTRAIL_KMS_KEY_ARN>"

  # Use the S3 bucket that was already created in this logs account by account-baseline-root
  config_s3_bucket_name     = "<CONFIG_BUCKET_NAME>"
  config_central_account_id = "<LOGS_ACCOUNT_ID>"
  config_aggregate_config_data_in_external_account = true

  # Enable the IAM groups you want
  should_create_iam_group_full_access    = true
  should_create_iam_group_read_only      = true
  should_create_iam_group_user_self_mgmt = true

  # Configure the names for IAM groups
  iam_group_name_iam_user_self_mgmt     = "iam-admin"
  iam_group_names_ssh_grunt_users       = ["ssh-grunt-users"]

  # Cleanup expired SSL/TLS certificates
  schedule_expression                         = "rate(1 hour)"

  # Security Hub - accept invitation from `root` account
  security_hub_associate_to_master_account_id = "<ROOT_ACCOUNT_ID>"

  # Create IAM groups that grant access to the other AWS accounts
  iam_groups_for_cross_account_access = [
    {
      group_name    = "_account.dev-read-only",
      iam_role_arns = ["arn:aws:iam::<DEV_ACCOUNT_ID>:role/allow-read-only-access-from-other-accounts"]
    },

    # ... Repeat the same set of groups for each of stage, prod, logs, and shared services account IDs too!
  ]

  # Create all the IAM users for your company and assign them to IAM groups
  users = {
    alice = {
      groups               = ["user-self-mgmt", "ssh-sudo-users", "_account.dev-full-access"]
      pgp_key              = "keybase:alice_on_keybase"
      create_login_profile = true
      create_access_keys   = false
    }

    bob = {
      groups               = ["user-self-mgmt", "_account.dev-full-access", "_account.prod-read-only"]
      pgp_key              = "keybase:bob_on_keybase"
      create_login_profile = true
      create_access_keys   = false
    }
  }

  # Allow ssh-grunt in all other accounts to look up user SSH keys in this account
  allow_ssh_grunt_access_from_other_account_arns = [
    "arn:aws:iam::<DEV_ACCOUNT_ID>:root",
    "arn:aws:iam::<STAGE_ACCOUNT_ID>:root",
    "arn:aws:iam::<PROD_ACCOUNT_ID>:root",
    "arn:aws:iam::<SHARED_SERVICES_ACCOUNT_ID>:root",
  ]
}
----

The code above does the following:

. **Enable Guard Duty**. We've configured AWS Guard Duty for all enabled regions in compliance with CIS.

. **Enable CloudTrail**. We've configured CloudTrail across all enabled regions to use the S3 bucket and KMS CMK in the logs account.

. **Enable AWS Config**. We've configured AWS Config for all enabled regions and set it up to use the S3 bucket in the logs account.

. **Create IAM groups**. We've created IAM groups, both for permissions within the security account (e.g.,
`iam-admin` grants IAM admin permissions in the security account) and for permissions in other accounts (e.g.,
`ssh-grunt-users` enables users to ssh into an EC2 instance running `ssh-grunt` in a any AWS Account).

. **Create IAM users**. The example above creates IAM users for `alice`, `bob` and assigns them to
the various IAM groups. You should create an IAM user for yourself in the `full-access` group, plus IAM users for the
rest of your team in the appropriate groups. Like the root account, the code will also generate a password for each
user and encrypt it with that users PGP key from Keybase (see below for how to handle the passwords).

. **Create IAM Cross Account IAM roles**. We've configured IAM cross account IAM roles that will allow you to authenticate using the IAM users and roles in other AWS Accounts that have been configured with the Landing Zone setup shown in this guide.

. **Create IAM User Password Policy**. We've configured the IAM user password policy to be compliant with CIS 1.3.

. **Create a function to cleanup expired TLS certificates**. We've setup a lambda function to monitor your SSL/TLS certificates and clean them up when they've expired. This is enforced by CIS requirement 1.19.

. **Enable Security Hub**. We've enabled Security Hub across all enabled regions. For this feature to work, the `master` Security Hub account (usually the Account that has the AWS Organizations, in this case `root`) will have to invite the `members` accounts, and the `members` accounts also have to accept the invitation. This is currently done programmatically, not via `terraform`.

Configure your Terraform backend:

.infrastructure-live/security/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
include {
  path = find_in_parent_folders()
}
----

Just as with the logs account, you're going to use the `OrganizationAccountAccessRole` IAM role created by
`account-baseline-root` to authenticate to the security account. There are many ways to
https://blog.gruntwork.io/a-comprehensive-guide-to-authenticating-to-aws-on-the-command-line-63656a686799[assume an IAM role on the CLI];
for this guide, we're going to keep using `aws-vault`.

Add a new `profile` entry in `~/.aws/config` for your security account that uses the `root-iam-user` as the
`source_profile`:

[source,text]
----
[profile security-from-root]
role_arn=arn:aws:iam::<SECURITY_ACCOUNT_ID>:role/OrganizationAccountAccessRole
source_profile=root-iam-user
----

Check that you're able to authenticate to the security account:

[source,bash]
----
aws-vault exec security-from-root -- aws sts get-caller-identity
----

You should see JSON output indicating that you've successfully assumed an IAM role:

[source,json]
----
{
  "UserId": "AIDAXXXXXXXXXXXX:1597932316055520000",
  "Account": "<SECURITY_ACCOUNT_ID>",
  "Arn": "arn:aws:sts::<SECURITY_ACCOUNT_ID>:assumed-role/OrganizationAccountAccessRole/1597932316055520000"
}
----

You're now ready to deploy the `account-baseline` module in the security account by running `terragrunt apply`:

[source,bash]
----
cd infrastructure-live/security/_global/account-baseline
aws-vault exec security-from-root -- terragrunt apply
----

[.exceptional]
IMPORTANT: On some operating systems, such as MacOS, you may also need to increase your open files limit to avoid "pipe: too many open files" errors by running: `ulimit -n 1024`.

When `apply` finishes, the module will output the encrypted passwords for the users defined above. Send the encrypted
password to each user, along with their user name, and the IAM user sign-in URL for the account. Each user can then
decrypt the password on their own computer (which should have their PGP key) as follows:

[source,bash]
----
echo "<PASSWORD>" | base64 --decode | keybase pgp decrypt
----


=== Apply the security baseline to the other child accounts

Now that your security account is fully configured, you need to apply the security baseline to the remaining child
accounts (e.g., dev, stage, prod, shared-services) as detailed in the <<child_accounts>> section. Feel free to adjust
this as necessary based on the accounts your company needs.

You can re-use the `account-baseline-app` module you created earlier in your `infrastructure-modules` repo for all of
these child accounts; this module can be used interchangeably between app accounts and log accounts as they deploy most
of the same resources.

Create `terragrunt.hcl` files in `infrastructure-live` under the file paths `<ACCOUNT>/_global/account-baseline`,
where `<ACCOUNT>` is one of these other child accounts, such as dev, stage, prod, and shared-services. In the rest of
this example, well look solely at the stage account, but make sure you follow the analogous steps for EACH of your
child accounts.

----
infrastructure-live
   root
   logs
   security
   stage
     _global
       account-baseline
         terragrunt.hcl
----

Point the `source` URL in your `terragrunt.hcl` file to your `account-baseline-app` wrapper module in the `infrastructure-modules`
repo, setting the `ref` param to the latest version:

.infrastructure-live/stage/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
terraform {
  source = "git::git@github.com/<YOUR_ORG>/infrastructure-modules.git//landingzone/account-baseline-app?ref=v0.3.2"

  # This module deploys some resources (e.g., AWS Config) across all AWS regions, each of which needs its own provider,
  # which in Terraform means a separate process. To avoid all these processes thrashing the CPU, which leads to network
  # connectivity issues, we limit the parallelism here.
  extra_arguments "parallelism" {
    commands  = get_terraform_commands_that_need_parallelism()
    arguments = ["-parallelism=2"]
  }
}
----

[.exceptional]
IMPORTANT: We **strongly** recommend setting Terraform parallelism to a low value (e.g., `-parallelism=2`), as shown above, with the `account-baseline-xxx` modules. This is because these modules deploy multi-region resources (e.g., GuardDuty, AWS Config, etc), and for each region, Terraform spins up a separate process, so if you don't limit the parallelism, it may peg all your CPU cores and lead to network connectivity errors.

Set the variables for the `account-baseline-app` module in this environment in the `inputs = { ... }` block of `terragrunt.hcl`:

.infrastructure-live/stage/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
inputs = {
  # Fill in your region you want to use (only used for API calls) and the ID of your security AWS account
  aws_region     = "us-east-2"
  aws_account_id = "<STAGE_ACCOUNT_ID>"

  # Prefix all resources with this name
  name_prefix = "<COMPANY_NAME>-stage"

  # Use the S3 bucket and KMS key that were already created in this logs account by account-baseline-root
  cloudtrail_s3_bucket_name = "<CLOUDTRAIL_BUCKET_NAME>"
  cloudtrail_kms_key_arn    = "<CLOUDTRAIL_KMS_KEY_ARN>"

  # Use the S3 bucket that was already created in this logs account by account-baseline-root
  config_s3_bucket_name                            = "<CONFIG_BUCKET_NAME>"
  config_aggregate_config_data_in_external_account = true
  config_central_account_id                        = "<LOGS_ACCOUNT_ID>"

  # Specify the services the dev IAM role will have access to
  dev_permitted_services = ["ec2", "s3", "rds", "dynamodb", "elasticache", "eks", "ecs"]

  # Specify the services the auto-deploy IAM role will have access to
  auto_deploy_permissions = ["cloudwatch:*", "logs:*", "dynamodb:*", "ecr:*", "ecs:*", "iam:GetPolicy", "iam:GetPolicyVersion", "iam:ListEntitiesForPolicy", "eks:DescribeCluster", "route53:*", "s3:*", "autoscaling:*", "elasticloadbalancing:*", "iam:GetRole", "iam:GetRolePolicy", "iam:PassRole"]

  # Allow users in the security account to access the IAM roles in this account
  allow_read_only_access_from_other_account_arns = ["arn:aws:iam::<SECURITY_ACCOUNT_ID>:root"]
  allow_billing_access_from_other_account_arns   = ["arn:aws:iam::<SECURITY_ACCOUNT_ID>:root"]
  allow_dev_access_from_other_account_arns       = ["arn:aws:iam::<SECURITY_ACCOUNT_ID>:root"]
  allow_full_access_from_other_account_arns      = ["arn:aws:iam::<SECURITY_ACCOUNT_ID>:root"]

  # Allow a CI server in the shared-services account to assume the auto-deploy IAM role in this account
  allow_auto_deploy_from_other_account_arns      = ["arn:aws:iam::<SHARED_SERVICES_ACCOUNT_ID>:root"]
}
----

The code above does the following:

. **Enable CloudTrail**. We've configured CloudTrail to use the S3 bucket and KMS CMK in the logs account.

. **Enable AWS Config**. We've configured AWS Config to use the S3 bucket in the logs account.

. **Configure the dev IAM role**. We create a `dev` IAM role in this account, which will get read and write access to
the services specified in `dev_permitted_services`.

. **Configure the Auto Deploy IAM role**. We also create an `auto-deploy` IAM role that can be assumed by a CI server
in the shared-services account to do deployments. This role will have the permissions specified in
`auto_deploy_permissions`.

. **Configure cross-account IAM roles**. We then specify which other accounts are allowed to assume the IAM roles in
this account. For the most part, we grant all permissions to the security account, so that by assigning users to IAM
groups in that account, you'll be able to access IAM roles in all the other child accounts.

Configure your Terraform backend:

.infrastructure-live/stage/_global/account-baseline/terragrunt.hcl
[source,hcl]
----
include {
  path = find_in_parent_folders()
}
----

Just as with the logs and security accounts, you're going to use the `OrganizationAccountAccessRole` IAM role created by
`account-baseline-root` to authenticate to the stage account and all other child accounts. There are many ways to
https://blog.gruntwork.io/a-comprehensive-guide-to-authenticating-to-aws-on-the-command-line-63656a686799[assume an IAM role on the CLI];
for this guide, we're going to keep using `aws-vault`.

Add a new `profile` entry in `~/.aws/config` for your stage account that uses the `root-iam-user` as the
`source_profile`:

[source,text]
----
[profile stage-from-root]
role_arn=arn:aws:iam::<STAGE_ACCOUNT_ID>:role/OrganizationAccountAccessRole
source_profile=root-iam-user
----

Check that you're able to authenticate to the stage account:

[source,bash]
----
aws-vault exec stage-from-root -- aws sts get-caller-identity
----

You should see JSON output indicating that you've successfully assumed an IAM role:

[source,json]
----
{
  "UserId": "AIDAXXXXXXXXXXXX:1597932316055520000",
  "Account": "<STAGE_ACCOUNT_ID>",
  "Arn": "arn:aws:sts::<STAGE_ACCOUNT_ID>:assumed-role/OrganizationAccountAccessRole/1597932316055520000"
}
----

You're now ready to deploy the `account-baseline` module in the stage account by running `terragrunt apply`:

[source,bash]
----
cd infrastructure-live/stage/_global/account-baseline
aws-vault exec stage-from-root -- terragrunt apply
----

[.exceptional]
IMPORTANT: On some operating systems, such as MacOS, you may also need to increase your open files limit to avoid "pipe: too many open files" errors by running: `ulimit -n 1024`.

Remember to repeat this process in the other child accounts too (i.e., dev, prod, shared-services, etc)!


//TODO: rest of account-baseline app, logs, security, etc






=== Try authenticating as an IAM user to the child accounts

Now that you have IAM users in the security account and IAM roles in the other accounts, it's time to practice
authenticating:

. Use your IAM user's user name and password (decrypted using keybase) to log into the web console of the security
  account (remember to use the IAM user sign-in URL for the security account).
. Follow the steps in <<lock_down_iam_users>> to lock down your IAM user in the security account. This includes
  configuring an MFA device for your IAM user.
. After configuring an MFA device, log out, and then log back into the security account again, this time providing your
  MFA token. If you don't do this, attempting to assume IAM roles in other accounts won't work, as those roles require
  an MFA token to be present.
. Try to https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-console.html[switch to a role] in
  one of the other child accounts using the AWS Web Console. For example, authenticate as one of the IAM users in the
  security account, and then assume the `allow-full-access-from-other-accounts` role in the dev account (you can find
  the default list of IAM roles created in each account
  https://github.com/gruntwork-io/module-security/tree/master/modules/cross-account-iam-roles#resources-created[here]).
. Alternatively, you can use the `aws-vault login xxx` command to login to the AWS Web Console for any profile `xxx`
  that you've configured in `aws-vault`. For example, `aws-vault login logs-from-root` will open up your web browser
  and log you into the logs account using the `OrganizationAccountAccessRole` IAM Role.

[[configure_security_hub]]
=== Configure AWS Security Hub in the root account

// TODO need to reword this. I've just thrown and edited two parts, but it doesn't make sense 

Next, we'll configure link:https://aws.amazon.com/security-hub/[AWS Security Hub] in the root account. AWS Security Hub
is deployed by the account baselines in every enabled region of an AWS account to check your account link:https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-standards.html[for compliance]
with the AWS CIS Foundations Benchmark. The Security Hub runs the exact audit steps specified in the Benchmark using AWS
Config managed rules. Note: Security Hub is not explicitly required by the Benchmark, however we suggest enabling it,
so you can track your compliance efforts and be notified if any recommendations have not been implemented.

Caveat: In the AWS Console UI, AWS Security Hub will show a low security score for the CIS AWS Foundations Benchmark v1.2.0. However, this is due to AWS limitations on checking compliance standards for cross-region/cross-account rules. This does not indicate that the accounts are not in compliance; it is a failure of the AWS audit tool. Note also that the accounts are configured for the latest version of the benchmark, v1.3.0; the AWS Security Hub does not support this version.

[[iam_roles_for_instances]]
=== Use IAM roles for EC2 instances
All Gruntwork modules that require AWS API access use roles rather than an IAM user with static API credentials for
authentication. For example:

* link:https://github.com/gruntwork-io/terraform-aws-server/blob/master/modules/single-server/main.tf[`terraform-aws-server`]
 is used to manage a single EC2 instance with an IAM role attached.
* link:https://github.com/gruntwork-io/terraform-aws-asg[`terraform-aws-asg`] applies IAM roles to instances in auto-scaling
 group.
* link:https://github.com/gruntwork-io/terraform-aws-eks/blob/master/modules/eks-cluster-workers/main.tf[`terraform-aws-eks`]
 uses IAM roles for EKS cluster workers.
* link:https://github.com/gruntwork-io/terraform-aws-ecs/tree/master/modules/ecs-cluster[`ecs-cluster`] creates IAM
 roles for ECS instances
* link:https://github.com/gruntwork-io/terraform-aws-lambda/tree/master/modules/lambda[`lambda`] creates IAM
 roles for Lambda functions

Use these modules whenever possible. You should always use IAM roles in your own modules any time you need to provide
access to the AWS API. Using static API credentials should be avoided whenever possible.

[[maintain_compliance_iam]]
=== Maintaining compliance by following IAM best practices
We conclude the IAM section with a few parting words of wisdom for maintaining compliance over time:

. Do not attach any policies without requiring MFA.
. Never use the `AdministratorAccess` AWS managed policy with any users, groups, or roles.
. Refrain from granting inline permissions or attaching managed policies directly to IAM users. Permissions
should be granted exclusively via IAM groups and roles.
. Never use static IAM user access keys to allow an application to access AWS, whether that application is hosted on an EC2 instance or anywhere else!
. Avoid logging in as the root user. Unfortunately, there is nothing built-in to AWS to prevent use of the
root user. It cannot be locked or removed from the account. In fact, there are
link:https://docs.aws.amazon.com/general/latest/gr/aws_tasks-that-require-root.html[several tasks that require
the use of root].  Fortunately, most of these activities are rare, so usage of the root account can be kept to
a minimum.

[[maintain_compliance_storage]]
=== Maintaining compliance by following Storage best practices

[[s3_buckets_deployment]]
==== S3 Buckets
To make sure your S3 buckets are compliant with the benchmark, use the
link:https://github.com/gruntwork-io/terraform-aws-security/tree/master/modules/private-s3-bucket[`private-s3-bucket` module]
to create and manage all of your S3 buckets. This module blocks public access and enforces encryption by default. Note
that all Gruntwork modules that create S3 buckets use this module under the hood.

You can either use the `private-s3-bucket` module in your own modules, or, if you wish to deploy a standalone S3 bucket, use the https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/modules/data-stores/s3-bucket/[`s3-bucket` service]
from the Gruntwork Service Catalog.

[[maintain_compliance_logging]]
=== Maintaining compliance by following Logging best practices

The logging section of the Benchmark includes configurations for CloudTrail, AWS Config, KMS keys, and VPC
flow logs.

[[kms]]
==== Enable key rotation for KMS keys
To make sure your KMS keys are compliant with the benchmark, use the
link:https://github.com/gruntwork-io/terraform-aws-security/blob/master/modules/kms-master-key/README.md[`kms-master-key` module]
to create KMS keys with key rotation enabled by default.

[[vpc_flow_logs]]
==== Create VPC flow logs
The Benchmark recommends enabling link:https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html[VPC Flow Logs]
for all VPCs in all regions. You can use the
link:https://github.com/gruntwork-io/terraform-aws-cis-service-catalog/blob/master/modules/networking/vpc[`vpc` service]
in the AWS CIS Service Catalog to create your VPCs. This service is configured for CIS compliance, and as such has VPC flow
logs enabled. For example, you might create a VPC using the VPC service:

.infrastructure-modules/networking/vpc/myvpc/main.tf
[source,hcl]
----

module "vpc" {
  # Replace <VERSION> with the most recent release from https://github.com/gruntwork-io/terraform-aws-cis-service-catalog/releases
  source = "git::git@github.com:gruntwork-io/terraform-aws-cis-service-catalog.git//modules/networking/vpc?ref=<VERSION>"

  vpc_name                                                = var.vpc_name
  aws_region                                              = var.aws_region
  cidr_block                                              = var.cidr_block
  num_nat_gateways                                        = var.num_nat_gateways
  allow_administrative_remote_access_cidrs_public_subnets = var.allow_administrative_remote_access_cidrs_public_subnets
}
----

Under the hood, the service will enable VPC flow logs. All that's remaining is to define the parameters in a `variables.tf`:

.infrastructure-modules/networking/vpc/myvpc/variables.tf
[source,hcl]
----
variable "aws_region" {
  description = "The AWS region to deploy to (e.g. us-east-1)"
  type        = string
}

variable "vpc_name" {
  description = "The name of the VPC to create"
  type        = string
}

variable "cidr_block" {
  description = "The IP address range of the app VPC in CIDR notation."
  type        = string
}

variable "num_nat_gateways" {
  description = "The number of NAT Gateways to launch for this VPC."
  type        = number
}

variable "allow_administrative_remote_access_cidrs_public_subnets" {
  description = "A map of CIDR blocks that will be allowed access to administrative ports (e.g., SSH, RDP) in the public subnet tier."
  type        = map(string)

  # Example:
  #
  #   default = {
  #    UsOffice = "1.2.3.4/32"
  #    EuOffice = "5.6.7.8/32"
  # }
}
----

Refer to the VPC
link:https://github.com/gruntwork-io/terraform-aws-cis-service-catalog/tree/master/examples/for-learning-and-testing/networking/vpc/terraform[example code].

To limit the number of flow logs, you may want to use the
link:https://github.com/gruntwork-io/cloud-nuke[`cloud-nuke defaults-aws`] command. It will remove the default VPC from
all regions in an account, saving you the hassle of creating flow logs in each default VPC.

[[maintain_compliance_monitoring]]
=== Maintaining compliance by following Monitoring best practices
The Monitoring section of the Benchmark centers on a collection of
link:https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/MonitoringLogData.html[CloudWatch Logs Metric
Filters]. Gruntwork has simplified this section to a single module: the
link:https://github.com/gruntwork-io/terraform-aws-cis-service-catalog/blob/master/modules/cloudwatch-logs-metric-filters/README.adoc[`cloudwatch-logs-metric
-filters` wrapper module]. It will create and configure all the CloudWatch Logs metric filters necessary for
compliance with the Benchmark. Note that when you deploy the CIS account baseline modules, the CloudWatch Logs metric
filters will be created and configured automatically.have to do anything special to enable the metric filters on the
deployed CloudTrail configuration.

Note that you must have a subscriber on the SNS topic to be compliant. Refer to <<subscribe_sns>> for details on how to
setup a subscriber to the SNS topics that are created.

[[maintain_compliance_networking]]
=== Maintaining compliance by following Networking best practices

To ensure all the networking recommendations are satisfied, use the
link:https://github.com/gruntwork-io/terraform-aws-cis-service-catalog/tree/master/modules/networking/vpc[`vpc`] (and/or
link:https://github.com/gruntwork-io/terraform-aws-cis-service-catalog/tree/master/modules/networking/vpc-mgmt[`vpc-mgmt`])
service from Gruntwork's AWS CIS Service Catalog to create all your VPCs. These services are specifically configured for
CIS compliance, and as such they don't allow security groups to access ports 22 or 3389 from the world. In addition,
our architecture has a least-privileges-based routing configuration by default.

To meet the 5.1 recommendation, you'll need to provide values for the `allow_administrative_remote_access_*` variables
when creating VPCs. These variables are used to create appropriate Network ACL Rules. For example, you might create a
VPC using the `vpc` service from `terraform-aws-cis-service-catalog`:

----
infrastructure-modules
 networking
     vpc
         myvpc
             main.tf
             variables.tf
----

.infrastructure-modules/networking/vpc/myvpc/main.tf
[source,hcl]
----
module "vpc" {
  # Replace <VERSION> with the most recent release from the https://github.com/gruntwork-io/terraform-aws-cis-service-catalog/releases:
  source = "git::git@github.com:gruntwork-io/terraform-aws-cis-service-catalog.git//modules/networking/vpc?ref=<VERSION>"

  # Set the basic required variables first
  vpc_name         = var.vpc_name
  aws_region       = var.aws_region
  cidr_block       = var.cidr_block
  num_nat_gateways = var.num_nat_gateways

  # Next, pass values for the allow_administrative_remote_access_* variables, thus creating the NACL rules under the hood
  allow_administrative_remote_access_cidrs_public_subnets              = var.allow_administrative_remote_access_cidrs
  allow_administrative_remote_access_cidrs_private_app_subnets         = { all_app_vpc_cidrs  = module.vpc.vpc_cidr_block }
  allow_administrative_remote_access_cidrs_private_persistence_subnets = { all_app_vpc_cidrs  = module.vpc.vpc_cidr_block }
----

Refer to the https://github.com/gruntwork-io/terraform-aws-cis-service-catalog/tree/master/examples/for-learning-and-testing/networking/vpc/terraform[terraform-aws-cis-service-catalog]
repo for a more comprehensive example.

Finally, run the link:https://github.com/gruntwork-io/cloud-nuke[`cloud-nuke defaults-aws`] command to remove all
default security groups from all VPCs in all regions.

[[next_steps]]
== Next steps

Congratulations! If you've made it this far, you should have achieved compliance with the CIS AWS Foundations
Benchmark. Now it's time to confirm that your configurations are correct and you didn't miss any steps.
 +
 +


[[traceability_matrix]]
== Traceability matrix
Use the table below as a quick reference to map the CIS AWS Foundations Benchmark recommendations to the
sections above.

[cols="^1,<10,15",format=csv]
|===
#,Section,Description
1.1,<<security_questions>>,Complete the contact details on the AWS account page
1.2,<<security_questions>>,Complete the security contact information on the AWS account page
1.3,<<security_questions>>,Answer the security questions on the AWS account page
1.4,<<next_steps>>,Use the Gruntwork Security Hub module to enable AWS Security Hub to ensure that no access key exists for the root user
1.5,<<root_mfa>>,Manually configure MFA for the root user
1.6,<<root_mfa>>,Use a Yubikey (or other hardware MFA) for the root user
1.7,<<manual_steps>>,Take manual steps to complete this recommendation
1.8-9,<<create_password_policy>>,Use the IAM password policy module
1.10,<<configure_authentication>>,Configure authentication using SAML or IAM
1.11,<<iam_user_authentication>>,Create IAM users with the `iam-users` module
1.12,<<next_steps>>,Use the Gruntwork Security Hub module to enable AWS Security Hub to ensure that there are no unused credentials
1.13,<<next_steps>>,Use the Gruntwork Security Hub module to enable AWS Security Hub to ensure that there are no extra access keys
1.14,<<next_steps>>,Use the Gruntwork Security Hub module to enable AWS Security Hub to ensure that there are no unused access keys
1.15,<<iam_user_authentication>>,Use IAM groups
1.16,<<iam_user_authentication>>,Use the Gruntwork modules to create best-practices groups and roles
1.17,<<iam_user_authentication>>,Use the `iam-groups` module to create a support group
1.18,<<iam_roles_for_instances>>,Use Gruntwork modules to ensure EC2 instances use roles for access
1.19,<<cleanup_expired_certs>>,Use Gruntwork modules to automatically remove expired certificates from IAM
1.20,<<s3_buckets_deployment>>,Use the `private-s3-bucket` module
1.21,<<iam_access_analyzer>>,Use Gruntwork modules to enable IAM Access Analyzer across regions
1.22,<<account_structure>>,Use the security AWS account as described in the Gruntwork production-grade AWS account structure
2.1.1-2.1.2,<<configure_storage>>,Use the `private-s3-bucket` module
2.2.1,<<configure_storage>>,Use Gruntwork modules to configure AWS EBS encryption
3.1-3.4,<<cloudtrail>>,Use the Gruntwork CloudTrail wrapper module
3.5,<<aws_config>>,Enable AWS Config for all regions
3.6-3.7,<<cloudtrail>>,Use the Gruntwork CloudTrail wrapper module
3.8,<<kms>>,Use the KMS module
3.9,<<vpc_flow_logs>>,Use the Gruntwork CIS-compliant `vpc` service to provision VPCs with flow logs enabled
3.10-3.11,<<cloudtrail>>,Use the Gruntwork CloudTrail wrapper module
4.1-4.15,<<configure_monitoring>>,The CloudWatch Logs metrics filters wrapper module will satisfy each recommendation
5.1,<<configure_networking>>,Use the Gruntwork CIS-compliant `vpc` service to ensure there is no public remote access
5.2,<<configure_networking>>,Use the Gruntwork CIS-compliant `vpc` service for a secure network configuration
5.3,<<configure_networking>>,Use the `cloud-nuke` tool to remove all default security groups
5.4,<<configure_networking>>,Use the Gruntwork CIS-compliant `vpc` service to configure least-privilege routing by default
|===
